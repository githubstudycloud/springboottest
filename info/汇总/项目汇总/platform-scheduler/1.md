我将帮你重写platform-scheduler模块。让我们从表结构设计开始。

首先创建所需的数据库表:



```sql
-- 任务定义表
CREATE TABLE job_definition (
    id VARCHAR(50) NOT NULL COMMENT '任务ID',
    name VARCHAR(100) NOT NULL COMMENT '任务名称',
    description VARCHAR(500) COMMENT '任务描述',  
    job_type VARCHAR(20) NOT NULL COMMENT '任务类型:HTTP/SHELL等',
    cron_expression VARCHAR(100) COMMENT 'CRON表达式',
    fixed_delay BIGINT COMMENT '固定延迟(毫秒)',
    timeout BIGINT COMMENT '超时时间(毫秒)',
    max_retries INT DEFAULT 0 COMMENT '最大重试次数',
    retry_interval BIGINT DEFAULT 0 COMMENT '重试间隔(毫秒)',
    job_data TEXT COMMENT '任务数据(JSON格式)',
    status VARCHAR(20) NOT NULL DEFAULT 'CREATED' COMMENT '任务状态',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id),
    INDEX idx_status (status),
    INDEX idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务定义表';

-- 任务执行表
CREATE TABLE job_execution (
    id VARCHAR(50) NOT NULL COMMENT '执行ID',
    job_id VARCHAR(50) NOT NULL COMMENT '任务ID',
    node_id VARCHAR(50) NOT NULL COMMENT '执行节点ID',
    start_time DATETIME NOT NULL COMMENT '开始时间',
    end_time DATETIME COMMENT '结束时间',
    status VARCHAR(20) NOT NULL COMMENT '执行状态',
    result TEXT COMMENT '执行结果',
    error TEXT COMMENT '错误信息',
    retry_count INT DEFAULT 0 COMMENT '重试次数',
    trace_id VARCHAR(50) COMMENT '链路追踪ID', 
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id),
    INDEX idx_job_id (job_id),
    INDEX idx_status (status),
    INDEX idx_start_time (start_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务执行表';

-- 任务日志表
CREATE TABLE job_log (
    id VARCHAR(50) NOT NULL COMMENT '日志ID',
    execution_id VARCHAR(50) NOT NULL COMMENT '执行ID',
    job_id VARCHAR(50) NOT NULL COMMENT '任务ID',
    log_type VARCHAR(20) NOT NULL COMMENT '日志类型',
    content TEXT NOT NULL COMMENT '日志内容',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    PRIMARY KEY (id),
    INDEX idx_execution_id (execution_id),
    INDEX idx_job_id (job_id),
    INDEX idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务日志表';

-- 任务锁表
CREATE TABLE job_lock (
    lock_key VARCHAR(100) NOT NULL COMMENT '锁键',
    node_id VARCHAR(50) NOT NULL COMMENT '持有节点',
    expires_at DATETIME NOT NULL COMMENT '过期时间',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (lock_key),
    INDEX idx_expires_at (expires_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务锁表';

-- 任务模板表
CREATE TABLE job_template (
    id VARCHAR(50) NOT NULL COMMENT '模板ID',
    name VARCHAR(100) NOT NULL COMMENT '模板名称',
    description VARCHAR(500) COMMENT '模板描述',
    template_content TEXT NOT NULL COMMENT '模板内容',
    variables TEXT COMMENT '变量定义',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务模板表';

-- 监控指标表 
CREATE TABLE metrics_record (
    id VARCHAR(50) NOT NULL COMMENT '记录ID',
    metrics_name VARCHAR(100) NOT NULL COMMENT '指标名称',
    metrics_value DECIMAL(20,4) NOT NULL COMMENT '指标值',
    node_id VARCHAR(50) COMMENT '节点ID',
    tags JSON COMMENT '标签',
    collect_time DATETIME NOT NULL COMMENT '采集时间',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    PRIMARY KEY (id),
    INDEX idx_metrics_name (metrics_name),
    INDEX idx_collect_time (collect_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='监控指标表';

-- 告警记录表
CREATE TABLE alert_record (
    id VARCHAR(50) NOT NULL COMMENT '告警ID',
    alert_name VARCHAR(100) NOT NULL COMMENT '告警名称',
    alert_level VARCHAR(20) NOT NULL COMMENT '告警级别',
    content TEXT NOT NULL COMMENT '告警内容',
    status VARCHAR(20) NOT NULL COMMENT '告警状态',
    node_id VARCHAR(50) COMMENT '告警节点',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id),
    INDEX idx_alert_name (alert_name),
    INDEX idx_status (status),
    INDEX idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='告警记录表';

```

接下来是pom.xml文件:



```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>platform-parent</artifactId>
        <groupId>com.study</groupId>
        <version>1.0.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>platform-scheduler</artifactId>

    <dependencies>
        <!-- Spring Boot -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-validation</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-aop</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <!-- Database -->
        <dependency>
            <groupId>org.mariadb.jdbc</groupId>
            <artifactId>mariadb-java-client</artifactId>
        </dependency>
        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>${mybatis.version}</version>
        </dependency>

        <!-- Redis -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>
        <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson-spring-boot-starter</artifactId>
            <version>3.23.0</version>
        </dependency>

        <!-- RabbitMQ -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-amqp</artifactId>
        </dependency>

        <!-- Quartz -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-quartz</artifactId>
        </dependency>

        <!-- Common -->
        <dependency>
            <groupId>com.study</groupId>
            <artifactId>platform-common</artifactId>
            <version>${project.version}</version>
        </dependency>

        <!-- Tools -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
        </dependency>
        <dependency> 
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-jsr310</artifactId>
        </dependency>

        <!-- Test -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-core</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <configuration>
                    <mainClass>com.study.scheduler.SchedulerApplication</mainClass>
                    <excludes>
                        <exclude>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok</artifactId>
                        </exclude>
                    </excludes>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>repackage</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>

```

下面是主要的配置文件application.yml:



```yaml
server:
  port: 8081

spring:
  application:
    name: platform-scheduler

  # DataSource
  datasource:
    driver-class-name: org.mariadb.jdbc.Driver
    url: jdbc:mariadb://localhost:3306/scheduler?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
    username: root
    password: 123456
    type: com.zaxxer.hikari.HikariDataSource
    hikari:
      minimum-idle: 5
      maximum-pool-size: 15
      idle-timeout: 30000
      pool-name: SchedulerHikariCP
      max-lifetime: 1800000
      connection-timeout: 30000
      connection-test-query: SELECT 1

  # Redis
  data:
    redis:
      password: 123456
      timeout: 5000
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0
          max-wait: 1000
      cluster:
        nodes:
          - 127.0.0.1:6379
          - 127.0.0.1:6380
          - 127.0.0.1:6381

  # RabbitMQ
  rabbitmq:
    host: localhost
    port: 5672
    username: admin
    password: 123456
    virtual-host: /
    publisher-confirms: true
    publisher-returns: true
    listener:
      simple:
        acknowledge-mode: manual
        prefetch: 1
        concurrency: 3
        max-concurrency: 10
        retry:
          enabled: true
          initial-interval: 1000ms
          max-attempts: 3
          multiplier: 2

  # Quartz
  quartz:
    job-store-type: jdbc
    jdbc:
      initialize-schema: always
    properties:
      org.quartz.scheduler.instanceName: QuartzScheduler
      org.quartz.scheduler.instanceId: AUTO
      org.quartz.jobStore.class: org.springframework.scheduling.quartz.LocalDataSourceJobStore
      org.quartz.jobStore.driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate
      org.quartz.jobStore.tablePrefix: QRTZ_
      org.quartz.jobStore.isClustered: true
      org.quartz.jobStore.clusterCheckinInterval: 10000
      org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool
      org.quartz.threadPool.threadCount: 10
      org.quartz.threadPool.threadPriority: 5

# MyBatis
mybatis:
  mapper-locations: classpath:mapper/*.xml
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.slf4j.Slf4jImpl

# Scheduler Config
scheduler:
  cluster:
    enabled: true
    node-id: ${HOSTNAME:node-1}
  execution:
    pool:
      core-size: 10
      max-size: 20
      queue-capacity: 50
      keep-alive: 300
  retry:
    max-attempts: 3
    initial-interval: 1000
    multiplier: 2.0
    max-interval: 10000
  monitor:
    metrics-interval: 60
    cleanup-interval: 86400

# Management
management:
  endpoints:
    web:
      exposure:
        include: health
```

好的,让我们按照项目结构开始输出代码。从api层开始:

1. 首先创建API层的Controller:



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.*;
import com.study.scheduler.api.model.vo.job.*;
import com.study.scheduler.domain.service.JobDomainService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api/jobs")
public class JobController {

    @Autowired
    private JobDomainService jobDomainService;

    @PostMapping
    public Result<JobVO> createJob(@Validated @RequestBody JobCreateRequest request) {
        log.info("Creating job: {}", request);
        JobVO job = jobDomainService.createJob(request);
        return Result.success(job);
    }

    @PutMapping("/{id}")
    public Result<JobVO> updateJob(@PathVariable String id, 
            @Validated @RequestBody JobUpdateRequest request) {
        log.info("Updating job {}: {}", id, request);
        JobVO job = jobDomainService.updateJob(id, request);
        return Result.success(job);
    }

    @DeleteMapping("/{id}")
    public Result<Void> deleteJob(@PathVariable String id) {
        log.info("Deleting job: {}", id);
        jobDomainService.deleteJob(id);
        return Result.success();
    }

    @GetMapping("/{id}")
    public Result<JobDetailVO> getJob(@PathVariable String id) {
        JobDetailVO job = jobDomainService.getJobDetail(id);
        return Result.success(job);
    }

    @GetMapping
    public Result<List<JobVO>> queryJobs(JobQueryRequest request) {
        List<JobVO> jobs = jobDomainService.queryJobs(request);
        return Result.success(jobs);
    }

    @GetMapping("/{id}/logs")
    public Result<List<JobLogVO>> getJobLogs(@PathVariable String id) {
        List<JobLogVO> logs = jobDomainService.getJobLogs(id);
        return Result.success(logs);
    }

    @PostMapping("/{id}/pause")
    public Result<Void> pauseJob(@PathVariable String id) {
        log.info("Pausing job: {}", id);
        jobDomainService.pauseJob(id);
        return Result.success();
    }

    @PostMapping("/{id}/resume") 
    public Result<Void> resumeJob(@PathVariable String id) {
        log.info("Resuming job: {}", id);
        jobDomainService.resumeJob(id);
        return Result.success();
    }
}

```



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.JobExecuteRequest;
import com.study.scheduler.core.executor.ExecuteResult;
import com.study.scheduler.domain.service.ExecutionDomainService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

@Slf4j
@RestController
@RequestMapping("/api/jobs/execute")
public class JobExecuteController {

    @Autowired
    private ExecutionDomainService executionService;

    @PostMapping("/{id}")
    public Result<ExecuteResult> executeJob(@PathVariable String id, 
            @Validated @RequestBody JobExecuteRequest request) {
        log.info("Executing job {}: {}", id, request);
        ExecuteResult result = executionService.executeJob(id, request);
        return Result.success(result);
    }

    @PostMapping("/{id}/stop")
    public Result<Void> stopJob(@PathVariable String id) {
        log.info("Stopping job execution: {}", id);
        executionService.stopJob(id);
        return Result.success();
    }

    @PostMapping("/{id}/retry")
    public Result<ExecuteResult> retryJob(@PathVariable String id) {
        log.info("Retrying job: {}", id);
        ExecuteResult result = executionService.retryJob(id);
        return Result.success(result);
    }

    @GetMapping("/{id}/status")
    public Result<String> getJobStatus(@PathVariable String id) {
        String status = executionService.getJobStatus(id);
        return Result.success(status);
    }
}

```

现在让我继续输出JobRegisterController和JobTemplateController的代码?好的，继续输出Controller层的代码：



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.JobRegisterRequest;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.manager.JobManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api/jobs/register")
public class JobRegisterController {

    @Autowired
    private JobManager jobManager;

    @PostMapping
    public Result<JobVO> registerJob(@Validated @RequestBody JobRegisterRequest request) {
        log.info("Registering new job: {}", request);
        JobVO job = jobManager.registerJob(request);
        return Result.success(job);
    }

    @PostMapping("/batch")
    public Result<List<JobVO>> batchRegister(@Validated @RequestBody List<JobRegisterRequest> requests) {
        log.info("Batch registering {} jobs", requests.size());
        List<JobVO> jobs = jobManager.batchRegisterJobs(requests);
        return Result.success(jobs);
    }

    @PutMapping("/{id}/enable")
    public Result<Void> enableJob(@PathVariable String id) {
        log.info("Enabling job: {}", id);
        jobManager.enableJob(id);
        return Result.success();
    }

    @PutMapping("/{id}/disable") 
    public Result<Void> disableJob(@PathVariable String id) {
        log.info("Disabling job: {}", id);
        jobManager.disableJob(id);
        return Result.success();
    }

    @GetMapping("/types")
    public Result<List<String>> getJobTypes() {
        List<String> types = jobManager.getSupportedJobTypes();
        return Result.success(types);
    }
}

```



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.JobTemplateRequest;
import com.study.scheduler.api.model.vo.job.JobTemplateVO;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.manager.JobTemplateManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Map;

@Slf4j
@RestController
@RequestMapping("/api/jobs/templates")
public class JobTemplateController {

    @Autowired
    private JobTemplateManager templateManager;

    @PostMapping
    public Result<JobTemplateVO> createTemplate(@Validated @RequestBody JobTemplateRequest request) {
        log.info("Creating job template: {}", request);
        JobTemplateVO template = templateManager.createTemplate(request);
        return Result.success(template);
    }

    @PutMapping("/{id}")
    public Result<JobTemplateVO> updateTemplate(@PathVariable String id,
            @Validated @RequestBody JobTemplateRequest request) {
        log.info("Updating job template {}: {}", id, request);
        JobTemplateVO template = templateManager.updateTemplate(id, request);
        return Result.success(template);
    }

    @DeleteMapping("/{id}")
    public Result<Void> deleteTemplate(@PathVariable String id) {
        log.info("Deleting job template: {}", id);
        templateManager.deleteTemplate(id);
        return Result.success();
    }

    @GetMapping("/{id}")
    public Result<JobTemplateVO> getTemplate(@PathVariable String id) {
        JobTemplateVO template = templateManager.getTemplate(id);
        return Result.success(template);
    }

    @GetMapping
    public Result<List<JobTemplateVO>> listTemplates() {
        List<JobTemplateVO> templates = templateManager.listTemplates();
        return Result.success(templates);
    }

    @PostMapping("/{id}/apply")
    public Result<JobVO> applyTemplate(
            @PathVariable String id,
            @RequestBody Map<String, Object> variables) {
        log.info("Applying template {} with variables: {}", id, variables);
        JobVO job = templateManager.applyTemplate(id, variables);
        return Result.success(job);
    }

    @GetMapping("/{id}/variables")
    public Result<Map<String, String>> getTemplateVariables(@PathVariable String id) {
        Map<String, String> variables = templateManager.getTemplateVariables(id);
        return Result.success(variables);
    }
}

```

接下来是监控相关的Controller:



```java
package com.study.scheduler.api.controller.monitor;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.monitor.MetricsRequest;
import com.study.scheduler.api.model.vo.monitor.MetricsVO;
import com.study.scheduler.core.manager.MetricsManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Map;

@Slf4j
@RestController
@RequestMapping("/api/monitor/metrics")
public class MetricsController {

    @Autowired
    private MetricsManager metricsManager;

    @GetMapping("/system")
    public Result<Map<String, Object>> getSystemMetrics() {
        Map<String, Object> metrics = metricsManager.getSystemMetrics();
        return Result.success(metrics);
    }

    @GetMapping("/job")
    public Result<List<MetricsVO>> getJobMetrics(MetricsRequest request) {
        List<MetricsVO> metrics = metricsManager.getJobMetrics(request);
        return Result.success(metrics);
    }

    @GetMapping("/node")
    public Result<List<MetricsVO>> getNodeMetrics(MetricsRequest request) {
        List<MetricsVO> metrics = metricsManager.getNodeMetrics(request);
        return Result.success(metrics);
    }

    @GetMapping("/execution")
    public Result<Map<String, Long>> getExecutionMetrics() {
        Map<String, Long> metrics = metricsManager.getExecutionMetrics();
        return Result.success(metrics);
    }

    @GetMapping("/{jobId}/history")
    public Result<List<MetricsVO>> getJobMetricsHistory(
            @PathVariable String jobId,
            @RequestParam String metric,
            @RequestParam Long startTime,
            @RequestParam Long endTime) {
        List<MetricsVO> metrics = metricsManager.getJobMetricsHistory(
                jobId, metric, startTime, endTime);
        return Result.success(metrics);
    }
}

```

需要我继续输出AlertController和SystemController吗？好的，继续输出监控告警和系统管理相关的Controller：



```java
package com.study.scheduler.api.controller.monitor;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.monitor.AlertRequest;
import com.study.scheduler.api.model.vo.monitor.AlertVO;
import com.study.scheduler.core.manager.AlertManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api/monitor/alerts")
public class AlertController {

    @Autowired
    private AlertManager alertManager;

    @PostMapping("/rules")
    public Result<Void> createAlertRule(@Validated @RequestBody AlertRequest request) {
        log.info("Creating alert rule: {}", request);
        alertManager.createAlertRule(request);
        return Result.success();
    }

    @GetMapping("/rules")
    public Result<List<AlertVO>> getAlertRules() {
        List<AlertVO> rules = alertManager.getAlertRules();
        return Result.success(rules);
    }

    @GetMapping("/active")
    public Result<List<AlertVO>> getActiveAlerts() {
        List<AlertVO> alerts = alertManager.getActiveAlerts();
        return Result.success(alerts);
    }

    @GetMapping("/history")
    public Result<List<AlertVO>> getAlertHistory(
            @RequestParam(required = false) String level,
            @RequestParam(required = false) Long startTime,
            @RequestParam(required = false) Long endTime) {
        List<AlertVO> alerts = alertManager.getAlertHistory(level, startTime, endTime);
        return Result.success(alerts);
    }

    @PostMapping("/{id}/acknowledge")
    public Result<Void> acknowledgeAlert(@PathVariable String id) {
        log.info("Acknowledging alert: {}", id);
        alertManager.acknowledgeAlert(id);
        return Result.success();
    }

    @PostMapping("/{id}/resolve")
    public Result<Void> resolveAlert(@PathVariable String id) {
        log.info("Resolving alert: {}", id);
        alertManager.resolveAlert(id);
        return Result.success();
    }

    @DeleteMapping("/rules/{id}")
    public Result<Void> deleteAlertRule(@PathVariable String id) {
        log.info("Deleting alert rule: {}", id);
        alertManager.deleteAlertRule(id);
        return Result.success();
    }
}

```



```java
package com.study.scheduler.api.controller.admin;

import com.study.common.util.Result;
import com.study.scheduler.core.manager.SystemManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Map;

@Slf4j
@RestController
@RequestMapping("/api/admin/system")
public class SystemController {

    @Autowired
    private SystemManager systemManager;

    @GetMapping("/nodes")
    public Result<List<Map<String, Object>>> getClusterNodes() {
        List<Map<String, Object>> nodes = systemManager.getClusterNodes();
        return Result.success(nodes);
    }

    @GetMapping("/config")
    public Result<Map<String, Object>> getSystemConfig() {
        Map<String, Object> config = systemManager.getSystemConfig();
        return Result.success(config);
    }

    @PutMapping("/config")
    public Result<Void> updateSystemConfig(@RequestBody Map<String, Object> config) {
        log.info("Updating system config: {}", config);
        systemManager.updateSystemConfig(config);
        return Result.success();
    }

    @PostMapping("/nodes/{nodeId}/offline")
    public Result<Void> offlineNode(@PathVariable String nodeId) {
        log.info("Taking node offline: {}", nodeId);
        systemManager.offlineNode(nodeId);
        return Result.success();
    }

    @PostMapping("/nodes/{nodeId}/online")
    public Result<Void> onlineNode(@PathVariable String nodeId) {
        log.info("Bringing node online: {}", nodeId);
        systemManager.onlineNode(nodeId);
        return Result.success();
    }

    @GetMapping("/status")
    public Result<Map<String, Object>> getSystemStatus() {
        Map<String, Object> status = systemManager.getSystemStatus();
        return Result.success(status);
    }

    @PostMapping("/maintenance/start")
    public Result<Void> startMaintenance() {
        log.info("Starting system maintenance mode");
        systemManager.startMaintenanceMode();
        return Result.success();
    }

    @PostMapping("/maintenance/stop")
    public Result<Void> stopMaintenance() {
        log.info("Stopping system maintenance mode");
        systemManager.stopMaintenanceMode();
        return Result.success();
    }

    @PostMapping("/cache/clear")
    public Result<Void> clearCache(@RequestParam(required = false) String type) {
        log.info("Clearing system cache, type: {}", type);
        systemManager.clearCache(type);
        return Result.success();
    }
}

```

现在我们开始实现API层的请求和响应模型。我先实现任务相关的请求模型：



```java
package com.study.scheduler.api.model.request.job;

import lombok.Data;
import jakarta.validation.constraints.NotBlank;
import jakarta.validation.constraints.NotNull;
import java.util.Map;

@Data
public class JobCreateRequest {
    @NotBlank(message = "Job name cannot be empty")
    private String name;
    
    private String description;
    
    @NotBlank(message = "Job type cannot be empty")
    private String jobType;
    
    private String cronExpression;
    
    private Long fixedDelay;
    
    private Long timeout;
    
    private Integer maxRetries;
    
    private Long retryInterval;
    
    private Map<String, Object> jobData;
}

@Data
public class JobUpdateRequest {
    private String name;
    private String description;
    private String cronExpression;
    private Long fixedDelay;
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private Map<String, Object> jobData;
}

@Data
public class JobQueryRequest {
    private String name;
    private String jobType;
    private String status;
    private Long startTime;
    private Long endTime;
    private Integer page;
    private Integer size;
}

@Data 
public class JobExecuteRequest {
    private Map<String, Object> parameters;
    private Boolean async = false;
    private Long timeout;
}

@Data
public class JobRegisterRequest extends JobCreateRequest {
    @NotNull(message = "Whether to enable job must be specified")
    private Boolean enabled = true;
    
    private Boolean replace = false;
}

@Data
public class BatchJobRequest {
    @NotNull(message = "Job list cannot be null")
    private List<JobCreateRequest> jobs;
}

```

需要我继续实现模板请求和监控告警相关的请求模型吗？
好的，继续实现模板和监控告警相关的请求模型：



```java
package com.study.scheduler.api.model.request.job;

import lombok.Data;
import jakarta.validation.constraints.NotBlank;
import jakarta.validation.constraints.NotNull;
import java.util.Map;
import java.util.List;

@Data
public class JobTemplateRequest {
    @NotBlank(message = "Template name cannot be empty")
    private String name;
    
    private String description;
    
    @NotBlank(message = "Template content cannot be empty")
    private String templateContent;
    
    private Map<String, String> variables;
    
    private List<String> tags;
}

package com.study.scheduler.api.model.request.monitor;

@Data
public class AlertRequest {
    @NotBlank(message = "Alert name cannot be empty")
    private String name;
    
    @NotBlank(message = "Alert level cannot be empty")
    private String level;
    
    @NotBlank(message = "Metric name cannot be empty")
    private String metricName;
    
    @NotNull(message = "Threshold cannot be null")
    private Double threshold;
    
    @NotBlank(message = "Operator cannot be empty")
    private String operator;
    
    private String description;
    
    private List<String> notifyChannels;
    
    private Map<String, String> labels;
    
    private Boolean enabled = true;
}

@Data
public class MetricsRequest {
    private String metricName;
    
    private List<String> dimensions;
    
    private Map<String, String> tags;
    
    private Long startTime;
    
    private Long endTime;
    
    private String aggregator;
    
    private Integer interval;
    
    private Integer page;
    
    private Integer size;
}

package com.study.scheduler.api.model.request.system;

@Data 
public class NodeRequest {
    @NotBlank(message = "Node ID cannot be empty")
    private String nodeId;
    
    private Map<String, Object> attributes;
    
    private List<String> tags;
    
    private Boolean enabled = true;
}

@Data
public class ConfigUpdateRequest {
    @NotNull(message = "Config items cannot be null")
    private Map<String, Object> configItems;
    
    private String operator;
    
    private String remark;
}

```

接下来实现视图对象（VO）模型：



```java
package com.study.scheduler.api.model.vo.job;

import lombok.Data;
import java.util.Date;
import java.util.Map;
import java.util.List;

@Data
public class JobVO {
    private String id;
    private String name;
    private String description;
    private String jobType;
    private String cronExpression;
    private Long fixedDelay;
    private String status;
    private Date nextFireTime;
    private Date lastFireTime;
    private Date createTime;
    private Date updateTime;
}

@Data
public class JobDetailVO extends JobVO {
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private Map<String, Object> jobData;
    private JobExecutionVO lastExecution;
    private JobStatisticsVO statistics;
}

@Data 
public class JobExecutionVO {
    private String id;
    private String jobId;
    private String nodeId;
    private Date startTime;
    private Date endTime;
    private String status;
    private String result;
    private String error;
    private Integer retryCount;
    private String traceId;
}

@Data
public class JobLogVO {
    private String id;
    private String executionId;
    private String jobId;
    private String logType;
    private String content;
    private Date createTime;
}

@Data
public class JobStatisticsVO {
    private Long totalExecutions;
    private Long successCount;
    private Long failureCount;
    private Double averageDuration;
    private Long lastSuccessTime;
    private Long lastFailureTime;
}

@Data
public class JobTemplateVO {
    private String id;
    private String name;
    private String description;
    private String templateContent;
    private Map<String, String> variables;
    private List<String> tags;
    private Date createTime;
    private Date updateTime;
}

package com.study.scheduler.api.model.vo.monitor;

@Data
public class AlertVO {
    private String id;
    private String name;
    private String level;
    private String metricName;
    private Double threshold;
    private String operator;
    private String description;
    private List<String> notifyChannels;
    private Map<String, String> labels;
    private Boolean enabled;
    private Date createTime;
    private Date updateTime;
}

@Data
public class MetricsVO {
    private String metricName;
    private Double value;
    private Map<String, String> tags;
    private Date timestamp;
}

package com.study.scheduler.api.model.vo.system;

@Data
public class NodeVO {
    private String nodeId;
    private String status;
    private Map<String, Object> attributes;
    private List<String> tags;
    private Date lastHeartbeat;
    private SystemMetricsVO metrics;
}

@Data
public class SystemMetricsVO {
    private Double cpuUsage;
    private Double memoryUsage;
    private Double diskUsage;
    private Integer activeThreads;
    private Integer queuedTasks;
    private Map<String, Object> customMetrics;
}

```

我们已经完成了API层的主要模型定义。接下来要实现Core层的组件吗？包括执行器、调度器、处理器和管理器等核心组件。好的，让我们开始实现Core层的组件，先从执行器(executor)开始：



```java
package com.study.scheduler.core.executor;

import com.study.scheduler.domain.entity.job.JobExecution;
import lombok.Data;
import java.util.Map;

public interface JobExecutor {
    String getType();
    
    ExecuteResult execute(ExecuteContext context);
    
    default void beforeExecute(ExecuteContext context) {}
    
    default void afterExecute(ExecuteContext context, ExecuteResult result) {}
    
    default boolean supports(String jobType) {
        return getType().equalsIgnoreCase(jobType);
    }
}

@Data
public class ExecuteContext {
    private String jobId;
    private String executionId;
    private String jobType;
    private Map<String, Object> jobData;
    private Map<String, Object> parameters;
    private Long timeout;
    private JobExecution execution;
}

@Data
public class ExecuteResult {
    private boolean success;
    private String result;
    private String error;
    private Long duration;
    private Map<String, Object> extraData;
    
    public static ExecuteResult success(String result) {
        ExecuteResult executeResult = new ExecuteResult();
        executeResult.setSuccess(true);
        executeResult.setResult(result);
        return executeResult;
    }
    
    public static ExecuteResult failure(String error) {
        ExecuteResult executeResult = new ExecuteResult();
        executeResult.setSuccess(false);
        executeResult.setError(error);
        return executeResult;
    }
}

@Slf4j
@Component
public class DefaultJobExecutor implements JobExecutor {
    
    @Override
    public String getType() {
        return "DEFAULT";
    }
    
    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            log.info("Executing job: {}", context.getJobId());
            String result = doExecute(context);
            return ExecuteResult.success(result);
        } catch (Exception e) {
            log.error("Job execution failed", e);
            return ExecuteResult.failure(e.getMessage());
        }
    }
    
    protected String doExecute(ExecuteContext context) {
        // Default implementation
        return "Job executed successfully";
    }
}

```



```java
package com.study.scheduler.core.executor;

import com.study.scheduler.core.handler.VariableHandler;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.*;
import org.springframework.stereotype.Component;
import org.springframework.web.client.RestTemplate;

import java.util.Map;

@Slf4j
@Component
public class HttpJobExecutor implements JobExecutor {

    @Autowired
    private RestTemplate restTemplate;
    
    @Autowired
    private VariableHandler variableHandler;

    @Override
    public String getType() {
        return "HTTP";
    }

    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            Map<String, Object> httpConfig = context.getJobData();
            
            // 处理变量
            String url = variableHandler.handleVariables(
                    httpConfig.get("url").toString(), 
                    context.getParameters()
            );
            
            // 构建请求
            HttpMethod method = HttpMethod.valueOf(
                    httpConfig.get("method").toString()
            );
            
            HttpHeaders headers = buildHeaders(httpConfig);
            
            Object body = httpConfig.get("body");
            
            HttpEntity<?> requestEntity = new HttpEntity<>(body, headers);
            
            // 发送请求
            ResponseEntity<String> response = restTemplate.exchange(
                    url,
                    method, 
                    requestEntity,
                    String.class
            );
            
            // 处理响应
            if (response.getStatusCode().is2xxSuccessful()) {
                return ExecuteResult.success(response.getBody());
            } else {
                return ExecuteResult.failure(
                    "HTTP request failed with status: " + response.getStatusCode()
                );
            }
            
        } catch (Exception e) {
            log.error("HTTP job execution failed", e);
            return ExecuteResult.failure(e.getMessage());
        }
    }
    
    private HttpHeaders buildHeaders(Map<String, Object> config) {
        HttpHeaders headers = new HttpHeaders();
        
        if (config.containsKey("headers")) {
            @SuppressWarnings("unchecked")
            Map<String, String> headerMap = (Map<String, String>) config.get("headers");
            headerMap.forEach((key, value) -> {
                String resolvedValue = variableHandler.handleVariables(value, null);
                headers.add(key, resolvedValue);
            });
        }
        
        return headers;
    }
}

```



```java
package com.study.scheduler.core.executor;

import lombok.extern.slf4j.Slf4j;
import org.apache.commons.io.IOUtils;
import org.springframework.stereotype.Component;
import java.nio.charset.StandardCharsets;
import java.util.Map;
import java.util.concurrent.*;

@Slf4j
@Component
public class ShellJobExecutor implements JobExecutor {

    private final ExecutorService executorService = Executors.newCachedThreadPool();

    @Override
    public String getType() {
        return "SHELL";
    }

    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            Map<String, Object> shellConfig = context.getJobData();
            String command = shellConfig.get("command").toString();
            
            // 处理工作目录
            String workDir = shellConfig.get("workDir") != null ? 
                    shellConfig.get("workDir").toString() : null;
                    
            // 处理环境变量
            @SuppressWarnings("unchecked")
            Map<String, String> env = shellConfig.get("env") != null ?
                    (Map<String, String>) shellConfig.get("env") : null;

            // 执行命令
            Process process = executeCommand(command, workDir, env);
            
            // 等待执行完成
            Future<String> outputFuture = captureOutput(process);
            Future<String> errorFuture = captureError(process);
            
            // 设置超时
            long timeout = context.getTimeout() != null ? 
                    context.getTimeout() : 60000L;
                    
            boolean completed = process.waitFor(timeout, TimeUnit.MILLISECONDS);
            
            if (!completed) {
                process.destroyForcibly();
                return ExecuteResult.failure("Command execution timed out");
            }

            // 获取执行结果
            int exitCode = process.exitValue();
            String output = outputFuture.get(5, TimeUnit.SECONDS);
            String error = errorFuture.get(5, TimeUnit.SECONDS);

            if (exitCode == 0) {
                return ExecuteResult.success(output);
            } else {
                return ExecuteResult.failure(error);
            }

        } catch (Exception e) {
            log.error("Shell job execution failed", e);
            return ExecuteResult.failure(e.getMessage());
        }
    }

    private Process executeCommand(String command, String workDir, Map<String, String> env) 
            throws IOException {
        ProcessBuilder builder = new ProcessBuilder();
        
        if (workDir != null) {
            builder.directory(new File(workDir));
        }
        
        if (env != null) {
            builder.environment().putAll(env);
        }
        
        builder.command("sh", "-c", command);
        return builder.start();
    }

    private Future<String> captureOutput(Process process) {
        return executorService.submit(() -> 
            IOUtils.toString(process.getInputStream(), StandardCharsets.UTF_8)
        );
    }

    private Future<String> captureError(Process process) {
        return executorService.submit(() ->
            IOUtils.toString(process.getErrorStream(), StandardCharsets.UTF_8)
        );
    }
}

```

需要我继续实现批量任务执行器(BatchJobExecutor)和调度器(scheduler)模块吗？好的，让我们继续实现批量执行器和调度器模块：



```java
package com.study.scheduler.core.executor;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import java.util.*;
import java.util.concurrent.*;

@Slf4j
@Component
public class BatchJobExecutor implements JobExecutor {
    
    @Autowired
    private List<JobExecutor> jobExecutors;
    
    private final ExecutorService executorService;
    
    public BatchJobExecutor() {
        this.executorService = new ThreadPoolExecutor(
            10, 20, 
            60L, TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(500),
            new ThreadFactoryBuilder().setNameFormat("batch-executor-%d").build(),
            new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }

    @Override
    public String getType() {
        return "BATCH";
    }

    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            @SuppressWarnings("unchecked")
            List<Map<String, Object>> batchTasks = (List<Map<String, Object>>) 
                    context.getJobData().get("tasks");

            // 提交所有任务
            List<Future<ExecuteResult>> futures = new ArrayList<>();
            for (Map<String, Object> taskConfig : batchTasks) {
                futures.add(submitTask(taskConfig, context));
            }

            // 收集执行结果
            List<ExecuteResult> results = new ArrayList<>();
            for (Future<ExecuteResult> future : futures) {
                try {
                    results.add(future.get(context.getTimeout(), TimeUnit.MILLISECONDS));
                } catch (TimeoutException e) {
                    future.cancel(true);
                    results.add(ExecuteResult.failure("Task execution timed out"));
                }
            }

            // 汇总结果
            return aggregateResults(results);

        } catch (Exception e) {
            log.error("Batch job execution failed", e);
            return ExecuteResult.failure("Batch execution failed: " + e.getMessage());
        }
    }

    private Future<ExecuteResult> submitTask(Map<String, Object> taskConfig, 
            ExecuteContext parentContext) {
        return executorService.submit(() -> {
            try {
                String jobType = taskConfig.get("jobType").toString();
                JobExecutor executor = findExecutor(jobType);
                
                ExecuteContext taskContext = new ExecuteContext();
                taskContext.setJobId(parentContext.getJobId() + "-" + UUID.randomUUID());
                taskContext.setJobType(jobType);
                taskContext.setJobData(taskConfig);
                taskContext.setParameters(parentContext.getParameters());
                taskContext.setTimeout(parentContext.getTimeout());
                
                return executor.execute(taskContext);
            } catch (Exception e) {
                log.error("Task execution failed", e);
                return ExecuteResult.failure(e.getMessage());
            }
        });
    }

    private JobExecutor findExecutor(String jobType) {
        return jobExecutors.stream()
                .filter(executor -> executor.supports(jobType))
                .findFirst()
                .orElseThrow(() -> new IllegalArgumentException(
                    "No executor found for job type: " + jobType));
    }

    private ExecuteResult aggregateResults(List<ExecuteResult> results) {
        boolean allSuccess = results.stream().allMatch(ExecuteResult::isSuccess);
        
        Map<String, Object> summary = new HashMap<>();
        summary.put("totalTasks", results.size());
        summary.put("successCount", results.stream()
                .filter(ExecuteResult::isSuccess).count());
        summary.put("failureCount", results.stream()
                .filter(r -> !r.isSuccess()).count());
        summary.put("details", results);

        if (allSuccess) {
            return ExecuteResult.success(
                String.format("All %d tasks completed successfully", results.size())
            ).setExtraData(summary);
        } else {
            return ExecuteResult.failure(
                String.format("Some tasks failed (%d/%d)", 
                    (int)summary.get("failureCount"), results.size())
            ).setExtraData(summary);
        }
    }
}

```



```java
package com.study.scheduler.core.scheduler;

import com.study.scheduler.domain.entity.job.JobDefinition;
import java.util.Date;

public interface JobScheduler {
    void scheduleJob(JobDefinition jobDef);
    
    void updateJob(JobDefinition jobDef);
    
    void deleteJob(String jobId);
    
    void pauseJob(String jobId);
    
    void resumeJob(String jobId);
    
    Date getNextFireTime(String jobId);
    
    boolean checkExists(String jobId);
}

package com.study.scheduler.core.scheduler.quartz;

import org.quartz.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import lombok.extern.slf4j.Slf4j;

@Slf4j
@Component
public class QuartzJobScheduler implements JobScheduler {

    @Autowired
    private Scheduler scheduler;

    @Override
    public void scheduleJob(JobDefinition jobDef) {
        try {
            JobDetail jobDetail = buildJobDetail(jobDef);
            Trigger trigger = buildTrigger(jobDef);
            
            if (checkExists(jobDef.getId())) {
                scheduler.deleteJob(new JobKey(jobDef.getId()));
            }
            
            scheduler.scheduleJob(jobDetail, trigger);
            log.info("Scheduled job: {}", jobDef.getId());
            
        } catch (SchedulerException e) {
            log.error("Failed to schedule job: " + jobDef.getId(), e);
            throw new RuntimeException("Failed to schedule job", e);
        }
    }

    @Override
    public void updateJob(JobDefinition jobDef) {
        try {
            TriggerKey triggerKey = new TriggerKey(jobDef.getId());
            
            // 更新触发器
            Trigger newTrigger = buildTrigger(jobDef);
            scheduler.rescheduleJob(triggerKey, newTrigger);
            
            // 更新任务数据
            JobDetail jobDetail = scheduler.getJobDetail(new JobKey(jobDef.getId()));
            jobDetail.getJobDataMap().put("jobData", jobDef.getJobData());
            scheduler.addJob(jobDetail, true);
            
            log.info("Updated job: {}", jobDef.getId());
            
        } catch (SchedulerException e) {
            log.error("Failed to update job: " + jobDef.getId(), e);
            throw new RuntimeException("Failed to update job", e);
        }
    }

    @Override
    public void deleteJob(String jobId) {
        try {
            scheduler.deleteJob(new JobKey(jobId));
            log.info("Deleted job: {}", jobId);
        } catch (SchedulerException e) {
            log.error("Failed to delete job: " + jobId, e);
            throw new RuntimeException("Failed to delete job", e);
        }
    }

    @Override
    public void pauseJob(String jobId) {
        try {
            scheduler.pauseJob(new JobKey(jobId));
            log.info("Paused job: {}", jobId);
        } catch (SchedulerException e) {
            log.error("Failed to pause job: " + jobId, e);
            throw new RuntimeException("Failed to pause job", e);
        }
    }

    @Override
    public void resumeJob(String jobId) {
        try {
            scheduler.resumeJob(new JobKey(jobId));
            log.info("Resumed job: {}", jobId);
        } catch (SchedulerException e) {
            log.error("Failed to resume job: " + jobId, e);
            throw new RuntimeException("Failed to resume job", e);
        }
    }

    @Override
    public Date getNextFireTime(String jobId) {
        try {
            Trigger trigger = scheduler.getTrigger(new TriggerKey(jobId));
            return trigger != null ? trigger.getNextFireTime() : null;
        } catch (SchedulerException e) {
            log.error("Failed to get next fire time for job: " + jobId, e);
            throw new RuntimeException("Failed to get next fire time", e);
        }
    }

    @Override
    public boolean checkExists(String jobId) {
        try {
            return scheduler.checkExists(new JobKey(jobId));
        } catch (SchedulerException e) {
            log.error("Failed to check job existence: " + jobId, e);
            throw new RuntimeException("Failed to check job existence", e);
        }
    }

    private JobDetail buildJobDetail(JobDefinition jobDef) {
        return JobBuilder.newJob(QuartzJobAdapter.class)
                .withIdentity(jobDef.getId())
                .withDescription(jobDef.getDescription())
                .usingJobData("jobType", jobDef.getJobType())
                .usingJobData("jobData", jobDef.getJobData())
                .storeDurably()
                .build();
    }

    private Trigger buildTrigger(JobDefinition jobDef) {
        TriggerBuilder<Trigger> builder = TriggerBuilder.newTrigger()
                .withIdentity(jobDef.getId());

        // 处理CRON表达式
        if (jobDef.getCronExpression() != null) {
            builder.withSchedule(CronScheduleBuilder.cronSchedule(jobDef.getCronExpression())
                    .withMisfireHandlingInstructionFireAndProceed());
        } 
        // 处理固定延迟
        else if (jobDef.getFixedDelay() != null) {
            builder.withSchedule(SimpleScheduleBuilder.simpleSchedule()
                    .withIntervalInMilliseconds(jobDef.getFixedDelay())
                    .repeatForever()
                    .withMisfireHandlingInstructionNextWithExistingCount());
        }
        
        return builder.build();
    }
}

```

需要我继续实现Quartz任务适配器(QuartzJobAdapter)和处理器(handler)模块吗？好的，让我们先实现Quartz任务适配器，然后是处理器模块：



```java
package com.study.scheduler.core.scheduler.quartz;

import com.study.scheduler.core.executor.ExecuteContext;
import com.study.scheduler.core.executor.ExecuteResult;
import com.study.scheduler.core.executor.JobExecutor;
import com.study.scheduler.core.manager.ExecutionManager;
import com.study.scheduler.domain.entity.job.JobExecution;
import lombok.extern.slf4j.Slf4j;
import org.quartz.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;

import java.util.Date;
import java.util.Map;
import java.util.UUID;

@Slf4j
@PersistJobDataAfterExecution
@DisallowConcurrentExecution
public class QuartzJobAdapter implements Job {

    @Autowired
    private ApplicationContext applicationContext;

    @Autowired
    private ExecutionManager executionManager;

    @Override
    public void execute(JobExecutionContext context) throws JobExecutionException {
        JobDataMap dataMap = context.getJobDetail().getJobDataMap();
        String jobType = dataMap.getString("jobType");
        String jobId = context.getJobDetail().getKey().getName();
        
        @SuppressWarnings("unchecked")
        Map<String, Object> jobData = (Map<String, Object>) dataMap.get("jobData");

        // 创建执行记录
        JobExecution execution = createExecution(jobId);

        try {
            // 获取执行器
            JobExecutor executor = findExecutor(jobType);

            // 构建执行上下文
            ExecuteContext executeContext = buildExecuteContext(jobId, jobType, jobData, execution);

            // 执行任务
            executor.beforeExecute(executeContext);
            ExecuteResult result = executor.execute(executeContext);
            executor.afterExecute(executeContext, result);

            // 更新执行记录
            updateExecution(execution, result);

        } catch (Exception e) {
            log.error("Job execution failed: " + jobId, e);
            failExecution(execution, e);
            throw new JobExecutionException(e);
        }
    }

    private JobExecutor findExecutor(String jobType) {
        Map<String, JobExecutor> executors = applicationContext.getBeansOfType(JobExecutor.class);
        return executors.values().stream()
                .filter(executor -> executor.supports(jobType))
                .findFirst()
                .orElseThrow(() -> new IllegalArgumentException(
                    "No executor found for job type: " + jobType));
    }

    private JobExecution createExecution(String jobId) {
        JobExecution execution = new JobExecution();
        execution.setId(UUID.randomUUID().toString());
        execution.setJobId(jobId);
        execution.setNodeId(getNodeId());
        execution.setStartTime(new Date());
        execution.setStatus("RUNNING");
        return executionManager.saveExecution(execution);
    }

    private ExecuteContext buildExecuteContext(String jobId, String jobType,
            Map<String, Object> jobData, JobExecution execution) {
        ExecuteContext context = new ExecuteContext();
        context.setJobId(jobId);
        context.setExecutionId(execution.getId());
        context.setJobType(jobType);
        context.setJobData(jobData);
        context.setExecution(execution);
        return context;
    }

    private void updateExecution(JobExecution execution, ExecuteResult result) {
        execution.setEndTime(new Date());
        execution.setStatus(result.isSuccess() ? "SUCCESS" : "FAILED");
        execution.setResult(result.getResult());
        execution.setError(result.getError());
        executionManager.saveExecution(execution);
    }

    private void failExecution(JobExecution execution, Exception e) {
        execution.setEndTime(new Date());
        execution.setStatus("FAILED");
        execution.setError(e.getMessage());
        executionManager.saveExecution(execution);
    }

    private String getNodeId() {
        return System.getenv().getOrDefault("HOSTNAME", "unknown");
    }
}

```



```java
package com.study.scheduler.core.handler;

import com.study.scheduler.extension.variable.provider.VariableProvider;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import java.util.List;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

@Component
public class VariableHandler {

    private static final Pattern VARIABLE_PATTERN = Pattern.compile("\\$\\{([^}]+)}");

    @Autowired
    private List<VariableProvider> providers;

    public String handleVariables(String content, Map<String, Object> parameters) {
        if (content == null) {
            return null;
        }

        StringBuffer result = new StringBuffer();
        Matcher matcher = VARIABLE_PATTERN.matcher(content);

        while (matcher.find()) {
            String variable = matcher.group(1);
            String value = resolveVariable(variable, parameters);
            matcher.appendReplacement(result, Matcher.quoteReplacement(value));
        }
        matcher.appendTail(result);

        return result.toString();
    }

    private String resolveVariable(String variable, Map<String, Object> parameters) {
        // 处理参数变量
        if (parameters != null && parameters.containsKey(variable)) {
            return String.valueOf(parameters.get(variable));
        }

        // 处理提供者变量
        String[] parts = variable.split(":", 2);
        String providerName = parts[0];
        String key = parts.length > 1 ? parts[1] : "";

        return providers.stream()
                .filter(p -> p.supports(providerName))
                .findFirst()
                .map(p -> p.getValue(key))
                .orElse(variable);
    }
}

@Component
public class ParamHandler {

    private static final Pattern EXPRESSION_PATTERN = Pattern.compile("\\$\\{([^}]+)}");

    public Map<String, Object> handleParameters(Map<String, Object> template,
            Map<String, Object> parameters) {
        Map<String, Object> result = new HashMap<>();
        
        template.forEach((key, value) -> {
            if (value instanceof String) {
                result.put(key, handleStringValue((String) value, parameters));
            } else if (value instanceof Map) {
                @SuppressWarnings("unchecked")
                Map<String, Object> nestedMap = (Map<String, Object>) value;
                result.put(key, handleParameters(nestedMap, parameters));
            } else if (value instanceof List) {
                result.put(key, handleList((List<?>) value, parameters));
            } else {
                result.put(key, value);
            }
        });

        return result;
    }

    private String handleStringValue(String value, Map<String, Object> parameters) {
        Matcher matcher = EXPRESSION_PATTERN.matcher(value);
        StringBuffer result = new StringBuffer();

        while (matcher.find()) {
            String expression = matcher.group(1);
            Object paramValue = evaluateExpression(expression, parameters);
            matcher.appendReplacement(result, 
                    Matcher.quoteReplacement(String.valueOf(paramValue)));
        }
        matcher.appendTail(result);

        return result.toString();
    }

    private List<Object> handleList(List<?> list, Map<String, Object> parameters) {
        return list.stream()
                .map(item -> {
                    if (item instanceof String) {
                        return handleStringValue((String) item, parameters);
                    } else if (item instanceof Map) {
                        @SuppressWarnings("unchecked")
                        Map<String, Object> map = (Map<String, Object>) item;
                        return handleParameters(map, parameters);
                    } else {
                        return item;
                    }
                })
                .collect(Collectors.toList());
    }

    private Object evaluateExpression(String expression, Map<String, Object> parameters) {
        // 支持点号访问嵌套属性
        String[] parts = expression.split("\\.");
        Object current = parameters;

        for (String part : parts) {
            if (current instanceof Map) {
                @SuppressWarnings("unchecked")
                Map<String, Object> map = (Map<String, Object>) current;
                current = map.get(part);
            } else {
                return null;
            }
        }

        return current != null ? current : expression;
    }
}

```

接下来需要我实现管理器(manager)模块吗？包括JobManager、ExecutionManager等核心管理组件。好的，让我们实现管理器(manager)模块的核心组件：



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.api.model.request.job.JobRegisterRequest;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.scheduler.JobScheduler;
import com.study.scheduler.domain.entity.job.JobDefinition;
import com.study.scheduler.domain.repository.JobRepository;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

@Slf4j
@Component
public class JobManager {

    @Autowired
    private JobRepository jobRepository;

    @Autowired
    private JobScheduler jobScheduler;

    @Autowired
    private ExecutionManager executionManager;

    @Transactional
    public JobVO registerJob(JobRegisterRequest request) {
        log.info("Registering job: {}", request);
        
        // 创建任务定义
        JobDefinition jobDef = createJobDefinition(request);
        
        // 保存到数据库
        jobDef = jobRepository.save(jobDef);
        
        // 如果启用则调度任务
        if (request.getEnabled()) {
            scheduleJob(jobDef);
        }
        
        return convertToJobVO(jobDef);
    }

    @Transactional
    public List<JobVO> batchRegisterJobs(List<JobRegisterRequest> requests) {
        List<JobVO> results = new ArrayList<>();
        
        for (JobRegisterRequest request : requests) {
            try {
                JobVO job = registerJob(request);
                results.add(job);
            } catch (Exception e) {
                log.error("Failed to register job: " + request, e);
                // 继续处理其他任务
            }
        }
        
        return results;
    }

    @Transactional
    public void enableJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if ("DISABLED".equals(jobDef.getStatus())) {
            jobDef.setStatus("ENABLED");
            jobRepository.save(jobDef);
            scheduleJob(jobDef);
        }
    }

    @Transactional
    public void disableJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if ("ENABLED".equals(jobDef.getStatus())) {
            jobDef.setStatus("DISABLED");
            jobRepository.save(jobDef);
            jobScheduler.deleteJob(jobId);
        }
    }

    public List<String> getSupportedJobTypes() {
        return Arrays.asList("HTTP", "SHELL", "BATCH", "DEFAULT");
    }

    private JobDefinition createJobDefinition(JobRegisterRequest request) {
        JobDefinition jobDef = new JobDefinition();
        jobDef.setId(UUID.randomUUID().toString());
        jobDef.setName(request.getName());
        jobDef.setDescription(request.getDescription());
        jobDef.setJobType(request.getJobType());
        jobDef.setCronExpression(request.getCronExpression());
        jobDef.setFixedDelay(request.getFixedDelay());
        jobDef.setTimeout(request.getTimeout());
        jobDef.setMaxRetries(request.getMaxRetries());
        jobDef.setRetryInterval(request.getRetryInterval());
        jobDef.setJobData(request.getJobData());
        jobDef.setStatus(request.getEnabled() ? "ENABLED" : "DISABLED");
        jobDef.setCreateTime(new Date());
        jobDef.setUpdateTime(new Date());
        return jobDef;
    }

    private void scheduleJob(JobDefinition jobDef) {
        try {
            jobScheduler.scheduleJob(jobDef);
        } catch (Exception e) {
            log.error("Failed to schedule job: " + jobDef.getId(), e);
            jobDef.setStatus("SCHEDULE_FAILED");
            jobRepository.save(jobDef);
            throw e;
        }
    }

    private JobDefinition getJobDefinition(String jobId) {
        return jobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
    }

    private JobVO convertToJobVO(JobDefinition jobDef) {
        JobVO vo = new JobVO();
        vo.setId(jobDef.getId());
        vo.setName(jobDef.getName());
        vo.setDescription(jobDef.getDescription());
        vo.setJobType(jobDef.getJobType());
        vo.setCronExpression(jobDef.getCronExpression());
        vo.setFixedDelay(jobDef.getFixedDelay());
        vo.setStatus(jobDef.getStatus());
        vo.setNextFireTime(jobScheduler.getNextFireTime(jobDef.getId()));
        vo.setCreateTime(jobDef.getCreateTime());
        vo.setUpdateTime(jobDef.getUpdateTime());
        return vo;
    }
}

```



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.domain.entity.job.JobExecution;
import com.study.scheduler.domain.entity.job.JobLog;
import com.study.scheduler.domain.repository.ExecutionRepository;
import com.study.scheduler.domain.repository.JobLogRepository;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.Date;
import java.util.List;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

@Slf4j
@Component
public class ExecutionManager {

    @Autowired
    private ExecutionRepository executionRepository;
    
    @Autowired
    private JobLogRepository jobLogRepository;

    // 执行中的任务缓存
    private final ConcurrentMap<String, JobExecution> runningExecutions = new ConcurrentHashMap<>();

    @Transactional
    public JobExecution saveExecution(JobExecution execution) {
        execution = executionRepository.save(execution);
        
        if ("RUNNING".equals(execution.getStatus())) {
            runningExecutions.put(execution.getId(), execution);
        } else {
            runningExecutions.remove(execution.getId());
        }
        
        return execution;
    }

    @Transactional
    public void logExecution(String executionId, String logType, String content) {
        JobLog log = new JobLog();
        log.setId(UUID.randomUUID().toString());
        log.setExecutionId(executionId);
        log.setLogType(logType);
        log.setContent(content);
        log.setCreateTime(new Date());
        jobLogRepository.save(log);
    }

    public JobExecution getExecution(String executionId) {
        // 先查缓存
        JobExecution execution = runningExecutions.get(executionId);
        if (execution != null) {
            return execution;
        }
        
        // 再查数据库
        return executionRepository.findById(executionId).orElse(null);
    }

    public List<JobExecution> getJobExecutions(String jobId) {
        return executionRepository.findByJobId(jobId);
    }

    public List<JobLog> getExecutionLogs(String executionId) {
        return jobLogRepository.findByExecutionId(executionId);
    }

    public boolean isJobRunning(String jobId) {
        return runningExecutions.values().stream()
                .anyMatch(e -> e.getJobId().equals(jobId));
    }

    @Transactional
    public void cleanupExecutions(Date before) {
        log.info("Cleaning up executions before: {}", before);
        
        // 清理执行记录
        int execCount = executionRepository.deleteByEndTimeBefore(before);
        
        // 清理日志记录
        int logCount = jobLogRepository.deleteByCreateTimeBefore(before);
        
        log.info("Cleaned up {} executions and {} logs", execCount, logCount);
    }

    public void registerExecutionCallback(String executionId, Runnable callback) {
        JobExecution execution = getExecution(executionId);
        if (execution != null && !"RUNNING".equals(execution.getStatus())) {
            callback.run();
        } else {
            // 将回调添加到监听列表
            getCallbacks(executionId).add(callback);
        }
    }

    public void handleExecutionComplete(String executionId) {
        // 触发所有注册的回调
        List<Runnable> callbacks = getCallbacks(executionId);
        callbacks.forEach(callback -> {
            try {
                callback.run();
            } catch (Exception e) {
                log.error("Execution callback failed", e);
            }
        });
        callbacks.clear();
    }

    private List<Runnable> getCallbacks(String executionId) {
        return executionCallbacks.computeIfAbsent(executionId, k -> new ArrayList<>());
    }

    private final ConcurrentMap<String, List<Runnable>> executionCallbacks = new ConcurrentHashMap<>();
}

```

要继续实现JobTemplateManager和AlertManager吗？好的，让我们继续实现模板管理和告警管理组件：



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.api.model.request.job.JobTemplateRequest;
import com.study.scheduler.api.model.vo.job.JobTemplateVO;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.handler.VariableHandler;
import com.study.scheduler.domain.entity.job.JobTemplate;
import com.study.scheduler.domain.repository.JobTemplateRepository;
import com.study.scheduler.extension.template.TemplateEngine;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

@Slf4j
@Component
public class JobTemplateManager {

    @Autowired
    private JobTemplateRepository templateRepository;

    @Autowired
    private JobManager jobManager;

    @Autowired
    private TemplateEngine templateEngine;

    @Autowired
    private VariableHandler variableHandler;

    @Transactional
    public JobTemplateVO createTemplate(JobTemplateRequest request) {
        validateTemplate(request.getTemplateContent());

        JobTemplate template = new JobTemplate();
        template.setId(UUID.randomUUID().toString());
        template.setName(request.getName());
        template.setDescription(request.getDescription());
        template.setTemplateContent(request.getTemplateContent());
        template.setVariables(request.getVariables());
        template.setCreateTime(new Date());
        template.setUpdateTime(new Date());

        template = templateRepository.save(template);
        return convertToTemplateVO(template);
    }

    @Transactional
    public JobTemplateVO updateTemplate(String id, JobTemplateRequest request) {
        JobTemplate template = getTemplate(id);
        validateTemplate(request.getTemplateContent());

        template.setName(request.getName());
        template.setDescription(request.getDescription());
        template.setTemplateContent(request.getTemplateContent());
        template.setVariables(request.getVariables());
        template.setUpdateTime(new Date());

        template = templateRepository.save(template);
        return convertToTemplateVO(template);
    }

    @Transactional
    public void deleteTemplate(String id) {
        templateRepository.deleteById(id);
    }

    public JobTemplateVO getTemplate(String id) {
        JobTemplate template = findTemplate(id);
        return convertToTemplateVO(template);
    }

    public List<JobTemplateVO> listTemplates() {
        return templateRepository.findAll().stream()
                .map(this::convertToTemplateVO)
                .toList();
    }

    @Transactional
    public JobVO applyTemplate(String templateId, Map<String, Object> variables) {
        // 获取模板
        JobTemplate template = findTemplate(templateId);
        
        // 验证必需变量
        validateVariables(template, variables);
        
        // 解析模板
        String processedContent = templateEngine.process(
            template.getTemplateContent(), 
            variables
        );
        
        // 转换为任务请求
        JobRegisterRequest jobRequest = convertToJobRequest(processedContent);
        
        // 注册任务
        return jobManager.registerJob(jobRequest);
    }

    public Map<String, String> getTemplateVariables(String templateId) {
        JobTemplate template = findTemplate(templateId);
        return template.getVariables();
    }

    private void validateTemplate(String templateContent) {
        try {
            templateEngine.validate(templateContent);
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid template content: " + e.getMessage());
        }
    }

    private void validateVariables(JobTemplate template, Map<String, Object> variables) {
        Set<String> requiredVars = new HashSet<>(template.getVariables().keySet());
        requiredVars.removeAll(variables.keySet());
        
        if (!requiredVars.isEmpty()) {
            throw new IllegalArgumentException(
                "Missing required variables: " + String.join(", ", requiredVars));
        }
    }

    private JobTemplate findTemplate(String id) {
        return templateRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Template not found: " + id));
    }

    private JobRegisterRequest convertToJobRequest(String content) {
        try {
            return objectMapper.readValue(content, JobRegisterRequest.class);
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid job configuration: " + e.getMessage());
        }
    }

    private JobTemplateVO convertToTemplateVO(JobTemplate template) {
        JobTemplateVO vo = new JobTemplateVO();
        vo.setId(template.getId());
        vo.setName(template.getName());
        vo.setDescription(template.getDescription());
        vo.setTemplateContent(template.getTemplateContent());
        vo.setVariables(template.getVariables());
        vo.setCreateTime(template.getCreateTime());
        vo.setUpdateTime(template.getUpdateTime());
        return vo;
    }
}

```



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.api.model.request.monitor.AlertRequest;
import com.study.scheduler.api.model.vo.monitor.AlertVO;
import com.study.scheduler.domain.entity.monitor.AlertRecord;
import com.study.scheduler.domain.repository.AlertRepository;
import com.study.scheduler.core.mq.producer.AlertProducer;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;
import java.util.concurrent.TimeUnit;

@Slf4j
@Component
public class AlertManager {

    private static final String ALERT_RULE_KEY = "scheduler:alert:rule:";
    private static final String ALERT_SILENCE_KEY = "scheduler:alert:silence:";

    @Autowired
    private AlertRepository alertRepository;

    @Autowired
    private AlertProducer alertProducer;

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    @Transactional
    public void createAlertRule(AlertRequest request) {
        validateRule(request);

        AlertRecord rule = new AlertRecord();
        rule.setId(UUID.randomUUID().toString());
        rule.setName(request.getName());
        rule.setLevel(request.getLevel());
        rule.setMetricName(request.getMetricName());
        rule.setThreshold(request.getThreshold());
        rule.setOperator(request.getOperator());
        rule.setDescription(request.getDescription());
        rule.setNotifyChannels(request.getNotifyChannels());
        rule.setLabels(request.getLabels());
        rule.setEnabled(request.getEnabled());
        rule.setCreateTime(new Date());
        rule.setUpdateTime(new Date());

        rule = alertRepository.save(rule);
        cacheAlertRule(rule);
    }

    public List<AlertVO> getAlertRules() {
        return alertRepository.findAll().stream()
                .map(this::convertToAlertVO)
                .toList();
    }

    public List<AlertVO> getActiveAlerts() {
        return alertRepository.findByStatus("ACTIVE").stream()
                .map(this::convertToAlertVO)
                .toList();
    }

    public List<AlertVO> getAlertHistory(String level, Long startTime, Long endTime) {
        return alertRepository.findAlertHistory(level, new Date(startTime), new Date(endTime))
                .stream()
                .map(this::convertToAlertVO)
                .toList();
    }

    @Transactional
    public void handleAlert(String metricName, double value, Map<String, String> labels) {
        // 查找匹配的规则
        List<AlertRecord> rules = findMatchingRules(metricName, labels);
        
        for (AlertRecord rule : rules) {
            if (isThresholdExceeded(rule, value)) {
                // 检查是否在静默期
                if (!isSilenced(rule.getId())) {
                    // 创建新告警
                    createAlert(rule, value);
                }
            }
        }
    }

    @Transactional
    public void acknowledgeAlert(String alertId) {
        AlertRecord alert = findAlert(alertId);
        
        // 更新状态
        alert.setStatus("ACKNOWLEDGED");
        alert.setUpdateTime(new Date());
        alertRepository.save(alert);
        
        // 设置静默期
        setSilenced(alert.getId(), alert.getSilenceDuration());
    }

    @Transactional
    public void resolveAlert(String alertId) {
        AlertRecord alert = findAlert(alertId);
        
        // 更新状态
        alert.setStatus("RESOLVED");
        alert.setUpdateTime(new Date());
        alertRepository.save(alert);
        
        // 发送恢复通知
        sendRecoveryNotification(alert);
    }

    private void validateRule(AlertRequest request) {
        // 验证阈值运算符
        if (!Arrays.asList(">", ">=", "<", "<=", "==").contains(request.getOperator())) {
            throw new IllegalArgumentException("Invalid operator: " + request.getOperator());
        }
        
        // 验证告警级别
        if (!Arrays.asList("INFO", "WARNING", "ERROR", "CRITICAL").contains(request.getLevel())) {
            throw new IllegalArgumentException("Invalid alert level: " + request.getLevel());
        }
    }

    private void cacheAlertRule(AlertRecord rule) {
        String key = ALERT_RULE_KEY + rule.getMetricName();
        redisTemplate.opsForList().rightPush(key, rule);
    }

    private List<AlertRecord> findMatchingRules(String metricName, Map<String, String> labels) {
        String key = ALERT_RULE_KEY + metricName;
        List<Object> rules = redisTemplate.opsForList().range(key, 0, -1);
        
        return rules.stream()
                .map(obj -> (AlertRecord) obj)
                .filter(rule -> matchLabels(rule.getLabels(), labels))
                .filter(AlertRecord::getEnabled)
                .toList();
    }

    private boolean matchLabels(Map<String, String> ruleLabels, Map<String, String> targetLabels) {
        return ruleLabels.entrySet().stream()
                .allMatch(entry -> 
                    targetLabels.containsKey(entry.getKey()) && 
                    targetLabels.get(entry.getKey()).equals(entry.getValue())
                );
    }

    private boolean isThresholdExceeded(AlertRecord rule, double value) {
        return switch (rule.getOperator()) {
            case ">" -> value > rule.getThreshold();
            case ">=" -> value >= rule.getThreshold();
            case "<" -> value < rule.getThreshold();
            case "<=" -> value <= rule.getThreshold();
            case "==" -> value == rule.getThreshold();
            default -> false;
        };
    }

    private boolean isSilenced(String alertId) {
        return redisTemplate.hasKey(ALERT_SILENCE_KEY + alertId);
    }

    private void setSilenced(String alertId, long duration) {
        redisTemplate.opsForValue().set(
            ALERT_SILENCE_KEY + alertId,
            "SILENCED",
            duration,
            TimeUnit.SECONDS
        );
    }

    private void createAlert(AlertRecord rule, double value) {
        AlertRecord alert = new AlertRecord();
        alert.setId(UUID.randomUUID().toString());
        alert.setRuleId(rule.getId());
        alert.setName(rule.getName());
        alert.setLevel(rule.getLevel());
        alert.setMetricName(rule.getMetricName());
        alert.setThreshold(rule.getThreshold());
        alert.setValue(value);
        alert.setStatus("ACTIVE");
        alert.setCreateTime(new Date());
        
        alert = alertRepository.save(alert);
        
        // 发送告警通知
        sendAlertNotification(alert);
    }

    private void sendAlertNotification(AlertRecord alert) {
        alert.getNotifyChannels().forEach(channel -> {
            try {
                alertProducer.sendAlert(channel, alert);
            } catch (Exception e) {
                log.error("Failed to send alert notification", e);
            }
        });
    }

    private void sendRecoveryNotification(AlertRecord alert) {
        alert.getNotifyChannels().forEach(channel -> {
            try {
                alertProducer.sendRecovery(channel, alert);
            } catch (Exception e) {
                log.error("Failed to send recovery notification", e);
            }
        });
    }

    private AlertRecord findAlert(String alertId) {
        return alertRepository.findById(alertId)
                .orElseThrow(() -> new IllegalArgumentException("Alert not found: " + alertId));
    }

    private AlertVO convertToAlertVO(AlertRecord alert) {
        AlertVO vo = new AlertVO();
        vo.setId(alert.getId());
        vo.setName(alert.getName());
        vo.setLevel(alert.getLevel());
        vo.setMetricName(alert.getMetricName());
        vo.setThreshold(alert.getThreshold());
        vo.setOperator(alert.getOperator());
        vo.setDescription(alert.getDescription());
        vo.setNotifyChannels(alert.getNotifyChannels());
        vo.setLabels(alert.getLabels());
        vo.setEnabled(alert.getEnabled());
        vo.setCreateTime(alert.getCreateTime());
        vo.setUpdateTime(alert.getUpdateTime());
        return vo;
    }
}

```

需要我继续实现Domain层的实体和仓储接口吗？好的，让我们实现Domain层的实体和仓储接口，从核心任务实体开始：



```java
package com.study.scheduler.domain.entity.job;

import lombok.Data;
import java.util.Date;
import java.util.Map;

@Data
public class JobDefinition {
    private String id;
    private String name;
    private String description;
    private String jobType;
    private String cronExpression;
    private Long fixedDelay;
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private Map<String, Object> jobData;
    private String status;
    private Date createTime;
    private Date updateTime;

    public boolean isEnabled() {
        return "ENABLED".equals(status);
    }

    public boolean canRetry() {
        return maxRetries != null && maxRetries > 0;
    }
}

@Data
public class JobExecution {
    private String id;
    private String jobId;
    private String nodeId;
    private Date startTime;
    private Date endTime;
    private String status;
    private String result;
    private String error;
    private Integer retryCount;
    private String traceId;
    private Date createTime;
    private Date updateTime;

    public boolean isCompleted() {
        return "SUCCESS".equals(status) || "FAILED".equals(status);
    }

    public long getDuration() {
        if (startTime != null && endTime != null) {
            return endTime.getTime() - startTime.getTime();
        }
        return 0;
    }
}

@Data
public class JobLog {
    private String id;
    private String executionId;
    private String jobId;
    private String logType;
    private String content;
    private Date createTime;
}

@Data
public class JobTemplate {
    private String id;
    private String name;
    private String description;
    private String templateContent;
    private Map<String, String> variables;
    private String tags;
    private Date createTime;
    private Date updateTime;
}

package com.study.scheduler.domain.entity.monitor;

@Data
public class AlertRecord {
    private String id;
    private String ruleId;
    private String name;
    private String level;
    private String metricName;
    private Double threshold;
    private Double value;
    private String operator;
    private String description;
    private List<String> notifyChannels;
    private Map<String, String> labels;
    private Boolean enabled;
    private String status;
    private Long silenceDuration;
    private Date createTime;
    private Date updateTime;
}

@Data
public class MetricsRecord {
    private String id;
    private String metricName;
    private Double value;
    private String nodeId;
    private Map<String, String> tags;
    private Date timestamp;
    private Date createTime;
}

```

接下来是仓储接口定义：



```java
package com.study.scheduler.domain.repository;

import com.study.scheduler.domain.entity.job.JobDefinition;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import java.util.List;
import java.util.Date;

public interface JobRepository extends JpaRepository<JobDefinition, String> {
    
    List<JobDefinition> findByStatus(String status);
    
    List<JobDefinition> findByJobType(String jobType);
    
    @Query("SELECT j FROM JobDefinition j WHERE " +
           "(:name IS NULL OR j.name LIKE %:name%) AND " +
           "(:jobType IS NULL OR j.jobType = :jobType) AND " +
           "(:status IS NULL OR j.status = :status) AND " +
           "j.createTime BETWEEN :startTime AND :endTime")
    List<JobDefinition> findJobs(
        @Param("name") String name,
        @Param("jobType") String jobType,
        @Param("status") String status,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
    
    @Query("SELECT COUNT(j) FROM JobDefinition j WHERE j.status = :status")
    long countByStatus(@Param("status") String status);
}

public interface ExecutionRepository extends JpaRepository<JobExecution, String> {
    
    List<JobExecution> findByJobId(String jobId);
    
    List<JobExecution> findByStatus(String status);
    
    List<JobExecution> findByJobIdAndStatus(String jobId, String status);
    
    @Query("SELECT e FROM JobExecution e WHERE " +
           "e.jobId = :jobId AND e.startTime BETWEEN :startTime AND :endTime")
    List<JobExecution> findExecutions(
        @Param("jobId") String jobId,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
    
    int deleteByEndTimeBefore(Date time);
}

public interface JobLogRepository extends JpaRepository<JobLog, String> {
    
    List<JobLog> findByExecutionId(String executionId);
    
    List<JobLog> findByJobId(String jobId);
    
    List<JobLog> findByLogType(String logType);
    
    @Query("SELECT l FROM JobLog l WHERE " +
           "l.jobId = :jobId AND l.createTime BETWEEN :startTime AND :endTime")
    List<JobLog> findLogs(
        @Param("jobId") String jobId,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
    
    int deleteByCreateTimeBefore(Date time);
}

public interface JobTemplateRepository extends JpaRepository<JobTemplate, String> {
    
    List<JobTemplate> findByNameContaining(String name);
    
    @Query("SELECT t FROM JobTemplate t WHERE " + 
           "t.tags LIKE %:tag%")
    List<JobTemplate> findByTag(@Param("tag") String tag);
}

public interface AlertRepository extends JpaRepository<AlertRecord, String> {
    
    List<AlertRecord> findByLevel(String level);
    
    List<AlertRecord> findByStatus(String status);
    
    List<AlertRecord> findByRuleId(String ruleId);
    
    @Query("SELECT a FROM AlertRecord a WHERE " +
           "(:level IS NULL OR a.level = :level) AND " +
           "a.createTime BETWEEN :startTime AND :endTime")
    List<AlertRecord> findAlertHistory(
        @Param("level") String level,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
}

public interface MetricsRepository extends JpaRepository<MetricsRecord, String> {
    
    List<MetricsRecord> findByMetricName(String metricName);
    
    List<MetricsRecord> findByNodeId(String nodeId);
    
    @Query("SELECT m FROM MetricsRecord m WHERE " +
           "m.metricName = :metricName AND " +
           "m.timestamp BETWEEN :startTime AND :endTime")
    List<MetricsRecord> findMetricsHistory(
        @Param("metricName") String metricName,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
}

```

需要我继续实现Domain层的服务类(DomainService)吗？这些服务类包含了核心的业务逻辑。好的，让我们实现Domain层的服务类，先从任务相关的领域服务开始：



```java
package com.study.scheduler.domain.service;

import com.study.scheduler.api.model.request.job.*;
import com.study.scheduler.api.model.vo.job.*;
import com.study.scheduler.core.scheduler.JobScheduler;
import com.study.scheduler.domain.entity.job.*;
import com.study.scheduler.domain.repository.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

@Slf4j
@Service
public class JobDomainService {

    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private JobLogRepository jobLogRepository;
    
    @Autowired
    private JobScheduler jobScheduler;
    
    @Autowired
    private ExecutionDomainService executionService;

    @Transactional
    public JobVO createJob(JobCreateRequest request) {
        // 校验请求
        validateJobRequest(request);
        
        // 创建任务定义
        JobDefinition jobDef = new JobDefinition();
        jobDef.setId(UUID.randomUUID().toString());
        jobDef.setName(request.getName());
        jobDef.setDescription(request.getDescription());
        jobDef.setJobType(request.getJobType());
        jobDef.setCronExpression(request.getCronExpression());
        jobDef.setFixedDelay(request.getFixedDelay());
        jobDef.setTimeout(request.getTimeout());
        jobDef.setMaxRetries(request.getMaxRetries());
        jobDef.setRetryInterval(request.getRetryInterval());
        jobDef.setJobData(request.getJobData());
        jobDef.setStatus("CREATED");
        jobDef.setCreateTime(new Date());
        jobDef.setUpdateTime(new Date());
        
        // 保存任务
        jobDef = jobRepository.save(jobDef);
        log.info("Created job: {}", jobDef.getId());
        
        return convertToJobVO(jobDef);
    }

    @Transactional
    public JobVO updateJob(String jobId, JobUpdateRequest request) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 更新字段
        if (request.getName() != null) {
            jobDef.setName(request.getName());
        }
        if (request.getDescription() != null) {
            jobDef.setDescription(request.getDescription());
        }
        if (request.getCronExpression() != null) {
            jobDef.setCronExpression(request.getCronExpression());
        }
        if (request.getFixedDelay() != null) {
            jobDef.setFixedDelay(request.getFixedDelay());
        }
        if (request.getTimeout() != null) {
            jobDef.setTimeout(request.getTimeout());
        }
        if (request.getMaxRetries() != null) {
            jobDef.setMaxRetries(request.getMaxRetries());
        }
        if (request.getRetryInterval() != null) {
            jobDef.setRetryInterval(request.getRetryInterval());
        }
        if (request.getJobData() != null) {
            jobDef.setJobData(request.getJobData());
        }
        
        jobDef.setUpdateTime(new Date());
        
        // 保存更新
        jobDef = jobRepository.save(jobDef);
        
        // 如果任务已调度，则更新调度信息
        if (jobDef.isEnabled()) {
            jobScheduler.updateJob(jobDef);
        }
        
        log.info("Updated job: {}", jobId);
        return convertToJobVO(jobDef);
    }

    @Transactional
    public void deleteJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 如果任务正在执行，则不允许删除
        if (executionService.isJobRunning(jobId)) {
            throw new IllegalStateException("Cannot delete running job: " + jobId);
        }
        
        // 删除调度信息
        if (jobDef.isEnabled()) {
            jobScheduler.deleteJob(jobId);
        }
        
        // 删除任务定义
        jobRepository.deleteById(jobId);
        
        log.info("Deleted job: {}", jobId);
    }

    public JobDetailVO getJobDetail(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        return convertToJobDetailVO(jobDef);
    }

    public List<JobVO> queryJobs(JobQueryRequest request) {
        List<JobDefinition> jobs = jobRepository.findJobs(
            request.getName(),
            request.getJobType(),
            request.getStatus(),
            new Date(request.getStartTime()),
            new Date(request.getEndTime())
        );
        
        return jobs.stream()
                .map(this::convertToJobVO)
                .toList();
    }

    public List<JobLogVO> getJobLogs(String jobId) {
        List<JobLog> logs = jobLogRepository.findByJobId(jobId);
        return logs.stream()
                .map(this::convertToJobLogVO)
                .toList();
    }

    @Transactional
    public void pauseJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if (jobDef.isEnabled()) {
            jobDef.setStatus("DISABLED");
            jobDef.setUpdateTime(new Date());
            jobRepository.save(jobDef);
            
            jobScheduler.pauseJob(jobId);
            log.info("Paused job: {}", jobId);
        }
    }

    @Transactional
    public void resumeJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if (!jobDef.isEnabled()) {
            jobDef.setStatus("ENABLED");
            jobDef.setUpdateTime(new Date());
            jobRepository.save(jobDef);
            
            jobScheduler.resumeJob(jobId);
            log.info("Resumed job: {}", jobId);
        }
    }

    private void validateJobRequest(JobCreateRequest request) {
        // 校验CRON表达式
        if (request.getCronExpression() != null) {
            validateCronExpression(request.getCronExpression());
        }
        
        // 校验固定延迟
        if (request.getFixedDelay() != null && request.getFixedDelay() <= 0) {
            throw new IllegalArgumentException("Fixed delay must be positive");
        }
        
        // 校验超时时间
        if (request.getTimeout() != null && request.getTimeout() <= 0) {
            throw new IllegalArgumentException("Timeout must be positive");
        }
        
        // 校验重试配置
        if (request.getMaxRetries() != null && request.getMaxRetries() < 0) {
            throw new IllegalArgumentException("Max retries cannot be negative");
        }
        
        if (request.getRetryInterval() != null && request.getRetryInterval() <= 0) {
            throw new IllegalArgumentException("Retry interval must be positive");
        }
    }

    private void validateCronExpression(String cronExpression) {
        try {
            new CronExpression(cronExpression);
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid cron expression: " + e.getMessage());
        }
    }

    private JobDefinition getJobDefinition(String jobId) {
        return jobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
    }

    private JobVO convertToJobVO(JobDefinition jobDef) {
        JobVO vo = new JobVO();
        vo.setId(jobDef.getId());
        vo.setName(jobDef.getName());
        vo.setDescription(jobDef.getDescription());
        vo.setJobType(jobDef.getJobType());
        vo.setCronExpression(jobDef.getCronExpression());
        vo.setFixedDelay(jobDef.getFixedDelay());
        vo.setStatus(jobDef.getStatus());
        vo.setNextFireTime(jobScheduler.getNextFireTime(jobDef.getId()));
        vo.setCreateTime(jobDef.getCreateTime());
        vo.setUpdateTime(jobDef.getUpdateTime());
        return vo;
    }

    private JobDetailVO convertToJobDetailVO(JobDefinition jobDef) {
        JobDetailVO vo = new JobDetailVO();
        // 复制基本字段
        BeanUtils.copyProperties(convertToJobVO(jobDef), vo);
        // 添加详细信息
        vo.setTimeout(jobDef.getTimeout());
        vo.setMaxRetries(jobDef.getMaxRetries());
        vo.setRetryInterval(jobDef.getRetryInterval());
        vo.setJobData(jobDef.getJobData());
        // 获取最后一次执行记录
        vo.setLastExecution(executionService.getLastExecution(jobDef.getId()));
        // 获取统计信息
        vo.setStatistics(executionService.getJobStatistics(jobDef.getId()));
        return vo;
    }

    private JobLogVO convertToJobLogVO(JobLog log) {
        JobLogVO vo = new JobLogVO();
        vo.setId(log.getId());
        vo.setExecutionId(log.getExecutionId());
        vo.setJobId(log.getJobId());
        vo.setLogType(log.getLogType());
        vo.setContent(log.getContent());
        vo.setCreateTime(log.getCreateTime());
        return vo;
    }
}

```

让我继续实现执行相关的领域服务：

```java
package com.study.scheduler.domain.service;

import com.study.scheduler.api.model.request.job.JobExecuteRequest;
import com.study.scheduler.core.executor.*;
import com.study.scheduler.domain.entity.job.*;
import com.study.scheduler.domain.repository.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;
import java.util.concurrent.CompletableFuture;

@Slf4j
@Service
public class ExecutionDomainService {

    @Autowired
    private ExecutionRepository executionRepository;
    
    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private List<JobExecutor> jobExecutors;

    @Transactional
    public ExecuteResult executeJob(String jobId, JobExecuteRequest request) {
        // 获取任务定义
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 创建执行记录
        JobExecution execution = createExecution(jobDef);
        
        try {
            // 获取执行器
            JobExecutor executor = findExecutor(jobDef.getJobType());
            
            // 构建执行上下文
            ExecuteContext context = buildExecuteContext(jobDef, execution, request);
            
            // 异步执行
            if (request.getAsync()) {
                CompletableFuture.runAsync(() -> {
                    executeWithContext(executor, context);
                });
                return ExecuteResult.success("Job execution started");
            }
            
            // 同步执行
            return executeWithContext(executor, context);
            
        } catch (Exception e) {
            log.error("Job execution failed: " + jobId, e);
            failExecution(execution, e);
            return ExecuteResult.failure(e.getMessage());
        }
    }

    public void stopJob(String jobId) {
        List<JobExecution> runningExecutions = executionRepository
                .findByJobIdAndStatus(jobId, "RUNNING");
                
        for (JobExecution execution : runningExecutions) {
            stopExecution(execution);
        }
    }

    @Transactional
    public ExecuteResult retryJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 检查是否可以重试
        if (!jobDef.canRetry()) {
            throw new IllegalStateException("Job is not configured for retry: " + jobId);
        }
        
        // 获取最后一次执行
        JobExecution lastExecution = getLastExecution(jobId);
        if (lastExecution == null || !lastExecution.isCompleted()) {
            throw new IllegalStateException("No failed execution to retry");
        }
        
        // 检查重试次数
        if (lastExecution.getRetryCount() >= jobDef.getMaxRetries()) {
            throw new IllegalStateException("Max retry attempts exceeded");
        }
        
        // 创建重试请求
        JobExecuteRequest request = new JobExecuteRequest();
        request.setParameters(Collections.emptyMap());
        request.setTimeout(jobDef.getTimeout());
        
        return executeJob(jobId, request);
    }

    public String getJobStatus(String jobId) {
        JobExecution lastExecution = getLastExecution(jobId);
        return lastExecution != null ? lastExecution.getStatus() : "UNKNOWN";
    }

    public boolean isJobRunning(String jobId) {
        return executionRepository.findByJobIdAndStatus(jobId, "RUNNING")
                .stream()
                .findAny()
                .isPresent();
    }

    public JobExecution getLastExecution(String jobId) {
        return executionRepository.findByJobId(jobId).stream()
                .max(Comparator.comparing(JobExecution::getStartTime))
                .orElse(null);
    }

    public JobStatisticsVO getJobStatistics(String jobId) {
        List<JobExecution> executions = executionRepository.findByJobId(jobId);
        
        JobStatisticsVO stats = new JobStatisticsVO();
        stats.setTotalExecutions((long) executions.size());
        stats.setSuccessCount(executions.stream()
                .filter(e -> "SUCCESS".equals(e.getStatus()))
                .count());
        stats.setFailureCount(executions.stream()
                .filter(e -> "FAILED".equals(e.getStatus()))
                .count());
        
        // 计算平均执行时间
        Double avgDuration = executions.stream()
                .mapToLong(JobExecution::getDuration)
                .average()
                .orElse(0.0);
        stats.setAverageDuration(avgDuration);
        
        // 获取最后成功和失败时间
        executions.stream()
                .filter(e -> "SUCCESS".equals(e.getStatus()))
                .max(Comparator.comparing(JobExecution::getEndTime))
                .ifPresent(e -> stats.setLastSuccessTime(
                    e.getEndTime().getTime
```好的，让我们继续完成ExecutionDomainService中未完成的部分：



```java
// ExecutionDomainService.java继续...
    
    private JobDefinition getJobDefinition(String jobId) {
        return jobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
    }

    private JobExecutor findExecutor(String jobType) {
        return jobExecutors.stream()
                .filter(executor -> executor.supports(jobType))
                .findFirst()
                .orElseThrow(() -> new IllegalArgumentException(
                    "No executor found for job type: " + jobType));
    }

    private JobExecution createExecution(JobDefinition jobDef) {
        JobExecution execution = new JobExecution();
        execution.setId(UUID.randomUUID().toString());
        execution.setJobId(jobDef.getId());
        execution.setNodeId(getNodeId());
        execution.setStartTime(new Date());
        execution.setStatus("RUNNING");
        execution.setRetryCount(0);
        execution.setTraceId(generateTraceId());
        execution.setCreateTime(new Date());
        execution.setUpdateTime(new Date());
        
        return executionRepository.save(execution);
    }

    private ExecuteContext buildExecuteContext(
            JobDefinition jobDef, 
            JobExecution execution,
            JobExecuteRequest request) {
        ExecuteContext context = new ExecuteContext();
        context.setJobId(jobDef.getId());
        context.setExecutionId(execution.getId());
        context.setJobType(jobDef.getJobType());
        context.setJobData(jobDef.getJobData());
        context.setParameters(request.getParameters());
        context.setTimeout(request.getTimeout() != null ? 
                request.getTimeout() : jobDef.getTimeout());
        context.setExecution(execution);
        return context;
    }

    private ExecuteResult executeWithContext(JobExecutor executor, ExecuteContext context) {
        try {
            // 执行前处理
            executor.beforeExecute(context);
            
            // 执行任务
            ExecuteResult result = executor.execute(context);
            
            // 执行后处理
            executor.afterExecute(context, result);
            
            // 更新执行状态
            if (result.isSuccess()) {
                completeExecution(context.getExecution(), result);
            } else {
                failExecution(context.getExecution(), new RuntimeException(result.getError()));
            }
            
            return result;
            
        } catch (Exception e) {
            log.error("Job execution failed", e);
            failExecution(context.getExecution(), e);
            return ExecuteResult.failure(e.getMessage());
        }
    }

    private void completeExecution(JobExecution execution, ExecuteResult result) {
        execution.setEndTime(new Date());
        execution.setStatus("SUCCESS");
        execution.setResult(result.getResult());
        execution.setUpdateTime(new Date());
        executionRepository.save(execution);
    }

    private void failExecution(JobExecution execution, Exception e) {
        execution.setEndTime(new Date());
        execution.setStatus("FAILED");
        execution.setError(e.getMessage());
        execution.setUpdateTime(new Date());
        executionRepository.save(execution);
    }

    private void stopExecution(JobExecution execution) {
        // 只能停止运行中的任务
        if ("RUNNING".equals(execution.getStatus())) {
            execution.setEndTime(new Date());
            execution.setStatus("STOPPED");
            execution.setError("Execution stopped by user");
            execution.setUpdateTime(new Date());
            executionRepository.save(execution);
        }
    }

    private String getNodeId() {
        return System.getenv().getOrDefault("HOSTNAME", "unknown");
    }

    private String generateTraceId() {
        return UUID.randomUUID().toString();
    }
}

```

现在我们实现监控领域服务：

```java
package com.study.scheduler.domain.service;

import com.study.scheduler.domain.entity.monitor.*;
import com.study.scheduler.domain.repository.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import java.util.*;

@Slf4j
@Service
public class MonitorDomainService {

    @Autowired
    private AlertRepository alertRepository;
    
    @Autowired
    private MetricsRepository metricsRepository;

    @Transactional
    public void recordMetrics(String metricName, double value, String nodeId, 
            Map<String, String> tags) {
        MetricsRecord record = new MetricsRecord();
        record.setId(UUID.randomUUID().toString());
        record.setMetricName(metricName);
        record.setValue(value);
        record.setNodeId(nodeId);
        record.setTags(tags);
        record.setTimestamp(new Date());
        record.setCreateTime(new Date());
        
        metricsRepository.save(record);
        
        // 检查告警规则
        checkAlertRules(metricName, value, tags);
    }

    public List<MetricsRecord> getMetricsHistory(String metricName, 
            Date startTime, Date endTime) {
        return metricsRepository.findMetricsHistory(metricName, startTime, endTime);
    }

    @Transactional
    public void createAlert(AlertRecord alert) {
        alert.setId(UUID.randomUUID().toString());
        alert.setStatus("ACTIVE");
        alert.setCreateTime(new Date());
        alert.setUpdateTime(new Date());
        
        alertRepository.save(alert);
    }

    @Transactional
    public void acknowledgeAlert(String alertId) {
        AlertRecord alert = getAlert(alertId);
        
        if ("ACTIVE".equals(alert.getStatus())) {
            alert.setStatus("ACKNOWLEDGED");
            alert.setUpdateTime(new Date());
            alertRepository.save(alert);
        }
    }

    @Transactional
    public void resolveAlert(String alertId) {
        AlertRecord alert = getAlert(alertId);
        
        if (!alert.getStatus().equals("RESOLVED")) {
            alert.setStatus("RESOLVED");
            alert.setUpdateTime(new Date());
            alertRepository.save(alert);
        }
    }

    public List<AlertRecord> getActiveAlerts() {
        return alertRepository.findByStatus("ACTIVE");
    }

    public List<AlertRecord> getAlertHistory(String level, Date startTime, Date endTime) {
        return alertRepository.findAlertHistory(level, startTime, endTime);
    }

    private void checkAlertRules(String metricName, double value, Map<String, String> tags) {
        List<AlertRecord> rules = alertRepository.findByMetricName(metricName);
        
        for (AlertRecord rule : rules) {
            if (isRuleMatched(rule, value, tags)) {
                createAlert(buildAlert(rule, value));
            }
        }
    }

    private boolean isRuleMatched(AlertRecord rule, double value, Map<String, String> tags) {
        // 检查标签匹配
        if (!matchLabels(rule.getLabels(), tags)) {
            return false;
        }
        
        // 检查阈值条件
        return switch (rule.getOperator()) {
            case ">" -> value > rule.getThreshold();
            case ">=" -> value >= rule.getThreshold();
            case "<" -> value < rule.getThreshold();
            case "<=" -> value <= rule.getThreshold();
            case "==" -> value == rule.getThreshold();
            default -> false;
        };
    }

    private boolean matchLabels(Map<String, String> ruleLabels, Map<String, String> tags) {
        return ruleLabels.entrySet().stream()
                .allMatch(entry -> 
                    tags.containsKey(entry.getKey()) && 
                    tags.get(entry.getKey()).equals(entry.getValue())
                );
    }

    private AlertRecord buildAlert(AlertRecord rule, double value) {
        AlertRecord alert = new AlertRecord();
        alert.setRuleId(rule.getId());
        alert.setName(rule.getName());
        alert.setLevel(rule.getLevel());
        alert.setMetricName(rule.getMetricName());
        alert.setThreshold(rule.getThreshold());
        alert.setValue(value);
        alert.setOperator(rule.getOperator());
        alert.setLabels(rule.getLabels());
        alert.setNotifyChannels(rule.getNotifyChannels());
        return alert;
    }

    private AlertRecord getAlert(String alertId) {
        return alertRepository.findById(alertId)
                .orElseThrow(() -> new IllegalArgumentException("Alert not found: " + alertId));
    }
}

```

需要我继续实现基础设施层(Infrastructure)的组件吗？包括持久化实现、消息队列等。好的，让我们开始实现基础设施层的组件，首先从配置类开始：



```java
package com.study.scheduler.infra.config;

import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import javax.sql.DataSource;

@Configuration
public class DatabaseConfig {
    
    @Value("${spring.datasource.url}")
    private String url;
    
    @Value("${spring.datasource.username}")
    private String username;
    
    @Value("${spring.datasource.password}")
    private String password;
    
    @Value("${spring.datasource.hikari.maximum-pool-size}")
    private int maxPoolSize;
    
    @Bean
    @Primary
    public DataSource dataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl(url);
        config.setUsername(username);
        config.setPassword(password);
        config.setMaximumPoolSize(maxPoolSize);
        config.setConnectionTestQuery("SELECT 1");
        config.addDataSourceProperty("cachePrepStmts", "true");
        config.addDataSourceProperty("prepStmtCacheSize", "250");
        config.addDataSourceProperty("prepStmtCacheSqlLimit", "2048");
        
        return new HikariDataSource(config);
    }
}

@Configuration
@EnableRedisRepositories
public class RedisConfig {
    
    @Value("${spring.data.redis.cluster.nodes}")
    private List<String> nodes;
    
    @Value("${spring.data.redis.password}")
    private String password;
    
    @Bean
    public RedisConnectionFactory redisConnectionFactory() {
        RedisClusterConfiguration config = new RedisClusterConfiguration(nodes);
        config.setPassword(password);
        
        return new LettuceConnectionFactory(config);
    }
    
    @Bean
    public RedisTemplate<String, Object> redisTemplate(
            RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);
        template.setKeySerializer(new StringRedisSerializer());
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());
        return template;
    }
}

@Configuration
public class RabbitConfig {
    
    @Value("${spring.rabbitmq.host}")
    private String host;
    
    @Value("${spring.rabbitmq.port}")
    private int port;
    
    @Value("${spring.rabbitmq.username}")
    private String username;
    
    @Value("${spring.rabbitmq.password}")
    private String password;
    
    @Bean
    public ConnectionFactory rabbitConnectionFactory() {
        CachingConnectionFactory factory = new CachingConnectionFactory();
        factory.setHost(host);
        factory.setPort(port);
        factory.setUsername(username);
        factory.setPassword(password);
        factory.setPublisherConfirmType(CachingConnectionFactory.ConfirmType.CORRELATED);
        factory.setPublisherReturns(true);
        return factory;
    }
    
    @Bean
    public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) {
        RabbitTemplate template = new RabbitTemplate(connectionFactory);
        template.setMandatory(true);
        template.setMessageConverter(new Jackson2JsonMessageConverter());
        
        template.setConfirmCallback((correlation, ack, reason) -> {
            if (!ack) {
                log.error("Message send failed: {}", reason);
            }
        });
        
        template.setReturnsCallback(returned -> {
            log.error("Message returned: {}", returned.getMessage());
        });
        
        return template;
    }
    
    @Bean
    public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(
            ConnectionFactory connectionFactory) {
        SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory();
        factory.setConnectionFactory(connectionFactory);
        factory.setConcurrentConsumers(3);
        factory.setMaxConcurrentConsumers(10);
        factory.setPrefetchCount(1);
        factory.setMessageConverter(new Jackson2JsonMessageConverter());
        factory.setAcknowledgeMode(AcknowledgeMode.MANUAL);
        return factory;
    }
}

@Configuration
public class ThreadPoolConfig {
    
    @Value("${scheduler.execution.pool.core-size}")
    private int coreSize;
    
    @Value("${scheduler.execution.pool.max-size}")
    private int maxSize;
    
    @Value("${scheduler.execution.pool.queue-capacity}")
    private int queueCapacity;
    
    @Value("${scheduler.execution.pool.keep-alive}")
    private int keepAlive;
    
    @Bean
    public ThreadPoolExecutor executorService() {
        return new ThreadPoolExecutor(
            coreSize,
            maxSize,
            keepAlive,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(queueCapacity),
            new ThreadFactoryBuilder()
                .setNameFormat("job-executor-%d")
                .setDaemon(true)
                .build(),
            new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }
}

```

接下来实现仓储的具体实现类：

```java
package com.study.scheduler.infra.persistence.repository;

import com.study.scheduler.domain.entity.job.JobDefinition;
import com.study.scheduler.domain.repository.JobRepository;
import com.study.scheduler.infra.persistence.entity.JobDefinitionDO;
import com.study.scheduler.infra.persistence.mapper.JobMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Repository;

@Repository
public class JobRepositoryImpl implements JobRepository {

    @Autowired
    private JobMapper jobMapper;
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    private static final String CACHE_KEY = "scheduler:job:";
    private static final Duration CACHE_TTL = Duration.ofMinutes(5);

    @Override
    public JobDefinition save(JobDefinition jobDef) {
        // 转换为DO对象
        JobDefinitionDO jobDO = convertToDO(jobDef);
        
        if (jobDO.getId() == null) {
            // 新增
            jobMapper.insert(jobDO);
        } else {
            // 更新
            jobMapper.update(jobDO);
        }
        
        // 更新缓存
        jobDef.setId(jobDO.getId());
        updateCache(jobDef);
        
        return jobDef;
    }

    @Override
    public Optional<JobDefinition> findById(String id) {
        // 先查缓存
        String key = CACHE_KEY + id;
        Object cached = redisTemplate.opsForValue().get(key);
        if (cached != null) {
            return Optional.of((JobDefinition) cached);
        }
        
        // 查数据库
        JobDefinitionDO jobDO = jobMapper.findById(id);
        if (jobDO == null) {
            return Optional.empty();
        }
        
        // 转换并缓存
        JobDefinition jobDef = convertToEntity(jobDO);
        updateCache(jobDef);
        
        return Optional.of(jobDef);
    }

    @Override
    public List<JobDefinition> findByStatus(String status) {
        return jobMapper.findByStatus(status).stream()
                .map(this::convertToEntity)
                .collect(Collectors.toList());
    }

    @Override
    public void deleteById(String id) {
        jobMapper.deleteById(id);
        redisTemplate.delete(CACHE_KEY + id);
    }

    private void updateCache(JobDefinition jobDef) {
        String key = CACHE_KEY + jobDef.getId();
        redisTemplate.opsForValue().set(key, jobDef, CACHE_TTL);
    }

    private JobDefinitionDO convertToDO(JobDefinition entity) {
        JobDefinitionDO DO = new JobDefinitionDO();
        BeanUtils.copyProperties(entity, DO);
        DO.setJobDataJson(JsonUtils.toJson(entity.getJobData()));
        return DO;
    }

    private JobDefinition convertToEntity(JobDefinitionDO DO) {
        JobDefinition entity = new JobDefinition();
        BeanUtils.copyProperties(DO, entity);
        entity.setJobData(JsonUtils.fromJson(DO.getJobDataJson(), Map.class));
        return entity;
    }
}

@Repository
public class ExecutionRepositoryImpl implements ExecutionRepository {

    @Autowired
    private MongoTemplate mongoTemplate;

    @Override
    public JobExecution save(JobExecution execution) {
        return mongoTemplate.save(execution);
    }

    @Override
    public Optional<JobExecution> findById(String id) {
        JobExecution execution = mongoTemplate.findById(id, JobExecution.class);
        return Optional.ofNullable(execution);
    }

    @Override
    public List<JobExecution> findByJobId(String jobId) {
        Query query = Query.query(Criteria.where("jobId").is(jobId));
        return mongoTemplate.find(query, JobExecution.class);
    }

    @Override
    public List<JobExecution> findByStatus(String status) {
        Query query = Query.query(Criteria.where("status").is(status));
        return mongoTemplate.find(query, JobExecution.class);
    }

    @Override
    public int deleteByEndTimeBefore(Date time) {
        Query query = Query.query(Criteria.where("endTime").lt(time));
        DeleteResult result = mongoTemplate.remove(query, JobExecution.class);
        return (int) result.getDeletedCount();
    }
}

```

需要我继续实现消息队列相关的组件吗？包括生产者和消费者。

好的，让我们实现消息队列相关的组件，先从生产者开始：



```java
package com.study.scheduler.infra.mq.producer;

import com.study.scheduler.domain.entity.job.JobExecution;
import com.study.scheduler.infra.mq.message.JobMessage;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Slf4j
@Component
public class JobProducer {

    private static final String JOB_EXCHANGE = "scheduler.job";
    private static final String EXECUTION_ROUTING_KEY = "job.execution";
    private static final String CALLBACK_ROUTING_KEY = "job.callback";

    @Autowired
    private RabbitTemplate rabbitTemplate;

    public void sendExecutionMessage(JobExecution execution) {
        JobMessage message = JobMessage.builder()
                .jobId(execution.getJobId())
                .executionId(execution.getId())
                .status(execution.getStatus())
                .result(execution.getResult())
                .error(execution.getError())
                .timestamp(System.currentTimeMillis())
                .build();

        try {
            rabbitTemplate.convertAndSend(
                JOB_EXCHANGE,
                EXECUTION_ROUTING_KEY,
                message
            );
            log.info("Sent execution message for job: {}", execution.getJobId());
        } catch (Exception e) {
            log.error("Failed to send execution message", e);
            throw e;
        }
    }

    public void sendCallbackMessage(String jobId, String callbackUrl, 
            Map<String, Object> result) {
        JobMessage message = JobMessage.builder()
                .jobId(jobId)
                .callbackUrl(callbackUrl)
                .result(JsonUtils.toJson(result))
                .timestamp(System.currentTimeMillis())
                .build();

        try {
            rabbitTemplate.convertAndSend(
                JOB_EXCHANGE,
                CALLBACK_ROUTING_KEY,
                message
            );
            log.info("Sent callback message for job: {}", jobId);
        } catch (Exception e) {
            log.error("Failed to send callback message", e);
            throw e;
        }
    }
}

@Slf4j
@Component
public class AlertProducer {

    private static final String ALERT_EXCHANGE = "scheduler.alert";
    private static final Map<String, String> CHANNEL_ROUTING_KEYS = Map.of(
        "email", "alert.email",
        "sms", "alert.sms",
        "webhook", "alert.webhook"
    );

    @Autowired
    private RabbitTemplate rabbitTemplate;

    public void sendAlert(String channel, AlertRecord alert) {
        String routingKey = CHANNEL_ROUTING_KEYS.get(channel);
        if (routingKey == null) {
            throw new IllegalArgumentException("Unsupported alert channel: " + channel);
        }

        AlertMessage message = AlertMessage.builder()
                .alertId(alert.getId())
                .level(alert.getLevel())
                .name(alert.getName())
                .content(buildAlertContent(alert))
                .timestamp(System.currentTimeMillis())
                .build();

        try {
            rabbitTemplate.convertAndSend(
                ALERT_EXCHANGE,
                routingKey,
                message
            );
            log.info("Sent alert message: {}", alert.getId());
        } catch (Exception e) {
            log.error("Failed to send alert message", e);
            throw e;
        }
    }

    public void sendRecovery(String channel, AlertRecord alert) {
        String routingKey = CHANNEL_ROUTING_KEYS.get(channel);
        if (routingKey == null) {
            throw new IllegalArgumentException("Unsupported alert channel: " + channel);
        }

        AlertMessage message = AlertMessage.builder()
                .alertId(alert.getId())
                .level(alert.getLevel())
                .name(alert.getName())
                .content("Alert recovered: " + alert.getName())
                .type("RECOVERY")
                .timestamp(System.currentTimeMillis())
                .build();

        try {
            rabbitTemplate.convertAndSend(
                ALERT_EXCHANGE,
                routingKey,
                message
            );
            log.info("Sent recovery message for alert: {}", alert.getId());
        } catch (Exception e) {
            log.error("Failed to send recovery message", e);
            throw e;
        }
    }

    private String buildAlertContent(AlertRecord alert) {
        return String.format(
            "Alert[%s]: %s\nMetric: %s %s %.2f (threshold: %.2f)",
            alert.getLevel(),
            alert.getName(),
            alert.getMetricName(),
            alert.getOperator(),
            alert.getValue(),
            alert.getThreshold()
        );
    }
}

```

接下来实现消费者：

```java
package com.study.scheduler.infra.mq.consumer;

import com.study.scheduler.core.manager.ExecutionManager;
import com.study.scheduler.infra.mq.message.JobMessage;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Slf4j
@Component
public class JobConsumer {

    @Autowired
    private ExecutionManager executionManager;

    @Autowired
    private RestTemplate restTemplate;

    @RabbitListener(queues = "job.execution.queue")
    public void handleExecutionMessage(JobMessage message) {
        log.info("Received execution message for job: {}", message.getJobId());
        
        try {
            executionManager.handleExecutionResult(
                message.getJobId(),
                message.getExecutionId(),
                message.getStatus(),
                message.getResult(),
                message.getError()
            );
        } catch (Exception e) {
            log.error("Failed to handle execution message", e);
            throw e;
        }
    }

    @RabbitListener(queues = "job.callback.queue")
    public void handleCallbackMessage(JobMessage message) {
        log.info("Received callback message for job: {}", message.getJobId());
        
        if (message.getCallbackUrl() == null) {
            return;
        }

        try {
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.APPLICATION_JSON);
            
            HttpEntity<String> request = new HttpEntity<>(
                message.getResult(),
                headers
            );
            
            ResponseEntity<String> response = restTemplate.postForEntity(
                message.getCallbackUrl(),
                request,
                String.class
            );
            
            if (!response.getStatusCode().is2xxSuccessful()) {
                log.error("Callback request failed: {}", response.getStatusCode());
                throw new RuntimeException("Callback request failed");
            }
            
        } catch (Exception e) {
            log.error("Failed to send callback request", e);
            throw e;
        }
    }
}

@Slf4j
@Component
public class AlertConsumer {

    @Autowired
    private JavaMailSender mailSender;

    @Autowired
    private RestTemplate restTemplate;

    @RabbitListener(queues = "alert.email.queue")
    public void handleEmailAlert(AlertMessage message) {
        log.info("Received email alert: {}", message.getAlertId());
        
        try {
            SimpleMailMessage mail = new SimpleMailMessage();
            mail.setTo("admin@example.com"); // 配置收件人
            mail.setSubject("Alert: " + message.getName());
            mail.setText(message.getContent());
            
            mailSender.send(mail);
            log.info("Sent alert email: {}", message.getAlertId());
            
        } catch (Exception e) {
            log.error("Failed to send alert email", e);
            throw e;
        }
    }

    @RabbitListener(queues = "alert.webhook.queue")
    public void handleWebhookAlert(AlertMessage message) {
        log.info("Received webhook alert: {}", message.getAlertId());
        
        try {
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.APPLICATION_JSON);
            
            Map<String, Object> body = new HashMap<>();
            body.put("alertId", message.getAlertId());
            body.put("level", message.getLevel());
            body.put("name", message.getName());
            body.put("content", message.getContent());
            body.put("timestamp", message.getTimestamp());
            
            HttpEntity<Map<String, Object>> request = new HttpEntity<>(body, headers);
            
            // webhook地址应该从配置获取
            String webhookUrl = "http://example.com/webhook";
            
            ResponseEntity<String> response = restTemplate.postForEntity(
                webhookUrl,
                request,
                String.class
            );
            
            if (!response.getStatusCode().is2xxSuccessful()) {
                log.error("Webhook request failed: {}", response.getStatusCode());
                throw new RuntimeException("Webhook request failed");
            }
            
        } catch (Exception e) {
            log.error("Failed to send webhook alert", e);
            throw e;
        }
    }
}

```

需要我继续实现消息定义和分布式锁的实现吗？好的，让我们先实现消息定义：



```java
package com.study.scheduler.infra.mq.message;

import lombok.Builder;
import lombok.Data;
import java.io.Serializable;

@Data
@Builder
public class JobMessage implements Serializable {
    private String jobId;
    private String executionId;
    private String status;
    private String result;
    private String error;
    private String callbackUrl;
    private Long timestamp;
}

@Data
@Builder
public class AlertMessage implements Serializable {
    private String alertId;
    private String level;
    private String name;
    private String content;
    private String type;  // ALERT/RECOVERY
    private Map<String, String> labels;
    private Map<String, Object> extraData;
    private Long timestamp;

    public boolean isRecovery() {
        return "RECOVERY".equals(type);
    }
}

// 消息常量定义
public class MessageConstants {
    // 交换机
    public static final String JOB_EXCHANGE = "scheduler.job";
    public static final String ALERT_EXCHANGE = "scheduler.alert";
    
    // 队列
    public static final String JOB_EXECUTION_QUEUE = "job.execution.queue";
    public static final String JOB_CALLBACK_QUEUE = "job.callback.queue";
    public static final String ALERT_EMAIL_QUEUE = "alert.email.queue";
    public static final String ALERT_SMS_QUEUE = "alert.sms.queue";
    public static final String ALERT_WEBHOOK_QUEUE = "alert.webhook.queue";
    
    // 路由键
    public static final String JOB_EXECUTION_KEY = "job.execution";
    public static final String JOB_CALLBACK_KEY = "job.callback";
    public static final String ALERT_EMAIL_KEY = "alert.email";
    public static final String ALERT_SMS_KEY = "alert.sms";
    public static final String ALERT_WEBHOOK_KEY = "alert.webhook";
}

```

接下来实现分布式锁：



```java
package com.study.scheduler.infra.lock;

import java.util.concurrent.TimeUnit;

public interface DistributedLock {
    boolean tryLock(String key, long timeout, TimeUnit unit);
    void unlock(String key);
    boolean isLocked(String key);
}

@Slf4j
@Component
@Primary
public class RedisDistributedLock implements DistributedLock {
    
    private static final String LOCK_PREFIX = "scheduler:lock:";
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    @Override
    public boolean tryLock(String key, long timeout, TimeUnit unit) {
        String lockKey = LOCK_PREFIX + key;
        String lockValue = getLockValue();
        
        try {
            Boolean success = redisTemplate.opsForValue()
                .setIfAbsent(lockKey, lockValue, timeout, unit);
            
            return Boolean.TRUE.equals(success);
            
        } catch (Exception e) {
            log.error("Failed to acquire Redis lock: {}", key, e);
            return false;
        }
    }
    
    @Override
    public void unlock(String key) {
        String lockKey = LOCK_PREFIX + key;
        String lockValue = getLockValue();
        
        try {
            String script = "if redis.call('get', KEYS[1]) == ARGV[1] then " +
                          "return redis.call('del', KEYS[1]) else return 0 end";
            
            redisTemplate.execute(new DefaultRedisScript<>(script, Long.class),
                Collections.singletonList(lockKey), lockValue);
                
        } catch (Exception e) {
            log.error("Failed to release Redis lock: {}", key, e);
        }
    }
    
    @Override
    public boolean isLocked(String key) {
        String lockKey = LOCK_PREFIX + key;
        return Boolean.TRUE.equals(redisTemplate.hasKey(lockKey));
    }
    
    private String getLockValue() {
        return UUID.randomUUID().toString();
    }
}

@Slf4j
@Component
public class DatabaseDistributedLock implements DistributedLock {
    
    @Autowired
    private JdbcTemplate jdbcTemplate;
    
    @Override
    public boolean tryLock(String key, long timeout, TimeUnit unit) {
        String nodeId = getNodeId();
        Date expiresAt = new Date(System.currentTimeMillis() + unit.toMillis(timeout));
        
        try {
            int updated = jdbcTemplate.update(
                "INSERT INTO job_lock (lock_key, node_id, expires_at, create_time) " +
                "VALUES (?, ?, ?, NOW()) " +
                "ON DUPLICATE KEY UPDATE " +
                "node_id = IF(expires_at < NOW(), VALUES(node_id), node_id), " +
                "expires_at = IF(expires_at < NOW(), VALUES(expires_at), expires_at)",
                key, nodeId, expiresAt
            );
            
            return updated > 0;
            
        } catch (Exception e) {
            log.error("Failed to acquire database lock: {}", key, e);
            return false;
        }
    }
    
    @Override
    public void unlock(String key) {
        String nodeId = getNodeId();
        
        try {
            jdbcTemplate.update(
                "DELETE FROM job_lock WHERE lock_key = ? AND node_id = ?",
                key, nodeId
            );
        } catch (Exception e) {
            log.error("Failed to release database lock: {}", key, e);
        }
    }
    
    @Override
    public boolean isLocked(String key) {
        try {
            Integer count = jdbcTemplate.queryForObject(
                "SELECT COUNT(*) FROM job_lock " +
                "WHERE lock_key = ? AND expires_at > NOW()",
                Integer.class,
                key
            );
            
            return count != null && count > 0;
            
        } catch (Exception e) {
            log.error("Failed to check database lock: {}", key, e);
            return false;
        }
    }
    
    private String getNodeId() {
        return System.getenv().getOrDefault("HOSTNAME", "unknown");
    }
}

@Component 
public class DistributedLockTemplate {
    
    @Autowired
    private DistributedLock lock;
    
    public <T> T executeWithLock(String key, long timeout, TimeUnit unit, 
            Supplier<T> action) {
        // 尝试获取锁
        if (!lock.tryLock(key, timeout, unit)) {
            throw new RuntimeException("Failed to acquire lock: " + key);
        }
        
        try {
            return action.get();
        } finally {
            lock.unlock(key);
        }
    }
    
    public void executeWithLock(String key, long timeout, TimeUnit unit, 
            Runnable action) {
        executeWithLock(key, timeout, unit, () -> {
            action.run();
            return null;
        });
    }
    
    public <T> T executeWithRetry(String key, long timeout, TimeUnit unit,
            Supplier<T> action, int maxAttempts, long retryInterval) {
        int attempts = 0;
        while (true) {
            try {
                return executeWithLock(key, timeout, unit, action);
            } catch (Exception e) {
                attempts++;
                if (attempts >= maxAttempts) {
                    throw e;
                }
                try {
                    Thread.sleep(retryInterval);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    throw new RuntimeException(ie);
                }
            }
        }
    }
}

```

需要我继续实现基础设施层的其他组件吗？比如缓存、工具类等。好的，让我们继续实现Infrastructure层的缓存组件：



```java
package com.study.scheduler.infra.persistence.redis;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;

import java.util.Optional;
import java.util.concurrent.TimeUnit;

@Slf4j
@Component
public class RedisCache {
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    public void set(String key, Object value, long timeout, TimeUnit unit) {
        try {
            redisTemplate.opsForValue().set(key, value, timeout, unit);
            log.debug("Cache set: {}", key);
        } catch (Exception e) {
            log.error("Failed to set cache: {}", key, e);
            throw e;
        }
    }
    
    public <T> Optional<T> get(String key, Class<T> type) {
        try {
            Object value = redisTemplate.opsForValue().get(key);
            if (value != null && type.isInstance(value)) {
                return Optional.of(type.cast(value));
            }
            return Optional.empty();
        } catch (Exception e) {
            log.error("Failed to get cache: {}", key, e);
            return Optional.empty();
        }
    }
    
    public void delete(String key) {
        try {
            redisTemplate.delete(key);
            log.debug("Cache deleted: {}", key);
        } catch (Exception e) {
            log.error("Failed to delete cache: {}", key, e);
            throw e;
        }
    }
    
    public boolean exists(String key) {
        try {
            return Boolean.TRUE.equals(redisTemplate.hasKey(key));
        } catch (Exception e) {
            log.error("Failed to check cache existence: {}", key, e);
            return false;
        }
    }
    
    public void expire(String key, long timeout, TimeUnit unit) {
        try {
            redisTemplate.expire(key, timeout, unit);
            log.debug("Cache expire set: {}", key);
        } catch (Exception e) {
            log.error("Failed to set cache expiration: {}", key, e);
            throw e;
        }
    }
}

@Component
public class RedisCacheRepository implements CacheRepository {
    
    private final RedisCache redisCache;
    private final LoadingCache<String, Object> localCache;
    
    public RedisCacheRepository(RedisCache redisCache) {
        this.redisCache = redisCache;
        this.localCache = CacheBuilder.newBuilder()
            .maximumSize(1000)
            .expireAfterWrite(5, TimeUnit.MINUTES)
            .build(new CacheLoader<String, Object>() {
                @Override
                public Object load(String key) {
                    return redisCache.get(key, Object.class)
                        .orElse(null);
                }
            });
    }
    
    @Override
    public <T> Optional<T> find(String key, Class<T> type) {
        // 先查本地缓存
        try {
            Object value = localCache.get(key);
            if (value != null && type.isInstance(value)) {
                return Optional.of(type.cast(value));
            }
        } catch (Exception e) {
            log.debug("Local cache miss: {}", key);
        }
        
        // 查Redis缓存
        return redisCache.get(key, type);
    }
    
    @Override
    public void save(String key, Object value, Duration ttl) {
        // 保存到Redis
        redisCache.set(key, value, ttl.toMillis(), TimeUnit.MILLISECONDS);
        
        // 更新本地缓存
        localCache.put(key, value);
    }
    
    @Override
    public void remove(String key) {
        redisCache.delete(key);
        localCache.invalidate(key);
    }
    
    @Override
    public void clear() {
        // 清空本地缓存
        localCache.invalidateAll();
    }
}

```

现在实现数据转换和数据库实体：

```java
package com.study.scheduler.infra.persistence.entity;

import lombok.Data;
import java.util.Date;

@Data
public class JobDefinitionDO {
    private String id;
    private String name;
    private String description;
    private String jobType;
    private String cronExpression;
    private Long fixedDelay;
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private String jobDataJson;
    private String status;
    private Date createTime;
    private Date updateTime;
}

@Data
public class JobExecutionDO {
    private String id;
    private String jobId;
    private String nodeId;
    private Date startTime;
    private Date endTime;
    private String status;
    private String result;
    private String error;
    private Integer retryCount;
    private String traceId;
    private Date createTime;
    private Date updateTime;
}

@Data
public class JobLogDO {
    private String id;
    private String executionId;
    private String jobId;
    private String logType;
    private String content;
    private Date createTime;
}

@Data
public class AlertRecordDO {
    private String id;
    private String ruleId;
    private String name;
    private String level;
    private String metricName;
    private Double threshold;
    private Double value;
    private String operator;
    private String description;
    private String notifyChannels;  // JSON格式存储
    private String labels;          // JSON格式存储
    private Boolean enabled;
    private String status;
    private Long silenceDuration;
    private Date createTime;
    private Date updateTime;
}

@Data
public class MetricsRecordDO {
    private String id;
    private String metricName;
    private Double value;
    private String nodeId;
    private String tags;  // JSON格式存储
    private Date timestamp;
    private Date createTime;
}

```

接下来是MyBatis的Mapper接口：

```java
package com.study.scheduler.infra.persistence.mapper;

import com.study.scheduler.infra.persistence.entity.*;
import org.apache.ibatis.annotations.*;
import java.util.List;
import java.util.Date;

@Mapper
public interface JobMapper {

    @Insert("""
        INSERT INTO job_definition (
            id, name, description, job_type, cron_expression, fixed_delay,
            timeout, max_retries, retry_interval, job_data_json, status,
            create_time, update_time
        ) VALUES (
            #{id}, #{name}, #{description}, #{jobType}, #{cronExpression},
            #{fixedDelay}, #{timeout}, #{maxRetries}, #{retryInterval},
            #{jobDataJson}, #{status}, #{createTime}, #{updateTime}
        )
    """)
    void insert(JobDefinitionDO job);

    @Update("""
        UPDATE job_definition SET
            name = #{name},
            description = #{description},
            cron_expression = #{cronExpression},
            fixed_delay = #{fixedDelay},
            timeout = #{timeout},
            max_retries = #{maxRetries},
            retry_interval = #{retryInterval},
            job_data_json = #{jobDataJson},
            status = #{status},
            update_time = #{updateTime}
        WHERE id = #{id}
    """)
    void update(JobDefinitionDO job);

    @Select("SELECT * FROM job_definition WHERE id = #{id}")
    JobDefinitionDO findById(String id);

    @Select("SELECT * FROM job_definition WHERE status = #{status}")
    List<JobDefinitionDO> findByStatus(String status);

    @Delete("DELETE FROM job_definition WHERE id = #{id}")
    void deleteById(String id);

    @Select("""
        SELECT * FROM job_definition
        WHERE (#{name} IS NULL OR name LIKE CONCAT('%', #{name}, '%'))
        AND (#{jobType} IS NULL OR job_type = #{jobType})
        AND (#{status} IS NULL OR status = #{status})
        AND create_time BETWEEN #{startTime} AND #{endTime}
    """)
    List<JobDefinitionDO> findJobs(
        @Param("name") String name,
        @Param("jobType") String jobType,
        @Param("status") String status,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
}

@Mapper
public interface JobLogMapper {

    @Insert("""
        INSERT INTO job_log (
            id, execution_id, job_id, log_type, content, create_time
        ) VALUES (
            #{id}, #{executionId}, #{jobId}, #{logType}, #{content}, 
            #{createTime}
        )
    """)
    void insert(JobLogDO log);

    @Select("SELECT * FROM job_log WHERE job_id = #{jobId}")
    List<JobLogDO> findByJobId(String jobId);

    @Select("SELECT * FROM job_log WHERE execution_id = #{executionId}")
    List<JobLogDO> findByExecutionId(String executionId);

    @Delete("""
        DELETE FROM job_log WHERE create_time < #{time}
    """)
    int deleteByCreateTimeBefore(Date time);
}

@Mapper
public interface AlertMapper {

    @Insert("""
        INSERT INTO alert_record (
            id, rule_id, name, level, metric_name, threshold, value,
            operator, description, notify_channels, labels, enabled,
            status, silence_duration, create_time, update_time
        ) VALUES (
            #{id}, #{ruleId}, #{name}, #{level}, #{metricName},
            #{threshold}, #{value}, #{operator}, #{description},
            #{notifyChannels}, #{labels}, #{enabled}, #{status},
            #{silenceDuration}, #{createTime}, #{updateTime}
        )
    """)
    void insert(AlertRecordDO alert);

    @Select("SELECT * FROM alert_record WHERE id = #{id}")
    AlertRecordDO findById(String id);

    @Select("SELECT * FROM alert_record WHERE status = #{status}")
    List<AlertRecordDO> findByStatus(String status);

    @Update("""
        UPDATE alert_record SET
            status = #{status},
            update_time = #{updateTime}
        WHERE id = #{id}
    """)
    void updateStatus(
        @Param("id") String id,
        @Param("status") String status,
        @Param("updateTime") Date updateTime
    );
}

```

需要我继续实现其他基础设施层的组件吗？让我们继续实现Extension层的组件，首先是变量管理相关的组件：



```java
package com.study.scheduler.extension.variable.provider;

import java.util.Map;

public abstract class AbstractProvider implements VariableProvider {
    
    @Override
    public boolean supports(String type) {
        return getType().equalsIgnoreCase(type);
    }
    
    public abstract String getType();
    
    public abstract String getValue(String key);
    
    protected String getFromCache(String key) {
        // 实现缓存逻辑
        return null;
    }
    
    protected void updateCache(String key, String value, long expireSeconds) {
        // 实现缓存更新逻辑
    }
}

@Component
public class TokenProvider extends AbstractProvider {
    
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @Override
    public String getType() {
        return "token";
    }
    
    @Override
    public String getValue(String key) {
        // 先查缓存
        String token = getFromCache(key);
        if (token != null) {
            return token;
        }
        
        // 生成新token
        token = generateToken(key);
        
        // 更新缓存
        updateCache(key, token, 3600);
        
        return token;
    }
    
    private String generateToken(String key) {
        // 实现token生成逻辑
        return UUID.randomUUID().toString();
    }
}

@Component
public class VersionProvider extends AbstractProvider {
    
    @Autowired
    private JdbcTemplate jdbcTemplate;
    
    @Override
    public String getType() {
        return "version";
    }
    
    @Override
    public String getValue(String key) {
        return jdbcTemplate.queryForObject(
            "SELECT version FROM version_info WHERE name = ?",
            String.class,
            key
        );
    }
}

@Component
public class EnvironmentProvider extends AbstractProvider {
    
    @Override
    public String getType() {
        return "env";
    }
    
    @Override
    public String getValue(String key) {
        return System.getenv(key);
    }
}

```

现在实现变量解析器和表达式解析器：

```java
package com.study.scheduler.extension.variable.resolver;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.expression.EvaluationContext;
import org.springframework.expression.Expression;
import org.springframework.expression.ExpressionParser;
import org.springframework.expression.spel.standard.SpelExpressionParser;
import org.springframework.expression.spel.support.StandardEvaluationContext;
import org.springframework.stereotype.Component;

@Slf4j
@Component
public class VariableResolver {
    
    private static final Pattern VARIABLE_PATTERN = Pattern.compile("\\$\\{([^}]+)}");
    
    @Autowired
    private List<VariableProvider> providers;
    
    @Autowired
    private ExpressionParser expressionParser;
    
    public String resolve(String content, Map<String, Object> context) {
        if (content == null) {
            return null;
        }
        
        StringBuffer result = new StringBuffer();
        Matcher matcher = VARIABLE_PATTERN.matcher(content);
        
        while (matcher.find()) {
            String variable = matcher.group(1);
            String value = resolveVariable(variable, context);
            matcher.appendReplacement(result, value != null ? 
                Matcher.quoteReplacement(value) : matcher.group());
        }
        matcher.appendTail(result);
        
        return result.toString();
    }
    
    private String resolveVariable(String variable, Map<String, Object> context) {
        // 处理表达式
        if (variable.startsWith("#{") && variable.endsWith("}")) {
            return evaluateExpression(
                variable.substring(2, variable.length() - 1), 
                context
            );
        }
        
        // 处理提供者变量
        String[] parts = variable.split(":", 2);
        String providerType = parts[0];
        String key = parts.length > 1 ? parts[1] : "";
        
        return providers.stream()
                .filter(p -> p.supports(providerType))
                .findFirst()
                .map(p -> p.getValue(key))
                .orElse(null);
    }
    
    private String evaluateExpression(String expression, Map<String, Object> context) {
        try {
            EvaluationContext evalContext = new StandardEvaluationContext();
            context.forEach(evalContext::setVariable);
            
            Expression exp = expressionParser.parseExpression(expression);
            Object value = exp.getValue(evalContext);
            
            return value != null ? value.toString() : null;
            
        } catch (Exception e) {
            log.error("Failed to evaluate expression: {}", expression, e);
            return null;
        }
    }
}

@Component
public class ExpressionParser {
    
    private final SpelExpressionParser parser = new SpelExpressionParser();
    
    public Expression parse(String expression) {
        return parser.parseExpression(expression);
    }
    
    public Object evaluate(String expression, Map<String, Object> variables) {
        StandardEvaluationContext context = new StandardEvaluationContext();
        variables.forEach(context::setVariable);
        return parse(expression).getValue(context);
    }
    
    public <T> T evaluate(String expression, Map<String, Object> variables, 
            Class<T> resultType) {
        StandardEvaluationContext context = new StandardEvaluationContext();
        variables.forEach(context::setVariable);
        return parse(expression).getValue(context, resultType);
    }
}

@Component
public class TemplateEngine {
    
    @Autowired
    private VariableResolver variableResolver;
    
    @Autowired
    private ExpressionParser expressionParser;
    
    public String process(String template, Map<String, Object> variables) {
        // 首先解析变量
        String resolvedTemplate = variableResolver.resolve(template, variables);
        
        // 再处理表达式
        return processExpressions(resolvedTemplate, variables);
    }
    
    public void validate(String template) {
        // 检查变量语法
        checkVariableSyntax(template);
        
        // 检查表达式语法
        checkExpressionSyntax(template);
    }
    
    private String processExpressions(String template, Map<String, Object> variables) {
        Matcher matcher = Pattern.compile("\\{\\{([^}]+)}}").matcher(template);
        StringBuffer result = new StringBuffer();
        
        while (matcher.find()) {
            String expression = matcher.group(1).trim();
            Object value = expressionParser.evaluate(expression, variables);
            matcher.appendReplacement(result, 
                value != null ? Matcher.quoteReplacement(value.toString()) : "");
        }
        matcher.appendTail(result);
        
        return result.toString();
    }
    
    private void checkVariableSyntax(String template) {
        Pattern pattern = Pattern.compile("\\$\\{([^}]+)}");
        Matcher matcher = pattern.matcher(template);
        
        while (matcher.find()) {
            String variable = matcher.group(1);
            if (!isValidVariableSyntax(variable)) {
                throw new IllegalArgumentException(
                    "Invalid variable syntax: ${" + variable + "}");
            }
        }
    }
    
    private void checkExpressionSyntax(String template) {
        Pattern pattern = Pattern.compile("\\{\\{([^}]+)}}");
        Matcher matcher = pattern.matcher(template);
        
        while (matcher.find()) {
            String expression = matcher.group(1).trim();
            try {
                expressionParser.parse(expression);
            } catch (Exception e) {
                throw new IllegalArgumentException(
                    "Invalid expression syntax: " + expression);
            }
        }
    }
    
    private boolean isValidVariableSyntax(String variable) {
        if (variable.contains(" ")) {
            return false;
        }
        
        if (variable.startsWith("#")) {
            return variable.matches("#\\{[^}]+}");
        }
        
        return variable.matches("[a-zA-Z0-9_]+(:[a-zA-Z0-9_]+)?");
    }
}

```

要继续实现模板管理和批量任务相关的组件吗？好的，让我们继续实现模板管理相关的组件：



```java
package com.study.scheduler.extension.template;

import lombok.Data;
import org.springframework.stereotype.Component;
import java.util.Map;

@Data
public class TaskTemplate {
    private String templateContent;
    private Map<String, String> variables;
    private Map<String, Object> defaultValues;
    private String description;
    
    public void validate() {
        // 检查模板内容
        if (templateContent == null || templateContent.trim().isEmpty()) {
            throw new IllegalArgumentException("Template content cannot be empty");
        }
        
        // 检查变量定义
        if (variables != null) {
            variables.forEach((key, desc) -> {
                if (!isValidVariableName(key)) {
                    throw new IllegalArgumentException(
                        "Invalid variable name: " + key);
                }
            });
        }
    }
    
    private boolean isValidVariableName(String name) {
        return name.matches("[a-zA-Z][a-zA-Z0-9_]*");
    }
}

@Component
public class TemplateParser {
    
    @Autowired
    private TemplateEngine templateEngine;
    
    @Autowired
    private ObjectMapper objectMapper;
    
    public TaskTemplate parseTemplate(String content) {
        try {
            JsonNode root = objectMapper.readTree(content);
            
            TaskTemplate template = new TaskTemplate();
            template.setTemplateContent(root.get("template").asText());
            
            // 解析变量定义
            if (root.has("variables")) {
                Map<String, String> variables = new HashMap<>();
                root.get("variables").fields().forEachRemaining(entry -> 
                    variables.put(entry.getKey(), entry.getValue().asText())
                );
                template.setVariables(variables);
            }
            
            // 解析默认值
            if (root.has("defaults")) {
                Map<String, Object> defaults = new HashMap<>();
                root.get("defaults").fields().forEachRemaining(entry -> 
                    defaults.put(entry.getKey(), parseJsonValue(entry.getValue()))
                );
                template.setDefaultValues(defaults);
            }
            
            // 解析描述
            if (root.has("description")) {
                template.setDescription(root.get("description").asText());
            }
            
            template.validate();
            return template;
            
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid template format", e);
        }
    }
    
    private Object parseJsonValue(JsonNode node) {
        if (node.isTextual()) {
            return node.asText();
        } else if (node.isNumber()) {
            return node.numberValue();
        } else if (node.isBoolean()) {
            return node.asBoolean();
        } else if (node.isObject() || node.isArray()) {
            return objectMapper.convertValue(node, Object.class);
        }
        return null;
    }
}

@Component
public class TemplateEngine {

    @Autowired
    private VariableResolver variableResolver;
    
    @Autowired
    private ObjectMapper objectMapper;

    public JobDefinition processTemplate(TaskTemplate template, 
            Map<String, Object> variables) {
        // 合并默认值和提供的变量
        Map<String, Object> resolvedVars = new HashMap<>(
            template.getDefaultValues() != null ? 
            template.getDefaultValues() : Collections.emptyMap()
        );
        resolvedVars.putAll(variables);
        
        // 验证必需变量
        validateRequiredVariables(template, resolvedVars);
        
        // 处理模板内容
        String processedContent = variableResolver.resolve(
            template.getTemplateContent(), 
            resolvedVars
        );
        
        // 解析为任务定义
        try {
            return objectMapper.readValue(processedContent, JobDefinition.class);
        } catch (Exception e) {
            throw new TemplateProcessException(
                "Failed to process template: " + e.getMessage(), e);
        }
    }
    
    private void validateRequiredVariables(TaskTemplate template, 
            Map<String, Object> variables) {
        if (template.getVariables() != null) {
            List<String> missing = template.getVariables().keySet().stream()
                .filter(key -> !variables.containsKey(key))
                .collect(Collectors.toList());
                
            if (!missing.isEmpty()) {
                throw new IllegalArgumentException(
                    "Missing required variables: " + String.join(", ", missing));
            }
        }
    }
}

```

现在实现批量任务相关的组件：

```java
package com.study.scheduler.extension.batch;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

@Slf4j
@Component
public class BatchTaskCreator {

    @Autowired
    private JobManager jobManager;
    
    @Autowired
    private TemplateEngine templateEngine;
    
    public List<JobDefinition> createBatchTasks(BatchTaskRequest request) {
        List<JobDefinition> jobs = new ArrayList<>();
        
        // 处理每个批次的变量
        for (Map<String, Object> batchVars : request.getBatchVariables()) {
            try {
                // 使用模板创建任务
                if (request.getTemplateId() != null) {
                    TaskTemplate template = templateEngine.getTemplate(
                        request.getTemplateId());
                    jobs.add(templateEngine.processTemplate(template, batchVars));
                } else {
                    // 直接使用任务定义
                    JobDefinition job = createJobFromDefinition(
                        request.getBaseJob(), batchVars);
                    jobs.add(job);
                }
            } catch (Exception e) {
                log.error("Failed to create batch task with variables: {}", 
                    batchVars, e);
                if (!request.isIgnoreErrors()) {
                    throw e;
                }
            }
        }
        
        return jobs;
    }
    
    private JobDefinition createJobFromDefinition(JobDefinition baseJob, 
            Map<String, Object> variables) {
        // 克隆基础任务定义
        JobDefinition job = new JobDefinition();
        BeanUtils.copyProperties(baseJob, job);
        
        // 设置新ID
        job.setId(UUID.randomUUID().toString());
        
        // 处理变量
        if (job.getJobData() != null) {
            Map<String, Object> jobData = new HashMap<>(job.getJobData());
            replaceVariables(jobData, variables);
            job.setJobData(jobData);
        }
        
        return job;
    }
    
    private void replaceVariables(Map<String, Object> data, 
            Map<String, Object> variables) {
        for (Map.Entry<String, Object> entry : data.entrySet()) {
            Object value = entry.getValue();
            if (value instanceof String) {
                entry.setValue(replaceVariableInString(
                    (String) value, variables));
            } else if (value instanceof Map) {
                @SuppressWarnings("unchecked")
                Map<String, Object> map = (Map<String, Object>) value;
                replaceVariables(map, variables);
            } else if (value instanceof List) {
                @SuppressWarnings("unchecked")
                List<Object> list = (List<Object>) value;
                replaceVariablesInList(list, variables);
            }
        }
    }
    
    private void replaceVariablesInList(List<Object> list, 
            Map<String, Object> variables) {
        for (int i = 0; i < list.size(); i++) {
            Object value = list.get(i);
            if (value instanceof String) {
                list.set(i, replaceVariableInString(
                    (String) value, variables));
            } else if (value instanceof Map) {
                @SuppressWarnings("unchecked")
                Map<String, Object> map = (Map<String, Object>) value;
                replaceVariables(map, variables);
            } else if (value instanceof List) {
                @SuppressWarnings("unchecked")
                List<Object> subList = (List<Object>) value;
                replaceVariablesInList(subList, variables);
            }
        }
    }
    
    private String replaceVariableInString(String text, 
            Map<String, Object> variables) {
        for (Map.Entry<String, Object> var : variables.entrySet()) {
            String placeholder = "${" + var.getKey() + "}";
            if (text.contains(placeholder)) {
                text = text.replace(placeholder, 
                    String.valueOf(var.getValue()));
            }
        }
        return text;
    }
}

@Slf4j
@Component
public class BatchTaskExecutor {

    @Autowired
    private JobManager jobManager;
    
    @Autowired
    private ExecutorService executorService;

    public BatchExecutionResult executeBatchTasks(List<JobDefinition> jobs, 
            BatchExecutionOptions options) {
        BatchExecutionResult result = new BatchExecutionResult();
        
        // 创建执行计划
        ExecutionPlan plan = createExecutionPlan(jobs, options);
        
        // 执行任务
        if (options.isParallel()) {
            executeParallel(plan, result);
        } else {
            executeSequential(plan, result);
        }
        
        return result;
    }
    
    private ExecutionPlan createExecutionPlan(List<JobDefinition> jobs, 
            BatchExecutionOptions options) {
        // 根据选项对任务进行分组和排序
        List<JobDefinition> plannedJobs = new ArrayList<>(jobs);
        
        if (options.getMaxConcurrent() != null) {
            // 限制并发数的分组
            return new ExecutionPlan(partition(plannedJobs, 
                options.getMaxConcurrent()));
        }
        
        return new ExecutionPlan(Collections.singletonList(plannedJobs));
    }
    
    private void executeParallel(ExecutionPlan plan, BatchExecutionResult result) {
        CountDownLatch latch = new CountDownLatch(plan.getTotalJobs());
        
        // 执行每个分组
        for (List<JobDefinition> batch : plan.getBatches()) {
            List<Future<ExecutionResult>> futures = new ArrayList<>();
            
            // 提交任务
            for (JobDefinition job : batch) {
                futures.add(executorService.submit(() -> {
                    try {
                        return executeJob(job);
                    } finally {
                        latch.countDown();
                    }
                }));
            }
            
            // 收集结果
            collectResults(futures, result);
        }
        
        try {
            latch.await();
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new BatchExecutionException("Batch execution interrupted", e);
        }
    }
    
    private void executeSequential(ExecutionPlan plan, BatchExecutionResult result) {
        for (List<JobDefinition> batch : plan.getBatches()) {
            for (JobDefinition job : batch) {
                try {
                    ExecutionResult execResult = executeJob(job);
                    result.addResult(job.getId(), execResult);
                } catch (Exception e) {
                    log.error("Failed to execute job: {}", job.getId(), e);
                    result.addFailure(job.getId(), e);
                    if (!plan.getContinueOnError()) {
                        throw new BatchExecutionException(
                            "Batch execution failed", e);
                    }
                }
            }
        }
    }
    
    private ExecutionResult executeJob(JobDefinition job) {
        return jobManager.executeJob(job.getId(), new JobExecuteRequest());
    }
    
    private void collectResults(List<Future<ExecutionResult>> futures, 
            BatchExecutionResult result) {
        for (Future<ExecutionResult> future : futures) {
            try {
                ExecutionResult execResult = future.get();
                result.addResult(execResult.getJobId(), execResult);
            } catch (Exception e) {
                log.error("Failed to get execution result", e);
                result.addFailure("unknown", e);
            }
        }
    }
    
    private <T> List<List<T>> partition(List<T> list, int size) {
        List<List<T>> partitions = new ArrayList<>();
        for (int i = 0; i < list.size(); i += size) {
            partitions.add(list.subList(i, 
                Math.min(i + size, list.size())));
        }
        return partitions;
    }
}

```

需要我继续实现Common层的组件吗？包括常量定义、工具类和异常定义等。好的，让我们实现Common层的组件，从常量定义开始：



```java
package com.study.scheduler.common.constant;

public class JobConstant {
    // 任务状态
    public static final String STATUS_CREATED = "CREATED";
    public static final String STATUS_WAITING = "WAITING";
    public static final String STATUS_RUNNING = "RUNNING";
    public static final String STATUS_COMPLETED = "COMPLETED";
    public static final String STATUS_FAILED = "FAILED";
    public static final String STATUS_STOPPED = "STOPPED";
    
    // 任务类型
    public static final String TYPE_HTTP = "HTTP";
    public static final String TYPE_SHELL = "SHELL";
    public static final String TYPE_BATCH = "BATCH";
    public static final String TYPE_DEFAULT = "DEFAULT";
    
    // 任务日志类型
    public static final String LOG_TYPE_INFO = "INFO";
    public static final String LOG_TYPE_ERROR = "ERROR";
    public static final String LOG_TYPE_DEBUG = "DEBUG";
    
    // 任务超时配置
    public static final long DEFAULT_TIMEOUT = 60000L;
    public static final long MAX_TIMEOUT = 3600000L;
    
    // 重试配置
    public static final int DEFAULT_MAX_RETRIES = 3;
    public static final long DEFAULT_RETRY_INTERVAL = 1000L;
}

public class MqConstant {
    // 交换机
    public static final String EXCHANGE_JOB = "scheduler.job";
    public static final String EXCHANGE_ALERT = "scheduler.alert";
    
    // 队列
    public static final String QUEUE_JOB_EXECUTION = "job.execution.queue";
    public static final String QUEUE_JOB_CALLBACK = "job.callback.queue";
    public static final String QUEUE_ALERT = "alert.queue";
    
    // 路由键
    public static final String ROUTING_JOB_EXECUTION = "job.execution";
    public static final String ROUTING_JOB_CALLBACK = "job.callback";
    public static final String ROUTING_ALERT = "alert";
    
    // 消息属性
    public static final String HEADER_RETRY_COUNT = "x-retry-count";
    public static final String HEADER_ORIGINAL_QUEUE = "x-original-queue";
}

public class SystemConstant {
    // 缓存相关
    public static final String CACHE_PREFIX_JOB = "scheduler:job:";
    public static final String CACHE_PREFIX_EXECUTION = "scheduler:execution:";
    public static final String CACHE_PREFIX_LOCK = "scheduler:lock:";
    
    // 锁超时时间
    public static final long LOCK_TIMEOUT_SECONDS = 60L;
    public static final long LOCK_WAIT_SECONDS = 5L;
    
    // 线程池配置
    public static final int CORE_POOL_SIZE = 10;
    public static final int MAX_POOL_SIZE = 20;
    public static final int QUEUE_CAPACITY = 500;
    public static final long KEEP_ALIVE_SECONDS = 300L;
    
    // 监控配置
    public static final long METRICS_INTERVAL_SECONDS = 60L;
    public static final long CLEANUP_INTERVAL_SECONDS = 86400L;
}

```

现在实现工具类：

```java
package com.study.scheduler.common.utils;

import lombok.extern.slf4j.Slf4j;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.UUID;

@Slf4j
public class DateUtils {
    private static final String DEFAULT_PATTERN = "yyyy-MM-dd HH:mm:ss";
    private static final SimpleDateFormat DEFAULT_FORMAT = new SimpleDateFormat(DEFAULT_PATTERN);
    
    public static String formatDate(Date date) {
        return date != null ? DEFAULT_FORMAT.format(date) : null;
    }
    
    public static Date parseDate(String dateStr) {
        try {
            return dateStr != null ? DEFAULT_FORMAT.parse(dateStr) : null;
        } catch (Exception e) {
            log.error("Failed to parse date: {}", dateStr, e);
            return null;
        }
    }
    
    public static long getIntervalMillis(Date start, Date end) {
        return end != null && start != null ? 
            end.getTime() - start.getTime() : 0;
    }
    
    public static Date addSeconds(Date date, int seconds) {
        if (date == null) {
            return null;
        }
        Calendar cal = Calendar.getInstance();
        cal.setTime(date);
        cal.add(Calendar.SECOND, seconds);
        return cal.getTime();
    }
}

@Slf4j
public class JsonUtils {
    private static final ObjectMapper objectMapper = new ObjectMapper()
        .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)
        .registerModule(new JavaTimeModule());
        
    public static String toJson(Object obj) {
        try {
            return obj != null ? objectMapper.writeValueAsString(obj) : null;
        } catch (Exception e) {
            log.error("Failed to serialize object to JSON", e);
            return null;
        }
    }
    
    public static <T> T fromJson(String json, Class<T> clazz) {
        try {
            return json != null ? objectMapper.readValue(json, clazz) : null;
        } catch (Exception e) {
            log.error("Failed to deserialize JSON to object", e);
            return null;
        }
    }
    
    public static <T> T fromJson(String json, TypeReference<T> typeRef) {
        try {
            return json != null ? objectMapper.readValue(json, typeRef) : null;
        } catch (Exception e) {
            log.error("Failed to deserialize JSON to object", e);
            return null;
        }
    }
}

@Slf4j
public class LockUtils {
    private static final String LOCK_KEY_FORMAT = "lock:%s:%s";
    
    public static String generateLockKey(String type, String id) {
        return String.format(LOCK_KEY_FORMAT, type, id);
    }
    
    public static String getLockValue() {
        return UUID.randomUUID().toString();
    }
    
    public static boolean isLockOwner(String storedValue, String expectedValue) {
        return storedValue != null && storedValue.equals(expectedValue);
    }
}

@Slf4j
public class ThreadUtils {
    public static void sleep(long millis) {
        try {
            Thread.sleep(millis);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            log.warn("Thread sleep interrupted", e);
        }
    }
    
    public static String getThreadName() {
        return Thread.currentThread().getName();
    }
    
    public static boolean isInterrupted() {
        return Thread.currentThread().isInterrupted();
    }
    
    public static void checkInterrupted() throws InterruptedException {
        if (isInterrupted()) {
            throw new InterruptedException("Thread is interrupted");
        }
    }
}

@Slf4j
public class ValidationUtils {
    public static void notNull(Object obj, String message) {
        if (obj == null) {
            throw new IllegalArgumentException(message);
        }
    }
    
    public static void notEmpty(String str, String message) {
        if (str == null || str.trim().isEmpty()) {
            throw new IllegalArgumentException(message);
        }
    }
    
    public static void notEmpty(Collection<?> collection, String message) {
        if (collection == null || collection.isEmpty()) {
            throw new IllegalArgumentException(message);
        }
    }
    
    public static void isTrue(boolean condition, String message) {
        if (!condition) {
            throw new IllegalArgumentException(message);
        }
    }
    
    public static void inRange(long value, long min, long max, String message) {
        if (value < min || value > max) {
            throw new IllegalArgumentException(message);
        }
    }
}

```

让我继续实现异常定义：

```java
package com.study.scheduler.common.exception;

public class JobException extends RuntimeException {
    public JobException(String message) {
        super(message);
    }
    
    public JobException(String message, Throwable cause) {
        super(message, cause);
    }
}

public class TaskExecutionException extends JobException {
    private final String jobId;
    private final String executionId;
    
    public TaskExecutionException(String message, String jobId, String executionId) {
        super(message);
        this.jobId = jobId;
        this.executionId = executionId;
    }
    
    public TaskExecutionException(String message, String jobId, String executionId, 
            Throwable cause) {
        super(message, cause);
        this.jobId = jobId;
        this.executionId = executionId;
    }
    
    public String getJobId() {
        return jobId;
    }
    
    public String getExecutionId() {
        return executionId;
    }
}

public class DistributedLockException extends RuntimeException {
    private final String lockKey;
    private final long waitTime;
    
    public DistributedLockException(String message, String lockKey, long waitTime) {
        super(message);
        this.lockKey = lockKey;
        this.waitTime = waitTime;
    }
    
    public String getLockKey() {
        return lockKey;
    }
    
    public long getWaitTime() {
        return waitTime;
    }
}

public class TemplateProcessException extends RuntimeException {
    private final String templateId;
    
    public TemplateProcessException(String message, String templateId) {
        super(message);
        this.templateId = templateId;
    }
    
    public TemplateProcessException(String message, String templateId, 
            Throwable cause) {
        super(message, cause);
        this.templateId = templateId;
    }
    
    public String getTemplateId() {
        return templateId;
    }
}

public class BatchExecutionException extends RuntimeException {
    private final List<String> failedJobs;
    
    public BatchExecutionException(String message, List<String> failedJobs) {
        super(message);
        this.failedJobs = failedJobs;
    }
    
    public BatchExecutionException(String message, List<String> failedJobs, 
            Throwable cause) {
        super(message, cause);
        this.failedJobs = failedJobs;
    }
    
    public List<String> getFailedJobs() {
        return failedJobs;
    }
}

public class SystemException extends RuntimeException {
    private final String errorCode;
    
    public SystemException(String message, String errorCode) {
        super(message);
        this.errorCode = errorCode;
    }
    
    public SystemException(String message, String errorCode, Throwable cause) {
        super(message, cause);
        this.errorCode = errorCode;
    }
    
    public String getErrorCode() {
        return errorCode;
    }
}

```

需要我继续实现其他组件或补充任何遗漏的部分吗？让我们补充一些遗漏的关键组件。首先是全局异常处理和接口响应封装：



```java
package com.study.scheduler.api.handler;

import com.study.common.util.Result;
import lombok.extern.slf4j.Slf4j;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.RestControllerAdvice;

@Slf4j
@RestControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(JobException.class)
    public Result<Void> handleJobException(JobException e) {
        log.error("Job execution error", e);
        return Result.error(400, e.getMessage());
    }

    @ExceptionHandler(TaskExecutionException.class)
    public Result<Void> handleTaskExecutionException(TaskExecutionException e) {
        log.error("Task execution error - JobId: {}, ExecutionId: {}", 
            e.getJobId(), e.getExecutionId(), e);
        return Result.error(500, "Task execution failed: " + e.getMessage());
    }

    @ExceptionHandler(DistributedLockException.class)
    public Result<Void> handleLockException(DistributedLockException e) {
        log.error("Failed to acquire lock - Key: {}, WaitTime: {}", 
            e.getLockKey(), e.getWaitTime(), e);
        return Result.error(409, "Resource is locked: " + e.getMessage());
    }

    @ExceptionHandler(TemplateProcessException.class)
    public Result<Void> handleTemplateException(TemplateProcessException e) {
        log.error("Template processing error - TemplateId: {}", 
            e.getTemplateId(), e);
        return Result.error(400, "Template processing failed: " + e.getMessage());
    }

    @ExceptionHandler(BatchExecutionException.class)
    public Result<Map<String, Object>> handleBatchException(BatchExecutionException e) {
        log.error("Batch execution error - Failed jobs: {}", 
            e.getFailedJobs(), e);
        Map<String, Object> details = new HashMap<>();
        details.put("failedJobs", e.getFailedJobs());
        return Result.error(500, "Batch execution failed")
            .setData(details);
    }

    @ExceptionHandler(SystemException.class)
    public Result<Void> handleSystemException(SystemException e) {
        log.error("System error - Code: {}", e.getErrorCode(), e);
        return Result.error(500, "System error: " + e.getMessage())
            .setCode(Integer.parseInt(e.getErrorCode()));
    }

    @ExceptionHandler(Exception.class)
    public Result<Void> handleException(Exception e) {
        log.error("Unexpected error", e);
        return Result.error(500, "Internal server error");
    }
}

// 统一响应格式包装器
@Aspect
@Component
@Slf4j
public class ResponseWrapper {

    @Pointcut("@annotation(org.springframework.web.bind.annotation.ResponseBody) || " +
              "@annotation(org.springframework.web.bind.annotation.RestController)")
    public void responsePointcut() {}

    @Around("responsePointcut()")
    public Object wrapResponse(ProceedingJoinPoint point) throws Throwable {
        Object result = point.proceed();
        
        // 已经是Result类型的不需要再包装
        if (result instanceof Result) {
            return result;
        }
        
        // 包装响应结果
        return Result.success(result);
    }
}

```

还需要添加拦截器和AOP切面:

```java
package com.study.scheduler.api.interceptor;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;
import org.springframework.web.servlet.HandlerInterceptor;

@Slf4j
@Component
public class RequestLogInterceptor implements HandlerInterceptor {

    @Override
    public boolean preHandle(HttpServletRequest request, 
            HttpServletResponse response, Object handler) {
        request.setAttribute("startTime", System.currentTimeMillis());
        
        if (log.isDebugEnabled()) {
            log.debug("Request started - Method: {}, URI: {}", 
                request.getMethod(), request.getRequestURI());
        }
        
        return true;
    }

    @Override
    public void afterCompletion(HttpServletRequest request, 
            HttpServletResponse response, Object handler, Exception ex) {
        Long startTime = (Long) request.getAttribute("startTime");
        long duration = System.currentTimeMillis() - startTime;
        
        log.info("Request completed - Method: {}, URI: {}, Status: {}, Duration: {}ms", 
            request.getMethod(), request.getRequestURI(), 
            response.getStatus(), duration);
        
        if (ex != null) {
            log.error("Request failed", ex);
        }
    }
}

@Aspect
@Component
@Slf4j
public class MetricsAspect {

    @Autowired
    private MetricsManager metricsManager;

    @Around("@annotation(com.study.scheduler.api.annotation.MetricsMonitor)")
    public Object recordMetrics(ProceedingJoinPoint point) throws Throwable {
        String methodName = point.getSignature().getName();
        long startTime = System.currentTimeMillis();
        
        try {
            Object result = point.proceed();
            
            // 记录成功指标
            metricsManager.recordMethodExecution(methodName, 
                System.currentTimeMillis() - startTime, true);
                
            return result;
            
        } catch (Throwable e) {
            // 记录失败指标
            metricsManager.recordMethodExecution(methodName, 
                System.currentTimeMillis() - startTime, false);
                
            throw e;
        }
    }
}

@Aspect
@Component
@Slf4j
public class LockAspect {

    @Autowired
    private DistributedLock distributedLock;

    @Around("@annotation(com.study.scheduler.api.annotation.DistributedLocked)")
    public Object withLock(ProceedingJoinPoint point) throws Throwable {
        MethodSignature signature = (MethodSignature) point.getSignature();
        DistributedLocked annotation = signature.getMethod()
            .getAnnotation(DistributedLocked.class);
            
        String lockKey = getLockKey(point, annotation);
        
        if (!distributedLock.tryLock(lockKey, annotation.waitTime(), 
                TimeUnit.SECONDS)) {
            throw new DistributedLockException(
                "Failed to acquire lock", lockKey, annotation.waitTime());
        }
        
        try {
            return point.proceed();
        } finally {
            distributedLock.unlock(lockKey);
        }
    }

    private String getLockKey(ProceedingJoinPoint point, 
            DistributedLocked annotation) {
        // 支持SpEL表达式解析
        String key = annotation.key();
        if (key.contains("#")) {
            EvaluationContext context = createEvaluationContext(point);
            Expression expression = new SpelExpressionParser().parseExpression(key);
            return expression.getValue(context, String.class);
        }
        return key;
    }
}

```

还需要添加启动类和配置类：

```java
package com.study.scheduler;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
@EnableScheduling
@EnableAsync
@EnableAspectJAutoProxy
public class SchedulerApplication {
    public static void main(String[] args) {
        SpringApplication.run(SchedulerApplication.class, args);
    }
}

@Configuration
public class WebConfig implements WebMvcConfigurer {

    @Autowired
    private RequestLogInterceptor requestLogInterceptor;

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(requestLogInterceptor);
    }

    @Override
    public void configureMessageConverters(List<HttpMessageConverter<?>> converters) {
        converters.add(0, new MappingJackson2HttpMessageConverter());
    }

    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping("/**")
            .allowedOrigins("*")
            .allowedMethods("*")
            .allowedHeaders("*");
    }
}

@Configuration
public class AsyncConfig implements AsyncConfigurer {

    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(10);
        executor.setMaxPoolSize(20);
        executor.setQueueCapacity(500);
        executor.setThreadNamePrefix("async-");
        executor.initialize();
        return executor;
    }

    @Override
    public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
        return new SimpleAsyncUncaughtExceptionHandler();
    }
}

@Configuration
@EnableCaching
public class CacheConfig {

    @Bean
    public CacheManager cacheManager(RedisConnectionFactory factory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofMinutes(10))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new GenericJackson2JsonRedisSerializer()));

        return RedisCacheManager.builder(factory)
            .cacheDefaults(config)
            .build();
    }
}

```

还需要我补充任何其他组件吗？比如测试类、文档注解或其他功能？让我们添加测试类和相关测试配置：



```java
package com.study.scheduler.test.unit;

import com.study.scheduler.core.executor.*;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.InjectMocks;
import org.mockito.Mock;
import org.mockito.junit.jupiter.MockitoExtension;

@ExtendWith(MockitoExtension.class)
class JobExecutorTest {

    @Mock
    private ExecutionManager executionManager;

    @InjectMocks
    private DefaultJobExecutor jobExecutor;

    @Test
    void shouldExecuteJobSuccessfully() {
        // Given
        ExecuteContext context = new ExecuteContext();
        context.setJobId("test-job");
        context.setExecutionId("test-execution");
        
        // When
        ExecuteResult result = jobExecutor.execute(context);
        
        // Then
        assertThat(result.isSuccess()).isTrue();
        verify(executionManager).saveExecution(any());
    }

    @Test
    void shouldHandleExecutionFailure() {
        // Given
        ExecuteContext context = new ExecuteContext();
        context.setJobId("test-job");
        
        when(executionManager.saveExecution(any()))
            .thenThrow(new RuntimeException("Execution failed"));
        
        // When
        ExecuteResult result = jobExecutor.execute(context);
        
        // Then
        assertThat(result.isSuccess()).isFalse();
        assertThat(result.getError()).contains("Execution failed");
    }
}

@ExtendWith(MockitoExtension.class)
class BatchTaskExecutorTest {

    @Mock
    private JobManager jobManager;

    @Mock
    private ExecutorService executorService;

    @InjectMocks
    private BatchTaskExecutor batchTaskExecutor;

    @Test
    void shouldExecuteBatchTasksInParallel() {
        // Given
        List<JobDefinition> jobs = Arrays.asList(
            createJobDefinition("job1"),
            createJobDefinition("job2")
        );
        
        BatchExecutionOptions options = new BatchExecutionOptions();
        options.setParallel(true);
        
        when(jobManager.executeJob(anyString(), any()))
            .thenReturn(ExecuteResult.success("OK"));
        
        // When
        BatchExecutionResult result = batchTaskExecutor.executeBatchTasks(jobs, options);
        
        // Then
        assertThat(result.getSuccessCount()).isEqualTo(2);
        assertThat(result.getFailureCount()).isZero();
    }

    @Test
    void shouldHandlePartialFailureInBatch() {
        // Given
        List<JobDefinition> jobs = Arrays.asList(
            createJobDefinition("job1"),
            createJobDefinition("job2")
        );
        
        when(jobManager.executeJob(eq("job1"), any()))
            .thenReturn(ExecuteResult.success("OK"));
        when(jobManager.executeJob(eq("job2"), any()))
            .thenReturn(ExecuteResult.failure("Failed"));
        
        // When
        BatchExecutionResult result = batchTaskExecutor.executeBatchTasks(
            jobs, new BatchExecutionOptions());
        
        // Then
        assertThat(result.getSuccessCount()).isEqualTo(1);
        assertThat(result.getFailureCount()).isEqualTo(1);
    }

    private JobDefinition createJobDefinition(String id) {
        return JobDefinition.builder()
            .id(id)
            .name("Test Job")
            .jobType("TEST")
            .build();
    }
}

```

让我们添加集成测试：

```java
package com.study.scheduler.test.integration;

import com.study.scheduler.api.controller.job.*;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.web.servlet.MockMvc;

@SpringBootTest
@AutoConfigureMockMvc
@ActiveProfiles("test")
class JobApiIntegrationTest {

    @Autowired
    private MockMvc mockMvc;

    @Autowired 
    private JobManager jobManager;

    @Test
    void shouldCreateAndExecuteJob() throws Exception {
        // Given
        JobCreateRequest request = JobCreateRequest.builder()
            .name("Test Job")
            .jobType("HTTP")
            .cronExpression("0 0 * * * ?")
            .jobData(Map.of("url", "http://test.com"))
            .build();
            
        // When
        String jobId = createJob(request);
        
        // Then
        mockMvc.perform(post("/api/jobs/{id}/execute", jobId))
            .andExpect(status().isOk())
            .andExpect(jsonPath("$.success").value(true));
            
        await().atMost(5, TimeUnit.SECONDS)
            .until(() -> isJobCompleted(jobId));
    }

    @Test
    void shouldHandleBatchExecution() throws Exception {
        // Given
        List<JobCreateRequest> requests = Arrays.asList(
            createHttpJobRequest("job1", "http://test1.com"),
            createHttpJobRequest("job2", "http://test2.com")
        );
        
        // When
        mockMvc.perform(post("/api/jobs/batch")
                .contentType(MediaType.APPLICATION_JSON)
                .content(JsonUtils.toJson(requests)))
            .andExpect(status().isOk())
            .andExpect(jsonPath("$.data.successCount").value(2));
    }

    private String createJob(JobCreateRequest request) throws Exception {
        MvcResult result = mockMvc.perform(post("/api/jobs")
                .contentType(MediaType.APPLICATION_JSON)
                .content(JsonUtils.toJson(request)))
            .andExpect(status().isOk())
            .andReturn();
            
        return JsonPath.read(result.getResponse().getContentAsString(), 
            "$.data.id");
    }

    private boolean isJobCompleted(String jobId) {
        return jobManager.getJobStatus(jobId).equals(TaskStatus.COMPLETED);
    }
}

@SpringBootTest
@ActiveProfiles("test")
class SchedulerIntegrationTest {

    @Autowired
    private JobScheduler jobScheduler;

    @Autowired
    private JobRepository jobRepository;

    @Test
    void shouldScheduleAndExecuteCronJob() {
        // Given
        JobDefinition job = createCronJob();
        jobRepository.save(job);
        
        // When
        jobScheduler.scheduleJob(job);
        
        // Then
        await().atMost(65, TimeUnit.SECONDS)
            .until(() -> hasExecutionRecord(job.getId()));
    }

    @Test
    void shouldHandleJobFailureAndRetry() {
        // Given
        JobDefinition job = createFailingJob();
        jobRepository.save(job);
        
        // When
        jobScheduler.scheduleJob(job);
        
        // Then
        await().atMost(10, TimeUnit.SECONDS)
            .until(() -> getRetryCount(job.getId()) == 3);
    }

    private JobDefinition createCronJob() {
        return JobDefinition.builder()
            .id(UUID.randomUUID().toString())
            .name("Cron Test Job")
            .jobType("TEST")
            .cronExpression("*/1 * * * * ?") // Every minute
            .build();
    }

    private JobDefinition createFailingJob() {
        return JobDefinition.builder()
            .id(UUID.randomUUID().toString())
            .name("Failing Job")
            .jobType("TEST")
            .cronExpression("*/1 * * * * ?")
            .maxRetries(3)
            .retryInterval(1000L)
            .build();
    }
}

```

让我们添加测试配置文件：

```java
# application-test.yml
spring:
  datasource:
    driver-class-name: org.h2.Driver
    url: jdbc:h2:mem:testdb;DB_CLOSE_DELAY=-1
    username: sa
    password: 
    
  data:
    mongodb:
      host: localhost
      port: 0
      database: test
    
  redis:
    host: localhost
    port: 6379
    database: 1
    
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
    
scheduler:
  cluster:
    enabled: false
  execution:
    pool:
      core-size: 5
      max-size: 10
      queue-capacity: 25
      
logging:
  level:
    com.study.scheduler: DEBUG

# TestConfig.java
@Configuration
@Profile("test")
public class TestConfig {

    @Bean
    public JobExecutor testJobExecutor() {
        return new TestJobExecutor();
    }
    
    @Bean
    @Primary
    public MongoTemplate mongoTemplate() throws Exception {
        MongodStarter starter = MongodStarter.getDefaultInstance();
        
        IMongodConfig mongodConfig = new MongodConfigBuilder()
            .version(Version.Main.PRODUCTION)
            .net(new Net("localhost", 0, Network.localhostIsIPv6()))
            .build();
            
        MongodExecutable mongodExecutable = starter.prepare(mongodConfig);
        mongodExecutable.start();
        
        return new MongoTemplate(
            new MongoClient("localhost", mongodConfig.net().getPort()), 
            "test"
        );
    }
    
    @Bean
    @Primary
    public RedisConnectionFactory redisConnectionFactory() {
        RedisServer redisServer = new RedisServer(6379);
        redisServer.start();
        return new LettuceConnectionFactory();
    }
}

# Test Job Executor
@Component
public class TestJobExecutor implements JobExecutor {

    @Override
    public String getType() {
        return "TEST";
    }
    
    @Override
    public ExecuteResult execute(ExecuteContext context) {
        if (context.getJobData() != null && 
            Boolean.TRUE.equals(context.getJobData().get("fail"))) {
            return ExecuteResult.failure("Test failure");
        }
        return ExecuteResult.success("Test success");
    }
}

```

需要我继续添加文档注解、API文档或其他组件吗？让我们添加API文档相关的注解和配置：



```java
package com.study.scheduler.api.config;

import io.swagger.v3.oas.models.OpenAPI;
import io.swagger.v3.oas.models.info.Info;
import io.swagger.v3.oas.models.info.Contact;
import org.springdoc.core.models.GroupedOpenApi;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class OpenApiConfig {

    @Bean
    public OpenAPI schedulerOpenAPI() {
        return new OpenAPI()
            .info(new Info()
                .title("Distributed Scheduler API")
                .description("API documentation for the distributed task scheduler system")
                .version("1.0.0")
                .contact(new Contact()
                    .name("Development Team")
                    .email("dev@example.com")));
    }

    @Bean
    public GroupedOpenApi jobApi() {
        return GroupedOpenApi.builder()
            .group("jobs")
            .pathsToMatch("/api/jobs/**")
            .packagesToScan("com.study.scheduler.api.controller.job")
            .build();
    }

    @Bean
    public GroupedOpenApi monitorApi() {
        return GroupedOpenApi.builder()
            .group("monitor")
            .pathsToMatch("/api/monitor/**")
            .packagesToScan("com.study.scheduler.api.controller.monitor")
            .build();
    }
}

// 在Controller中添加的API文档注解示例：
@Tag(name = "Job Management", description = "APIs for managing scheduler jobs")
@RestController
@RequestMapping("/api/jobs")
public class JobController {

    @Operation(summary = "Create a new job",
              description = "Creates a new job with the specified configuration")
    @ApiResponse(responseCode = "200", description = "Job created successfully")
    @ApiResponse(responseCode = "400", description = "Invalid job configuration")
    @PostMapping
    public Result<JobVO> createJob(
            @Parameter(description = "Job creation request", required = true)
            @RequestBody JobCreateRequest request) {
        // ...
    }

    @Operation(summary = "Execute a job",
              description = "Triggers the execution of an existing job")
    @ApiResponse(responseCode = "200", description = "Job execution started")
    @ApiResponse(responseCode = "404", description = "Job not found")
    @PostMapping("/{id}/execute")
    public Result<ExecuteResult> executeJob(
            @Parameter(description = "Job ID", required = true)
            @PathVariable String id,
            @Parameter(description = "Execution parameters")
            @RequestBody JobExecuteRequest request) {
        // ...
    }
}

@Tag(name = "Monitoring", description = "APIs for system monitoring")
@RestController
@RequestMapping("/api/monitor")
public class MonitorController {

    @Operation(summary = "Get system metrics",
              description = "Retrieves current system performance metrics")
    @GetMapping("/metrics")
    public Result<Map<String, Object>> getSystemMetrics() {
        // ...
    }

    @Operation(summary = "Get active alerts",
              description = "Retrieves list of currently active alerts")
    @GetMapping("/alerts")
    public Result<List<AlertVO>> getActiveAlerts() {
        // ...
    }
}

```

添加一些自定义注解：

```java
package com.study.scheduler.api.annotation;

import java.lang.annotation.*;

@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface MetricsMonitor {
    String value() default "";
    String[] tags() default {};
}

@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface DistributedLocked {
    String key();
    long waitTime() default 5;
    long leaseTime() default 30;
}

@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface RateLimited {
    String key();
    int limit() default 100;
    int period() default 60;
}

@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface AccessLog {
    String module();
    String operation();
    boolean includeRequest() default false;
    boolean includeResponse() default false;
}

@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface Idempotent {
    String key();
    long expireTime() default 3600;
    boolean async() default false;
}

```

让我们添加一个简单的API调用示例文档：

```markdown
# Scheduler API Examples

## Job Management

### Create a Job
```http
POST /api/jobs
Content-Type: application/json

{
    "name": "Daily Report",
    "description": "Generate daily sales report",
    "jobType": "HTTP",
    "cronExpression": "0 0 1 * * ?",
    "timeout": 3600000,
    "maxRetries": 3,
    "retryInterval": 300000,
    "jobData": {
        "url": "http://reports.example.com/daily",
        "method": "POST",
        "headers": {
            "Authorization": "${token:system}"
        },
        "body": {
            "date": "#{T(java.time.LocalDate).now()}"
        }
    }
}
```

### Execute a Job
```http
POST /api/jobs/{jobId}/execute
Content-Type: application/json

{
    "parameters": {
        "reportDate": "2024-03-15"
    },
    "async": true
}
```

### Create Batch Jobs
```http
POST /api/jobs/batch
Content-Type: application/json

{
    "templateId": "daily-report",
    "batchVariables": [
        {
            "region": "APAC",
            "reportType": "SALES"
        },
        {
            "region": "EMEA",
            "reportType": "INVENTORY"
        }
    ]
}
```

## Monitoring

### Get System Metrics
```http
GET /api/monitor/metrics
```

### Query Alerts
```http
GET /api/monitor/alerts?level=ERROR&startTime=1615766400000&endTime=1615852800000
```

## Best Practices

1. Error Handling
```java
try {
    JobVO job = jobClient.createJob(request);
} catch (JobException e) {
    log.error("Failed to create job", e);
    // Handle job-specific errors
} catch (Exception e) {
    log.error("Unexpected error", e);
    // Handle unexpected errors
}
```

2. Retry Handling
```java
RetryTemplate template = RetryTemplate.builder()
    .maxAttempts(3)
    .exponentialBackoff(1000, 2, 10000)
    .build();

template.execute(context -> jobClient.executeJob(jobId));
```

3. Batch Processing
```java
BatchExecutionOptions options = BatchExecutionOptions.builder()
    .parallel(true)
    .maxConcurrent(5)
    .continueOnError(true)
    .build();

BatchExecutionResult result = jobClient.executeBatch(jobs, options);
```

```

需要我继续添加其他文档或组件吗？例如部署文档、性能测试脚本或监控配置等。让我们添加部署相关的文档和配置：



```markdown
# Scheduler Deployment Guide

## 1. System Requirements

### Hardware Requirements
- CPU: 4+ cores
- Memory: 8GB+ RAM
- Disk: 100GB+ SSD
- Network: 1Gbps+

### Software Requirements
- JDK 21+
- Docker 24.0+
- Kubernetes 1.28+
- MySQL 8.0+/MariaDB 10.11+
- Redis 7.2+ (Cluster)
- RabbitMQ 3.12+
- MongoDB 7.0+

## 2. Environment Setup

### 2.1 Database Setup
```sql
-- Create Database
CREATE DATABASE scheduler DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- Create User
CREATE USER 'scheduler'@'%' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON scheduler.* TO 'scheduler'@'%';
FLUSH PRIVILEGES;

-- Initialize Tables
source init-schema.sql
```

### 2.2 Redis Cluster Setup
```bash
# Deploy Redis Cluster
kubectl apply -f k8s/redis/
kubectl get pods -l app=redis-cluster

# Verify Cluster
redis-cli -h redis-cluster -c ping
```

### 2.3 RabbitMQ Setup
```bash
# Deploy RabbitMQ
kubectl apply -f k8s/rabbitmq/
kubectl get pods -l app=rabbitmq

# Create Exchanges and Queues
rabbitmqadmin declare exchange name=scheduler.job type=topic
rabbitmqadmin declare queue name=job.execution.queue
rabbitmqadmin declare binding source=scheduler.job destination=job.execution.queue routing_key=job.execution
```

## 3. Application Deployment

### 3.1 Docker Build
```dockerfile
FROM eclipse-temurin:21-jre-alpine

WORKDIR /app
COPY target/scheduler.jar app.jar

ENV JAVA_OPTS="-Xms2g -Xmx4g -XX:+UseG1GC"
ENV TZ=Asia/Shanghai

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### 3.2 Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scheduler
  namespace: scheduler
spec:
  replicas: 3
  selector:
    matchLabels:
      app: scheduler
  template:
    metadata:
      labels:
        app: scheduler
    spec:
      containers:
      - name: scheduler
        image: scheduler:1.0.0
        ports:
        - containerPort: 8081
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: SERVER_PORT
          value: "8081"
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 20
```

## 4. Monitoring Setup

### 4.1 Prometheus Configuration
```yaml
scrape_configs:
  - job_name: 'scheduler'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 15s
    static_configs:
      - targets: ['scheduler:8081']
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
```

### 4.2 Grafana Dashboard
```json
{
  "dashboard": {
    "title": "Scheduler Monitoring",
    "panels": [
      {
        "title": "Job Execution Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(scheduler_job_executions_total[5m])",
            "legendFormat": "{{status}}"
          }
        ]
      },
      {
        "title": "Job Execution Duration",
        "type": "heatmap",
        "targets": [
          {
            "expr": "rate(scheduler_job_execution_duration_seconds_bucket[5m])"
          }
        ]
      }
    ]
  }
}
```

## 5. Production Checklist

### 5.1 Security Configuration
- Enable SSL/TLS
- Configure authentication
- Set up firewall rules
- Enable audit logging

### 5.2 Performance Tuning
- JVM tuning
- Connection pool settings
- Thread pool configuration
- Database indexing

### 5.3 Backup Strategy
- Database backup
- Configuration backup
- Log archival

### 5.4 Scaling Guidelines
- Horizontal scaling
- Vertical scaling
- Load balancing

```

让我们添加性能测试脚本：

```java
package com.study.scheduler.test.performance;

import org.junit.jupiter.api.Test;
import org.springframework.test.context.junit.jupiter.SpringJUnitConfig;
import io.gatling.javaapi.core.*;
import io.gatling.javaapi.http.*;
import java.time.Duration;

@SpringJUnitConfig
public class JobExecutionSimulation extends Simulation {

    HttpProtocolBuilder httpProtocol = http
        .baseUrl("http://localhost:8081")
        .acceptHeader("application/json")
        .contentTypeHeader("application/json");

    ScenarioBuilder createJobScenario = scenario("Create Job Scenario")
        .exec(http("create_job")
            .post("/api/jobs")
            .body(StringBody("""
                {
                    "name": "Test Job ${uniqueId}",
                    "jobType": "HTTP",
                    "cronExpression": "0 0/5 * * * ?",
                    "jobData": {
                        "url": "http://test.com",
                        "method": "GET"
                    }
                }
                """))
            .check(status().is(200))
            .check(jsonPath("$.data.id").saveAs("jobId")))
        .pause(1)
        .exec(http("execute_job")
            .post("/api/jobs/${jobId}/execute")
            .check(status().is(200)));

    ScenarioBuilder batchExecutionScenario = scenario("Batch Execution Scenario")
        .exec(http("batch_execute")
            .post("/api/jobs/batch")
            .body(StringBody("""
                {
                    "jobs": [
                        {
                            "name": "Batch Job 1",
                            "jobType": "HTTP"
                        },
                        {
                            "name": "Batch Job 2",
                            "jobType": "HTTP"
                        }
                    ]
                }
                """))
            .check(status().is(200)));

    @Test
    void loadTest() {
        setUp(
            createJobScenario.injectOpen(
                rampUsers(100).during(60),
                constantUsersPerSec(10).during(300)
            ),
            batchExecutionScenario.injectOpen(
                rampUsers(50).during(60),
                constantUsersPerSec(5).during(300)
            )
        ).protocols(httpProtocol)
         .assertions(
            global().responseTime().max().lt(5000),
            global().successfulRequests().percent().gt(95)
         );
    }
}

@Slf4j
public class JobPerformanceTest {

    private static final int CONCURRENT_USERS = 10;
    private static final int REQUESTS_PER_USER = 100;
    private static final int WARMUP_REQUESTS = 10;

    @Autowired
    private TestRestTemplate restTemplate;

    @Test
    void measureJobCreationPerformance() {
        // Warmup
        performWarmup();

        // Test
        long startTime = System.currentTimeMillis();
        List<CompletableFuture<Void>> futures = new ArrayList<>();

        for (int i = 0; i < CONCURRENT_USERS; i++) {
            futures.add(CompletableFuture.runAsync(() -> {
                for (int j = 0; j < REQUESTS_PER_USER; j++) {
                    createAndExecuteJob();
                }
            }));
        }

        // Wait for completion
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
        long duration = System.currentTimeMillis() - startTime;

        // Calculate metrics
        int totalRequests = CONCURRENT_USERS * REQUESTS_PER_USER;
        double throughput = totalRequests * 1000.0 / duration;
        log.info("Performance Test Results:");
        log.info("Total Requests: {}", totalRequests);
        log.info("Total Duration: {} ms", duration);
        log.info("Throughput: {:.2f} req/sec", throughput);
    }

    private void performWarmup() {
        for (int i = 0; i < WARMUP_REQUESTS; i++) {
            createAndExecuteJob();
            ThreadUtils.sleep(100);
        }
    }

    private void createAndExecuteJob() {
        try {
            JobCreateRequest request = createTestJobRequest();
            ResponseEntity<Result<JobVO>> response = restTemplate.postForEntity(
                "/api/jobs",
                request,
                new ParameterizedTypeReference<Result<JobVO>>() {}
            );

            if (response.getStatusCode() == HttpStatus.OK) {
                String jobId = response.getBody().getData().getId();
                executeJob(jobId);
            }
        } catch (Exception e) {
            log.error("Error in performance test", e);
        }
    }
}

```

需要我继续添加监控配置或其他组件吗？比如告警规则、容量规划指南等。我来帮你添加监控告警规则和容量规划指南。首先是监控告警规则配置：

```yaml
# alert-rules.yml
groups:
- name: job_execution_rules
  rules:
  # 任务执行成功率
  - alert: JobExecutionSuccessRateLow
    expr: sum(rate(scheduler_job_executions_total{status="success"}[5m])) / sum(rate(scheduler_job_executions_total[5m])) < 0.95
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Job execution success rate below 95%"
      description: "Success rate is {{ $value | humanizePercentage }} over last 5m"

  # 任务执行延迟 
  - alert: JobExecutionDelayHigh  
    expr: scheduler_job_execution_delay_seconds > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Job execution delay high"
      description: "Job {{ $labels.job_name }} execution delayed by {{ $value }} seconds"

  # 系统资源告警
  - alert: HighCPUUsage
    expr: avg by (instance) (scheduler_system_cpu_usage) > 0.85
    for: 5m
    labels:
      severity: warning
    annotations: 
      summary: "High CPU usage"
      description: "CPU usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"

  - alert: HighMemoryUsage
    expr: avg by (instance) (scheduler_system_memory_usage) > 0.9
    for: 5m
    labels:
      severity: warning  
    annotations:
      summary: "High memory usage"
      description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"

  # 队列堆积
  - alert: JobQueueBacklog
    expr: scheduler_job_queue_size > 1000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Job queue backlog"
      description: "Job queue size is {{ $value }}"
```

接下来是容量规划指南：

```markdown
# 调度系统容量规划指南

## 1. 系统规格

### 1.1 基础资源需求

#### 应用服务器
- CPU: 每个实例4核心(8 vCPU)
- 内存: 每个实例8GB 
- 磁盘: 每个实例50GB SSD
- 网络带宽: 1Gbps
- 实例数量: 根据负载情况设置,建议 N+2 架构

#### 数据库服务器
- CPU: 8核心(16 vCPU)  
- 内存: 32GB
- 磁盘: 
  - 系统盘: 100GB SSD
  - 数据盘: 500GB-1TB SSD
- IOPS: 至少5000

#### Redis集群
- 节点规格: 8GB内存, 4核心CPU
- 节点数量: 6个(3主3从)
- 网络带宽: 1Gbps

#### RabbitMQ集群
- 节点规格: 8GB内存, 4核心CPU
- 节点数量: 3个
- 磁盘: 100GB SSD

### 1.2 扩展建议

根据以下指标进行水平扩展:
- CPU利用率持续超过70%
- 内存使用率持续超过80% 
- 任务队列积压超过1000个
- 任务执行延迟超过5分钟

## 2. 性能指标

### 2.1 基准性能
- 单机任务执行能力: 100 jobs/second
- 批量任务处理能力: 1000 jobs/batch
- API响应时间: 99%请求 < 200ms
- 任务调度延迟: < 1s

### 2.2 关键指标阈值
- CPU使用率: < 70%
- 内存使用率: < 80%
- 磁盘使用率: < 75%
- 连接池使用率: < 80%
- GC暂停时间: < 200ms

## 3. 存储容量规划

### 3.1 数据增长预估
- 任务定义: ~1KB/record
- 执行记录: ~2KB/record  
- 任务日志: ~500B/record
- 系统日志: ~100MB/day/instance

### 3.2 存储需求计算
每月存储需求 = 
  (日任务量 * 30 * 记录大小) + 
  (日志量 * 30) +
  20% buffer

### 3.3 数据保留策略
- 任务定义: 永久保存
- 执行记录: 保留90天
- 任务日志: 保留30天
- 系统日志: 保留15天

## 4. 限流配置

### 4.1 API限流
- 创建任务: 100 req/s
- 执行任务: 200 req/s
- 查询接口: 500 req/s
- 批量接口: 50 req/s

### 4.2 任务执行限流
- 单节点最大并发: 100
- 单任务最大重试: 3次
- 批量任务大小: 1000 
- 队列容量: 10000

## 5. 集群配置

### 5.1 高可用配置
- 最小节点数: 3
- 建议节点数: 5 
- 跨可用区部署
- 自动故障转移

### 5.2 分片策略
- 任务分片数: 节点数 * 2
- 分片算法: 一致性哈希
- 再平衡触发条件:
  - 节点上下线
  - 负载不均衡超过20%
  - 手动触发

## 6. 监控指标

### 6.1 业务指标
- 任务执行量
- 任务成功率
- 任务执行延迟 
- 任务执行时长
- 任务排队数量

### 6.2 系统指标  
- CPU/内存/磁盘使用率
- GC情况
- 线程池状态
- 连接池状态
- 网络IO

### 6.3 中间件指标
- Redis连接数/命中率
- MQ队列长度/消费延迟
- 数据库连接数/慢查询

## 7. 告警配置

### 7.1 告警级别
- P0: 紧急 - 需要立即处理
- P1: 严重 - 30分钟内处理
- P2: 警告 - 2小时内处理  
- P3: 提示 - 24小时内处理

### 7.2 告警渠道
- P0: 短信+电话+邮件
- P1: 短信+邮件
- P2: 邮件
- P3: 系统通知

## 8. 巡检清单 

### 8.1 日常巡检
- 系统监控指标
- 任务执行情况
- 资源使用情况
- 错误日志分析

### 8.2 周巡检
- 性能分析
- 容量分析
- 可用性测试
- 数据一致性检查

### 8.3 月巡检
- 系统基线更新
- 性能优化
- 容量规划
- 可靠性分析
```

要继续添加其他组件或配置吗？比如安全配置、灾备方案等。