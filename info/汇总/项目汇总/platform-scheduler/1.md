我将帮你重写platform-scheduler模块。让我们从表结构设计开始。

首先创建所需的数据库表:



```sql
-- 任务定义表
CREATE TABLE job_definition (
    id VARCHAR(50) NOT NULL COMMENT '任务ID',
    name VARCHAR(100) NOT NULL COMMENT '任务名称',
    description VARCHAR(500) COMMENT '任务描述',  
    job_type VARCHAR(20) NOT NULL COMMENT '任务类型:HTTP/SHELL等',
    cron_expression VARCHAR(100) COMMENT 'CRON表达式',
    fixed_delay BIGINT COMMENT '固定延迟(毫秒)',
    timeout BIGINT COMMENT '超时时间(毫秒)',
    max_retries INT DEFAULT 0 COMMENT '最大重试次数',
    retry_interval BIGINT DEFAULT 0 COMMENT '重试间隔(毫秒)',
    job_data TEXT COMMENT '任务数据(JSON格式)',
    status VARCHAR(20) NOT NULL DEFAULT 'CREATED' COMMENT '任务状态',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id),
    INDEX idx_status (status),
    INDEX idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务定义表';

-- 任务执行表
CREATE TABLE job_execution (
    id VARCHAR(50) NOT NULL COMMENT '执行ID',
    job_id VARCHAR(50) NOT NULL COMMENT '任务ID',
    node_id VARCHAR(50) NOT NULL COMMENT '执行节点ID',
    start_time DATETIME NOT NULL COMMENT '开始时间',
    end_time DATETIME COMMENT '结束时间',
    status VARCHAR(20) NOT NULL COMMENT '执行状态',
    result TEXT COMMENT '执行结果',
    error TEXT COMMENT '错误信息',
    retry_count INT DEFAULT 0 COMMENT '重试次数',
    trace_id VARCHAR(50) COMMENT '链路追踪ID', 
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id),
    INDEX idx_job_id (job_id),
    INDEX idx_status (status),
    INDEX idx_start_time (start_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务执行表';

-- 任务日志表
CREATE TABLE job_log (
    id VARCHAR(50) NOT NULL COMMENT '日志ID',
    execution_id VARCHAR(50) NOT NULL COMMENT '执行ID',
    job_id VARCHAR(50) NOT NULL COMMENT '任务ID',
    log_type VARCHAR(20) NOT NULL COMMENT '日志类型',
    content TEXT NOT NULL COMMENT '日志内容',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    PRIMARY KEY (id),
    INDEX idx_execution_id (execution_id),
    INDEX idx_job_id (job_id),
    INDEX idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务日志表';

-- 任务锁表
CREATE TABLE job_lock (
    lock_key VARCHAR(100) NOT NULL COMMENT '锁键',
    node_id VARCHAR(50) NOT NULL COMMENT '持有节点',
    expires_at DATETIME NOT NULL COMMENT '过期时间',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (lock_key),
    INDEX idx_expires_at (expires_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务锁表';

-- 任务模板表
CREATE TABLE job_template (
    id VARCHAR(50) NOT NULL COMMENT '模板ID',
    name VARCHAR(100) NOT NULL COMMENT '模板名称',
    description VARCHAR(500) COMMENT '模板描述',
    template_content TEXT NOT NULL COMMENT '模板内容',
    variables TEXT COMMENT '变量定义',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务模板表';

-- 监控指标表 
CREATE TABLE metrics_record (
    id VARCHAR(50) NOT NULL COMMENT '记录ID',
    metrics_name VARCHAR(100) NOT NULL COMMENT '指标名称',
    metrics_value DECIMAL(20,4) NOT NULL COMMENT '指标值',
    node_id VARCHAR(50) COMMENT '节点ID',
    tags JSON COMMENT '标签',
    collect_time DATETIME NOT NULL COMMENT '采集时间',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    PRIMARY KEY (id),
    INDEX idx_metrics_name (metrics_name),
    INDEX idx_collect_time (collect_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='监控指标表';

-- 告警记录表
CREATE TABLE alert_record (
    id VARCHAR(50) NOT NULL COMMENT '告警ID',
    alert_name VARCHAR(100) NOT NULL COMMENT '告警名称',
    alert_level VARCHAR(20) NOT NULL COMMENT '告警级别',
    content TEXT NOT NULL COMMENT '告警内容',
    status VARCHAR(20) NOT NULL COMMENT '告警状态',
    node_id VARCHAR(50) COMMENT '告警节点',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (id),
    INDEX idx_alert_name (alert_name),
    INDEX idx_status (status),
    INDEX idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='告警记录表';

```

接下来是pom.xml文件:



```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>platform-parent</artifactId>
        <groupId>com.study</groupId>
        <version>1.0.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>platform-scheduler</artifactId>

    <dependencies>
        <!-- Spring Boot -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-validation</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-aop</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <!-- Database -->
        <dependency>
            <groupId>org.mariadb.jdbc</groupId>
            <artifactId>mariadb-java-client</artifactId>
        </dependency>
        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>${mybatis.version}</version>
        </dependency>

        <!-- Redis -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>
        <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson-spring-boot-starter</artifactId>
            <version>3.23.0</version>
        </dependency>

        <!-- RabbitMQ -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-amqp</artifactId>
        </dependency>

        <!-- Quartz -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-quartz</artifactId>
        </dependency>

        <!-- Common -->
        <dependency>
            <groupId>com.study</groupId>
            <artifactId>platform-common</artifactId>
            <version>${project.version}</version>
        </dependency>

        <!-- Tools -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
        </dependency>
        <dependency> 
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-jsr310</artifactId>
        </dependency>

        <!-- Test -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-core</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <configuration>
                    <mainClass>com.study.scheduler.SchedulerApplication</mainClass>
                    <excludes>
                        <exclude>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok</artifactId>
                        </exclude>
                    </excludes>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>repackage</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>

```

下面是主要的配置文件application.yml:



```yaml
server:
  port: 8081

spring:
  application:
    name: platform-scheduler

  # DataSource
  datasource:
    driver-class-name: org.mariadb.jdbc.Driver
    url: jdbc:mariadb://localhost:3306/scheduler?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
    username: root
    password: 123456
    type: com.zaxxer.hikari.HikariDataSource
    hikari:
      minimum-idle: 5
      maximum-pool-size: 15
      idle-timeout: 30000
      pool-name: SchedulerHikariCP
      max-lifetime: 1800000
      connection-timeout: 30000
      connection-test-query: SELECT 1

  # Redis
  data:
    redis:
      password: 123456
      timeout: 5000
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0
          max-wait: 1000
      cluster:
        nodes:
          - 127.0.0.1:6379
          - 127.0.0.1:6380
          - 127.0.0.1:6381

  # RabbitMQ
  rabbitmq:
    host: localhost
    port: 5672
    username: admin
    password: 123456
    virtual-host: /
    publisher-confirms: true
    publisher-returns: true
    listener:
      simple:
        acknowledge-mode: manual
        prefetch: 1
        concurrency: 3
        max-concurrency: 10
        retry:
          enabled: true
          initial-interval: 1000ms
          max-attempts: 3
          multiplier: 2

  # Quartz
  quartz:
    job-store-type: jdbc
    jdbc:
      initialize-schema: always
    properties:
      org.quartz.scheduler.instanceName: QuartzScheduler
      org.quartz.scheduler.instanceId: AUTO
      org.quartz.jobStore.class: org.springframework.scheduling.quartz.LocalDataSourceJobStore
      org.quartz.jobStore.driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate
      org.quartz.jobStore.tablePrefix: QRTZ_
      org.quartz.jobStore.isClustered: true
      org.quartz.jobStore.clusterCheckinInterval: 10000
      org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool
      org.quartz.threadPool.threadCount: 10
      org.quartz.threadPool.threadPriority: 5

# MyBatis
mybatis:
  mapper-locations: classpath:mapper/*.xml
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.slf4j.Slf4jImpl

# Scheduler Config
scheduler:
  cluster:
    enabled: true
    node-id: ${HOSTNAME:node-1}
  execution:
    pool:
      core-size: 10
      max-size: 20
      queue-capacity: 50
      keep-alive: 300
  retry:
    max-attempts: 3
    initial-interval: 1000
    multiplier: 2.0
    max-interval: 10000
  monitor:
    metrics-interval: 60
    cleanup-interval: 86400

# Management
management:
  endpoints:
    web:
      exposure:
        include: health
```

好的,让我们按照项目结构开始输出代码。从api层开始:

1. 首先创建API层的Controller:



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.*;
import com.study.scheduler.api.model.vo.job.*;
import com.study.scheduler.domain.service.JobDomainService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api/jobs")
public class JobController {

    @Autowired
    private JobDomainService jobDomainService;

    @PostMapping
    public Result<JobVO> createJob(@Validated @RequestBody JobCreateRequest request) {
        log.info("Creating job: {}", request);
        JobVO job = jobDomainService.createJob(request);
        return Result.success(job);
    }

    @PutMapping("/{id}")
    public Result<JobVO> updateJob(@PathVariable String id, 
            @Validated @RequestBody JobUpdateRequest request) {
        log.info("Updating job {}: {}", id, request);
        JobVO job = jobDomainService.updateJob(id, request);
        return Result.success(job);
    }

    @DeleteMapping("/{id}")
    public Result<Void> deleteJob(@PathVariable String id) {
        log.info("Deleting job: {}", id);
        jobDomainService.deleteJob(id);
        return Result.success();
    }

    @GetMapping("/{id}")
    public Result<JobDetailVO> getJob(@PathVariable String id) {
        JobDetailVO job = jobDomainService.getJobDetail(id);
        return Result.success(job);
    }

    @GetMapping
    public Result<List<JobVO>> queryJobs(JobQueryRequest request) {
        List<JobVO> jobs = jobDomainService.queryJobs(request);
        return Result.success(jobs);
    }

    @GetMapping("/{id}/logs")
    public Result<List<JobLogVO>> getJobLogs(@PathVariable String id) {
        List<JobLogVO> logs = jobDomainService.getJobLogs(id);
        return Result.success(logs);
    }

    @PostMapping("/{id}/pause")
    public Result<Void> pauseJob(@PathVariable String id) {
        log.info("Pausing job: {}", id);
        jobDomainService.pauseJob(id);
        return Result.success();
    }

    @PostMapping("/{id}/resume") 
    public Result<Void> resumeJob(@PathVariable String id) {
        log.info("Resuming job: {}", id);
        jobDomainService.resumeJob(id);
        return Result.success();
    }
}

```



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.JobExecuteRequest;
import com.study.scheduler.core.executor.ExecuteResult;
import com.study.scheduler.domain.service.ExecutionDomainService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

@Slf4j
@RestController
@RequestMapping("/api/jobs/execute")
public class JobExecuteController {

    @Autowired
    private ExecutionDomainService executionService;

    @PostMapping("/{id}")
    public Result<ExecuteResult> executeJob(@PathVariable String id, 
            @Validated @RequestBody JobExecuteRequest request) {
        log.info("Executing job {}: {}", id, request);
        ExecuteResult result = executionService.executeJob(id, request);
        return Result.success(result);
    }

    @PostMapping("/{id}/stop")
    public Result<Void> stopJob(@PathVariable String id) {
        log.info("Stopping job execution: {}", id);
        executionService.stopJob(id);
        return Result.success();
    }

    @PostMapping("/{id}/retry")
    public Result<ExecuteResult> retryJob(@PathVariable String id) {
        log.info("Retrying job: {}", id);
        ExecuteResult result = executionService.retryJob(id);
        return Result.success(result);
    }

    @GetMapping("/{id}/status")
    public Result<String> getJobStatus(@PathVariable String id) {
        String status = executionService.getJobStatus(id);
        return Result.success(status);
    }
}

```

现在让我继续输出JobRegisterController和JobTemplateController的代码?好的，继续输出Controller层的代码：



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.JobRegisterRequest;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.manager.JobManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api/jobs/register")
public class JobRegisterController {

    @Autowired
    private JobManager jobManager;

    @PostMapping
    public Result<JobVO> registerJob(@Validated @RequestBody JobRegisterRequest request) {
        log.info("Registering new job: {}", request);
        JobVO job = jobManager.registerJob(request);
        return Result.success(job);
    }

    @PostMapping("/batch")
    public Result<List<JobVO>> batchRegister(@Validated @RequestBody List<JobRegisterRequest> requests) {
        log.info("Batch registering {} jobs", requests.size());
        List<JobVO> jobs = jobManager.batchRegisterJobs(requests);
        return Result.success(jobs);
    }

    @PutMapping("/{id}/enable")
    public Result<Void> enableJob(@PathVariable String id) {
        log.info("Enabling job: {}", id);
        jobManager.enableJob(id);
        return Result.success();
    }

    @PutMapping("/{id}/disable") 
    public Result<Void> disableJob(@PathVariable String id) {
        log.info("Disabling job: {}", id);
        jobManager.disableJob(id);
        return Result.success();
    }

    @GetMapping("/types")
    public Result<List<String>> getJobTypes() {
        List<String> types = jobManager.getSupportedJobTypes();
        return Result.success(types);
    }
}

```



```java
package com.study.scheduler.api.controller.job;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.job.JobTemplateRequest;
import com.study.scheduler.api.model.vo.job.JobTemplateVO;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.manager.JobTemplateManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Map;

@Slf4j
@RestController
@RequestMapping("/api/jobs/templates")
public class JobTemplateController {

    @Autowired
    private JobTemplateManager templateManager;

    @PostMapping
    public Result<JobTemplateVO> createTemplate(@Validated @RequestBody JobTemplateRequest request) {
        log.info("Creating job template: {}", request);
        JobTemplateVO template = templateManager.createTemplate(request);
        return Result.success(template);
    }

    @PutMapping("/{id}")
    public Result<JobTemplateVO> updateTemplate(@PathVariable String id,
            @Validated @RequestBody JobTemplateRequest request) {
        log.info("Updating job template {}: {}", id, request);
        JobTemplateVO template = templateManager.updateTemplate(id, request);
        return Result.success(template);
    }

    @DeleteMapping("/{id}")
    public Result<Void> deleteTemplate(@PathVariable String id) {
        log.info("Deleting job template: {}", id);
        templateManager.deleteTemplate(id);
        return Result.success();
    }

    @GetMapping("/{id}")
    public Result<JobTemplateVO> getTemplate(@PathVariable String id) {
        JobTemplateVO template = templateManager.getTemplate(id);
        return Result.success(template);
    }

    @GetMapping
    public Result<List<JobTemplateVO>> listTemplates() {
        List<JobTemplateVO> templates = templateManager.listTemplates();
        return Result.success(templates);
    }

    @PostMapping("/{id}/apply")
    public Result<JobVO> applyTemplate(
            @PathVariable String id,
            @RequestBody Map<String, Object> variables) {
        log.info("Applying template {} with variables: {}", id, variables);
        JobVO job = templateManager.applyTemplate(id, variables);
        return Result.success(job);
    }

    @GetMapping("/{id}/variables")
    public Result<Map<String, String>> getTemplateVariables(@PathVariable String id) {
        Map<String, String> variables = templateManager.getTemplateVariables(id);
        return Result.success(variables);
    }
}

```

接下来是监控相关的Controller:



```java
package com.study.scheduler.api.controller.monitor;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.monitor.MetricsRequest;
import com.study.scheduler.api.model.vo.monitor.MetricsVO;
import com.study.scheduler.core.manager.MetricsManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Map;

@Slf4j
@RestController
@RequestMapping("/api/monitor/metrics")
public class MetricsController {

    @Autowired
    private MetricsManager metricsManager;

    @GetMapping("/system")
    public Result<Map<String, Object>> getSystemMetrics() {
        Map<String, Object> metrics = metricsManager.getSystemMetrics();
        return Result.success(metrics);
    }

    @GetMapping("/job")
    public Result<List<MetricsVO>> getJobMetrics(MetricsRequest request) {
        List<MetricsVO> metrics = metricsManager.getJobMetrics(request);
        return Result.success(metrics);
    }

    @GetMapping("/node")
    public Result<List<MetricsVO>> getNodeMetrics(MetricsRequest request) {
        List<MetricsVO> metrics = metricsManager.getNodeMetrics(request);
        return Result.success(metrics);
    }

    @GetMapping("/execution")
    public Result<Map<String, Long>> getExecutionMetrics() {
        Map<String, Long> metrics = metricsManager.getExecutionMetrics();
        return Result.success(metrics);
    }

    @GetMapping("/{jobId}/history")
    public Result<List<MetricsVO>> getJobMetricsHistory(
            @PathVariable String jobId,
            @RequestParam String metric,
            @RequestParam Long startTime,
            @RequestParam Long endTime) {
        List<MetricsVO> metrics = metricsManager.getJobMetricsHistory(
                jobId, metric, startTime, endTime);
        return Result.success(metrics);
    }
}

```

需要我继续输出AlertController和SystemController吗？好的，继续输出监控告警和系统管理相关的Controller：



```java
package com.study.scheduler.api.controller.monitor;

import com.study.common.util.Result;
import com.study.scheduler.api.model.request.monitor.AlertRequest;
import com.study.scheduler.api.model.vo.monitor.AlertVO;
import com.study.scheduler.core.manager.AlertManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api/monitor/alerts")
public class AlertController {

    @Autowired
    private AlertManager alertManager;

    @PostMapping("/rules")
    public Result<Void> createAlertRule(@Validated @RequestBody AlertRequest request) {
        log.info("Creating alert rule: {}", request);
        alertManager.createAlertRule(request);
        return Result.success();
    }

    @GetMapping("/rules")
    public Result<List<AlertVO>> getAlertRules() {
        List<AlertVO> rules = alertManager.getAlertRules();
        return Result.success(rules);
    }

    @GetMapping("/active")
    public Result<List<AlertVO>> getActiveAlerts() {
        List<AlertVO> alerts = alertManager.getActiveAlerts();
        return Result.success(alerts);
    }

    @GetMapping("/history")
    public Result<List<AlertVO>> getAlertHistory(
            @RequestParam(required = false) String level,
            @RequestParam(required = false) Long startTime,
            @RequestParam(required = false) Long endTime) {
        List<AlertVO> alerts = alertManager.getAlertHistory(level, startTime, endTime);
        return Result.success(alerts);
    }

    @PostMapping("/{id}/acknowledge")
    public Result<Void> acknowledgeAlert(@PathVariable String id) {
        log.info("Acknowledging alert: {}", id);
        alertManager.acknowledgeAlert(id);
        return Result.success();
    }

    @PostMapping("/{id}/resolve")
    public Result<Void> resolveAlert(@PathVariable String id) {
        log.info("Resolving alert: {}", id);
        alertManager.resolveAlert(id);
        return Result.success();
    }

    @DeleteMapping("/rules/{id}")
    public Result<Void> deleteAlertRule(@PathVariable String id) {
        log.info("Deleting alert rule: {}", id);
        alertManager.deleteAlertRule(id);
        return Result.success();
    }
}

```



```java
package com.study.scheduler.api.controller.admin;

import com.study.common.util.Result;
import com.study.scheduler.core.manager.SystemManager;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Map;

@Slf4j
@RestController
@RequestMapping("/api/admin/system")
public class SystemController {

    @Autowired
    private SystemManager systemManager;

    @GetMapping("/nodes")
    public Result<List<Map<String, Object>>> getClusterNodes() {
        List<Map<String, Object>> nodes = systemManager.getClusterNodes();
        return Result.success(nodes);
    }

    @GetMapping("/config")
    public Result<Map<String, Object>> getSystemConfig() {
        Map<String, Object> config = systemManager.getSystemConfig();
        return Result.success(config);
    }

    @PutMapping("/config")
    public Result<Void> updateSystemConfig(@RequestBody Map<String, Object> config) {
        log.info("Updating system config: {}", config);
        systemManager.updateSystemConfig(config);
        return Result.success();
    }

    @PostMapping("/nodes/{nodeId}/offline")
    public Result<Void> offlineNode(@PathVariable String nodeId) {
        log.info("Taking node offline: {}", nodeId);
        systemManager.offlineNode(nodeId);
        return Result.success();
    }

    @PostMapping("/nodes/{nodeId}/online")
    public Result<Void> onlineNode(@PathVariable String nodeId) {
        log.info("Bringing node online: {}", nodeId);
        systemManager.onlineNode(nodeId);
        return Result.success();
    }

    @GetMapping("/status")
    public Result<Map<String, Object>> getSystemStatus() {
        Map<String, Object> status = systemManager.getSystemStatus();
        return Result.success(status);
    }

    @PostMapping("/maintenance/start")
    public Result<Void> startMaintenance() {
        log.info("Starting system maintenance mode");
        systemManager.startMaintenanceMode();
        return Result.success();
    }

    @PostMapping("/maintenance/stop")
    public Result<Void> stopMaintenance() {
        log.info("Stopping system maintenance mode");
        systemManager.stopMaintenanceMode();
        return Result.success();
    }

    @PostMapping("/cache/clear")
    public Result<Void> clearCache(@RequestParam(required = false) String type) {
        log.info("Clearing system cache, type: {}", type);
        systemManager.clearCache(type);
        return Result.success();
    }
}

```

现在我们开始实现API层的请求和响应模型。我先实现任务相关的请求模型：



```java
package com.study.scheduler.api.model.request.job;

import lombok.Data;
import jakarta.validation.constraints.NotBlank;
import jakarta.validation.constraints.NotNull;
import java.util.Map;

@Data
public class JobCreateRequest {
    @NotBlank(message = "Job name cannot be empty")
    private String name;
    
    private String description;
    
    @NotBlank(message = "Job type cannot be empty")
    private String jobType;
    
    private String cronExpression;
    
    private Long fixedDelay;
    
    private Long timeout;
    
    private Integer maxRetries;
    
    private Long retryInterval;
    
    private Map<String, Object> jobData;
}

@Data
public class JobUpdateRequest {
    private String name;
    private String description;
    private String cronExpression;
    private Long fixedDelay;
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private Map<String, Object> jobData;
}

@Data
public class JobQueryRequest {
    private String name;
    private String jobType;
    private String status;
    private Long startTime;
    private Long endTime;
    private Integer page;
    private Integer size;
}

@Data 
public class JobExecuteRequest {
    private Map<String, Object> parameters;
    private Boolean async = false;
    private Long timeout;
}

@Data
public class JobRegisterRequest extends JobCreateRequest {
    @NotNull(message = "Whether to enable job must be specified")
    private Boolean enabled = true;
    
    private Boolean replace = false;
}

@Data
public class BatchJobRequest {
    @NotNull(message = "Job list cannot be null")
    private List<JobCreateRequest> jobs;
}

```

需要我继续实现模板请求和监控告警相关的请求模型吗？
好的，继续实现模板和监控告警相关的请求模型：



```java
package com.study.scheduler.api.model.request.job;

import lombok.Data;
import jakarta.validation.constraints.NotBlank;
import jakarta.validation.constraints.NotNull;
import java.util.Map;
import java.util.List;

@Data
public class JobTemplateRequest {
    @NotBlank(message = "Template name cannot be empty")
    private String name;
    
    private String description;
    
    @NotBlank(message = "Template content cannot be empty")
    private String templateContent;
    
    private Map<String, String> variables;
    
    private List<String> tags;
}

package com.study.scheduler.api.model.request.monitor;

@Data
public class AlertRequest {
    @NotBlank(message = "Alert name cannot be empty")
    private String name;
    
    @NotBlank(message = "Alert level cannot be empty")
    private String level;
    
    @NotBlank(message = "Metric name cannot be empty")
    private String metricName;
    
    @NotNull(message = "Threshold cannot be null")
    private Double threshold;
    
    @NotBlank(message = "Operator cannot be empty")
    private String operator;
    
    private String description;
    
    private List<String> notifyChannels;
    
    private Map<String, String> labels;
    
    private Boolean enabled = true;
}

@Data
public class MetricsRequest {
    private String metricName;
    
    private List<String> dimensions;
    
    private Map<String, String> tags;
    
    private Long startTime;
    
    private Long endTime;
    
    private String aggregator;
    
    private Integer interval;
    
    private Integer page;
    
    private Integer size;
}

package com.study.scheduler.api.model.request.system;

@Data 
public class NodeRequest {
    @NotBlank(message = "Node ID cannot be empty")
    private String nodeId;
    
    private Map<String, Object> attributes;
    
    private List<String> tags;
    
    private Boolean enabled = true;
}

@Data
public class ConfigUpdateRequest {
    @NotNull(message = "Config items cannot be null")
    private Map<String, Object> configItems;
    
    private String operator;
    
    private String remark;
}

```

接下来实现视图对象（VO）模型：



```java
package com.study.scheduler.api.model.vo.job;

import lombok.Data;
import java.util.Date;
import java.util.Map;
import java.util.List;

@Data
public class JobVO {
    private String id;
    private String name;
    private String description;
    private String jobType;
    private String cronExpression;
    private Long fixedDelay;
    private String status;
    private Date nextFireTime;
    private Date lastFireTime;
    private Date createTime;
    private Date updateTime;
}

@Data
public class JobDetailVO extends JobVO {
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private Map<String, Object> jobData;
    private JobExecutionVO lastExecution;
    private JobStatisticsVO statistics;
}

@Data 
public class JobExecutionVO {
    private String id;
    private String jobId;
    private String nodeId;
    private Date startTime;
    private Date endTime;
    private String status;
    private String result;
    private String error;
    private Integer retryCount;
    private String traceId;
}

@Data
public class JobLogVO {
    private String id;
    private String executionId;
    private String jobId;
    private String logType;
    private String content;
    private Date createTime;
}

@Data
public class JobStatisticsVO {
    private Long totalExecutions;
    private Long successCount;
    private Long failureCount;
    private Double averageDuration;
    private Long lastSuccessTime;
    private Long lastFailureTime;
}

@Data
public class JobTemplateVO {
    private String id;
    private String name;
    private String description;
    private String templateContent;
    private Map<String, String> variables;
    private List<String> tags;
    private Date createTime;
    private Date updateTime;
}

package com.study.scheduler.api.model.vo.monitor;

@Data
public class AlertVO {
    private String id;
    private String name;
    private String level;
    private String metricName;
    private Double threshold;
    private String operator;
    private String description;
    private List<String> notifyChannels;
    private Map<String, String> labels;
    private Boolean enabled;
    private Date createTime;
    private Date updateTime;
}

@Data
public class MetricsVO {
    private String metricName;
    private Double value;
    private Map<String, String> tags;
    private Date timestamp;
}

package com.study.scheduler.api.model.vo.system;

@Data
public class NodeVO {
    private String nodeId;
    private String status;
    private Map<String, Object> attributes;
    private List<String> tags;
    private Date lastHeartbeat;
    private SystemMetricsVO metrics;
}

@Data
public class SystemMetricsVO {
    private Double cpuUsage;
    private Double memoryUsage;
    private Double diskUsage;
    private Integer activeThreads;
    private Integer queuedTasks;
    private Map<String, Object> customMetrics;
}

```

我们已经完成了API层的主要模型定义。接下来要实现Core层的组件吗？包括执行器、调度器、处理器和管理器等核心组件。好的，让我们开始实现Core层的组件，先从执行器(executor)开始：



```java
package com.study.scheduler.core.executor;

import com.study.scheduler.domain.entity.job.JobExecution;
import lombok.Data;
import java.util.Map;

public interface JobExecutor {
    String getType();
    
    ExecuteResult execute(ExecuteContext context);
    
    default void beforeExecute(ExecuteContext context) {}
    
    default void afterExecute(ExecuteContext context, ExecuteResult result) {}
    
    default boolean supports(String jobType) {
        return getType().equalsIgnoreCase(jobType);
    }
}

@Data
public class ExecuteContext {
    private String jobId;
    private String executionId;
    private String jobType;
    private Map<String, Object> jobData;
    private Map<String, Object> parameters;
    private Long timeout;
    private JobExecution execution;
}

@Data
public class ExecuteResult {
    private boolean success;
    private String result;
    private String error;
    private Long duration;
    private Map<String, Object> extraData;
    
    public static ExecuteResult success(String result) {
        ExecuteResult executeResult = new ExecuteResult();
        executeResult.setSuccess(true);
        executeResult.setResult(result);
        return executeResult;
    }
    
    public static ExecuteResult failure(String error) {
        ExecuteResult executeResult = new ExecuteResult();
        executeResult.setSuccess(false);
        executeResult.setError(error);
        return executeResult;
    }
}

@Slf4j
@Component
public class DefaultJobExecutor implements JobExecutor {
    
    @Override
    public String getType() {
        return "DEFAULT";
    }
    
    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            log.info("Executing job: {}", context.getJobId());
            String result = doExecute(context);
            return ExecuteResult.success(result);
        } catch (Exception e) {
            log.error("Job execution failed", e);
            return ExecuteResult.failure(e.getMessage());
        }
    }
    
    protected String doExecute(ExecuteContext context) {
        // Default implementation
        return "Job executed successfully";
    }
}

```



```java
package com.study.scheduler.core.executor;

import com.study.scheduler.core.handler.VariableHandler;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.*;
import org.springframework.stereotype.Component;
import org.springframework.web.client.RestTemplate;

import java.util.Map;

@Slf4j
@Component
public class HttpJobExecutor implements JobExecutor {

    @Autowired
    private RestTemplate restTemplate;
    
    @Autowired
    private VariableHandler variableHandler;

    @Override
    public String getType() {
        return "HTTP";
    }

    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            Map<String, Object> httpConfig = context.getJobData();
            
            // 处理变量
            String url = variableHandler.handleVariables(
                    httpConfig.get("url").toString(), 
                    context.getParameters()
            );
            
            // 构建请求
            HttpMethod method = HttpMethod.valueOf(
                    httpConfig.get("method").toString()
            );
            
            HttpHeaders headers = buildHeaders(httpConfig);
            
            Object body = httpConfig.get("body");
            
            HttpEntity<?> requestEntity = new HttpEntity<>(body, headers);
            
            // 发送请求
            ResponseEntity<String> response = restTemplate.exchange(
                    url,
                    method, 
                    requestEntity,
                    String.class
            );
            
            // 处理响应
            if (response.getStatusCode().is2xxSuccessful()) {
                return ExecuteResult.success(response.getBody());
            } else {
                return ExecuteResult.failure(
                    "HTTP request failed with status: " + response.getStatusCode()
                );
            }
            
        } catch (Exception e) {
            log.error("HTTP job execution failed", e);
            return ExecuteResult.failure(e.getMessage());
        }
    }
    
    private HttpHeaders buildHeaders(Map<String, Object> config) {
        HttpHeaders headers = new HttpHeaders();
        
        if (config.containsKey("headers")) {
            @SuppressWarnings("unchecked")
            Map<String, String> headerMap = (Map<String, String>) config.get("headers");
            headerMap.forEach((key, value) -> {
                String resolvedValue = variableHandler.handleVariables(value, null);
                headers.add(key, resolvedValue);
            });
        }
        
        return headers;
    }
}

```



```java
package com.study.scheduler.core.executor;

import lombok.extern.slf4j.Slf4j;
import org.apache.commons.io.IOUtils;
import org.springframework.stereotype.Component;
import java.nio.charset.StandardCharsets;
import java.util.Map;
import java.util.concurrent.*;

@Slf4j
@Component
public class ShellJobExecutor implements JobExecutor {

    private final ExecutorService executorService = Executors.newCachedThreadPool();

    @Override
    public String getType() {
        return "SHELL";
    }

    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            Map<String, Object> shellConfig = context.getJobData();
            String command = shellConfig.get("command").toString();
            
            // 处理工作目录
            String workDir = shellConfig.get("workDir") != null ? 
                    shellConfig.get("workDir").toString() : null;
                    
            // 处理环境变量
            @SuppressWarnings("unchecked")
            Map<String, String> env = shellConfig.get("env") != null ?
                    (Map<String, String>) shellConfig.get("env") : null;

            // 执行命令
            Process process = executeCommand(command, workDir, env);
            
            // 等待执行完成
            Future<String> outputFuture = captureOutput(process);
            Future<String> errorFuture = captureError(process);
            
            // 设置超时
            long timeout = context.getTimeout() != null ? 
                    context.getTimeout() : 60000L;
                    
            boolean completed = process.waitFor(timeout, TimeUnit.MILLISECONDS);
            
            if (!completed) {
                process.destroyForcibly();
                return ExecuteResult.failure("Command execution timed out");
            }

            // 获取执行结果
            int exitCode = process.exitValue();
            String output = outputFuture.get(5, TimeUnit.SECONDS);
            String error = errorFuture.get(5, TimeUnit.SECONDS);

            if (exitCode == 0) {
                return ExecuteResult.success(output);
            } else {
                return ExecuteResult.failure(error);
            }

        } catch (Exception e) {
            log.error("Shell job execution failed", e);
            return ExecuteResult.failure(e.getMessage());
        }
    }

    private Process executeCommand(String command, String workDir, Map<String, String> env) 
            throws IOException {
        ProcessBuilder builder = new ProcessBuilder();
        
        if (workDir != null) {
            builder.directory(new File(workDir));
        }
        
        if (env != null) {
            builder.environment().putAll(env);
        }
        
        builder.command("sh", "-c", command);
        return builder.start();
    }

    private Future<String> captureOutput(Process process) {
        return executorService.submit(() -> 
            IOUtils.toString(process.getInputStream(), StandardCharsets.UTF_8)
        );
    }

    private Future<String> captureError(Process process) {
        return executorService.submit(() ->
            IOUtils.toString(process.getErrorStream(), StandardCharsets.UTF_8)
        );
    }
}

```

需要我继续实现批量任务执行器(BatchJobExecutor)和调度器(scheduler)模块吗？好的，让我们继续实现批量执行器和调度器模块：



```java
package com.study.scheduler.core.executor;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import java.util.*;
import java.util.concurrent.*;

@Slf4j
@Component
public class BatchJobExecutor implements JobExecutor {
    
    @Autowired
    private List<JobExecutor> jobExecutors;
    
    private final ExecutorService executorService;
    
    public BatchJobExecutor() {
        this.executorService = new ThreadPoolExecutor(
            10, 20, 
            60L, TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(500),
            new ThreadFactoryBuilder().setNameFormat("batch-executor-%d").build(),
            new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }

    @Override
    public String getType() {
        return "BATCH";
    }

    @Override
    public ExecuteResult execute(ExecuteContext context) {
        try {
            @SuppressWarnings("unchecked")
            List<Map<String, Object>> batchTasks = (List<Map<String, Object>>) 
                    context.getJobData().get("tasks");

            // 提交所有任务
            List<Future<ExecuteResult>> futures = new ArrayList<>();
            for (Map<String, Object> taskConfig : batchTasks) {
                futures.add(submitTask(taskConfig, context));
            }

            // 收集执行结果
            List<ExecuteResult> results = new ArrayList<>();
            for (Future<ExecuteResult> future : futures) {
                try {
                    results.add(future.get(context.getTimeout(), TimeUnit.MILLISECONDS));
                } catch (TimeoutException e) {
                    future.cancel(true);
                    results.add(ExecuteResult.failure("Task execution timed out"));
                }
            }

            // 汇总结果
            return aggregateResults(results);

        } catch (Exception e) {
            log.error("Batch job execution failed", e);
            return ExecuteResult.failure("Batch execution failed: " + e.getMessage());
        }
    }

    private Future<ExecuteResult> submitTask(Map<String, Object> taskConfig, 
            ExecuteContext parentContext) {
        return executorService.submit(() -> {
            try {
                String jobType = taskConfig.get("jobType").toString();
                JobExecutor executor = findExecutor(jobType);
                
                ExecuteContext taskContext = new ExecuteContext();
                taskContext.setJobId(parentContext.getJobId() + "-" + UUID.randomUUID());
                taskContext.setJobType(jobType);
                taskContext.setJobData(taskConfig);
                taskContext.setParameters(parentContext.getParameters());
                taskContext.setTimeout(parentContext.getTimeout());
                
                return executor.execute(taskContext);
            } catch (Exception e) {
                log.error("Task execution failed", e);
                return ExecuteResult.failure(e.getMessage());
            }
        });
    }

    private JobExecutor findExecutor(String jobType) {
        return jobExecutors.stream()
                .filter(executor -> executor.supports(jobType))
                .findFirst()
                .orElseThrow(() -> new IllegalArgumentException(
                    "No executor found for job type: " + jobType));
    }

    private ExecuteResult aggregateResults(List<ExecuteResult> results) {
        boolean allSuccess = results.stream().allMatch(ExecuteResult::isSuccess);
        
        Map<String, Object> summary = new HashMap<>();
        summary.put("totalTasks", results.size());
        summary.put("successCount", results.stream()
                .filter(ExecuteResult::isSuccess).count());
        summary.put("failureCount", results.stream()
                .filter(r -> !r.isSuccess()).count());
        summary.put("details", results);

        if (allSuccess) {
            return ExecuteResult.success(
                String.format("All %d tasks completed successfully", results.size())
            ).setExtraData(summary);
        } else {
            return ExecuteResult.failure(
                String.format("Some tasks failed (%d/%d)", 
                    (int)summary.get("failureCount"), results.size())
            ).setExtraData(summary);
        }
    }
}

```



```java
package com.study.scheduler.core.scheduler;

import com.study.scheduler.domain.entity.job.JobDefinition;
import java.util.Date;

public interface JobScheduler {
    void scheduleJob(JobDefinition jobDef);
    
    void updateJob(JobDefinition jobDef);
    
    void deleteJob(String jobId);
    
    void pauseJob(String jobId);
    
    void resumeJob(String jobId);
    
    Date getNextFireTime(String jobId);
    
    boolean checkExists(String jobId);
}

package com.study.scheduler.core.scheduler.quartz;

import org.quartz.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import lombok.extern.slf4j.Slf4j;

@Slf4j
@Component
public class QuartzJobScheduler implements JobScheduler {

    @Autowired
    private Scheduler scheduler;

    @Override
    public void scheduleJob(JobDefinition jobDef) {
        try {
            JobDetail jobDetail = buildJobDetail(jobDef);
            Trigger trigger = buildTrigger(jobDef);
            
            if (checkExists(jobDef.getId())) {
                scheduler.deleteJob(new JobKey(jobDef.getId()));
            }
            
            scheduler.scheduleJob(jobDetail, trigger);
            log.info("Scheduled job: {}", jobDef.getId());
            
        } catch (SchedulerException e) {
            log.error("Failed to schedule job: " + jobDef.getId(), e);
            throw new RuntimeException("Failed to schedule job", e);
        }
    }

    @Override
    public void updateJob(JobDefinition jobDef) {
        try {
            TriggerKey triggerKey = new TriggerKey(jobDef.getId());
            
            // 更新触发器
            Trigger newTrigger = buildTrigger(jobDef);
            scheduler.rescheduleJob(triggerKey, newTrigger);
            
            // 更新任务数据
            JobDetail jobDetail = scheduler.getJobDetail(new JobKey(jobDef.getId()));
            jobDetail.getJobDataMap().put("jobData", jobDef.getJobData());
            scheduler.addJob(jobDetail, true);
            
            log.info("Updated job: {}", jobDef.getId());
            
        } catch (SchedulerException e) {
            log.error("Failed to update job: " + jobDef.getId(), e);
            throw new RuntimeException("Failed to update job", e);
        }
    }

    @Override
    public void deleteJob(String jobId) {
        try {
            scheduler.deleteJob(new JobKey(jobId));
            log.info("Deleted job: {}", jobId);
        } catch (SchedulerException e) {
            log.error("Failed to delete job: " + jobId, e);
            throw new RuntimeException("Failed to delete job", e);
        }
    }

    @Override
    public void pauseJob(String jobId) {
        try {
            scheduler.pauseJob(new JobKey(jobId));
            log.info("Paused job: {}", jobId);
        } catch (SchedulerException e) {
            log.error("Failed to pause job: " + jobId, e);
            throw new RuntimeException("Failed to pause job", e);
        }
    }

    @Override
    public void resumeJob(String jobId) {
        try {
            scheduler.resumeJob(new JobKey(jobId));
            log.info("Resumed job: {}", jobId);
        } catch (SchedulerException e) {
            log.error("Failed to resume job: " + jobId, e);
            throw new RuntimeException("Failed to resume job", e);
        }
    }

    @Override
    public Date getNextFireTime(String jobId) {
        try {
            Trigger trigger = scheduler.getTrigger(new TriggerKey(jobId));
            return trigger != null ? trigger.getNextFireTime() : null;
        } catch (SchedulerException e) {
            log.error("Failed to get next fire time for job: " + jobId, e);
            throw new RuntimeException("Failed to get next fire time", e);
        }
    }

    @Override
    public boolean checkExists(String jobId) {
        try {
            return scheduler.checkExists(new JobKey(jobId));
        } catch (SchedulerException e) {
            log.error("Failed to check job existence: " + jobId, e);
            throw new RuntimeException("Failed to check job existence", e);
        }
    }

    private JobDetail buildJobDetail(JobDefinition jobDef) {
        return JobBuilder.newJob(QuartzJobAdapter.class)
                .withIdentity(jobDef.getId())
                .withDescription(jobDef.getDescription())
                .usingJobData("jobType", jobDef.getJobType())
                .usingJobData("jobData", jobDef.getJobData())
                .storeDurably()
                .build();
    }

    private Trigger buildTrigger(JobDefinition jobDef) {
        TriggerBuilder<Trigger> builder = TriggerBuilder.newTrigger()
                .withIdentity(jobDef.getId());

        // 处理CRON表达式
        if (jobDef.getCronExpression() != null) {
            builder.withSchedule(CronScheduleBuilder.cronSchedule(jobDef.getCronExpression())
                    .withMisfireHandlingInstructionFireAndProceed());
        } 
        // 处理固定延迟
        else if (jobDef.getFixedDelay() != null) {
            builder.withSchedule(SimpleScheduleBuilder.simpleSchedule()
                    .withIntervalInMilliseconds(jobDef.getFixedDelay())
                    .repeatForever()
                    .withMisfireHandlingInstructionNextWithExistingCount());
        }
        
        return builder.build();
    }
}

```

需要我继续实现Quartz任务适配器(QuartzJobAdapter)和处理器(handler)模块吗？好的，让我们先实现Quartz任务适配器，然后是处理器模块：



```java
package com.study.scheduler.core.scheduler.quartz;

import com.study.scheduler.core.executor.ExecuteContext;
import com.study.scheduler.core.executor.ExecuteResult;
import com.study.scheduler.core.executor.JobExecutor;
import com.study.scheduler.core.manager.ExecutionManager;
import com.study.scheduler.domain.entity.job.JobExecution;
import lombok.extern.slf4j.Slf4j;
import org.quartz.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;

import java.util.Date;
import java.util.Map;
import java.util.UUID;

@Slf4j
@PersistJobDataAfterExecution
@DisallowConcurrentExecution
public class QuartzJobAdapter implements Job {

    @Autowired
    private ApplicationContext applicationContext;

    @Autowired
    private ExecutionManager executionManager;

    @Override
    public void execute(JobExecutionContext context) throws JobExecutionException {
        JobDataMap dataMap = context.getJobDetail().getJobDataMap();
        String jobType = dataMap.getString("jobType");
        String jobId = context.getJobDetail().getKey().getName();
        
        @SuppressWarnings("unchecked")
        Map<String, Object> jobData = (Map<String, Object>) dataMap.get("jobData");

        // 创建执行记录
        JobExecution execution = createExecution(jobId);

        try {
            // 获取执行器
            JobExecutor executor = findExecutor(jobType);

            // 构建执行上下文
            ExecuteContext executeContext = buildExecuteContext(jobId, jobType, jobData, execution);

            // 执行任务
            executor.beforeExecute(executeContext);
            ExecuteResult result = executor.execute(executeContext);
            executor.afterExecute(executeContext, result);

            // 更新执行记录
            updateExecution(execution, result);

        } catch (Exception e) {
            log.error("Job execution failed: " + jobId, e);
            failExecution(execution, e);
            throw new JobExecutionException(e);
        }
    }

    private JobExecutor findExecutor(String jobType) {
        Map<String, JobExecutor> executors = applicationContext.getBeansOfType(JobExecutor.class);
        return executors.values().stream()
                .filter(executor -> executor.supports(jobType))
                .findFirst()
                .orElseThrow(() -> new IllegalArgumentException(
                    "No executor found for job type: " + jobType));
    }

    private JobExecution createExecution(String jobId) {
        JobExecution execution = new JobExecution();
        execution.setId(UUID.randomUUID().toString());
        execution.setJobId(jobId);
        execution.setNodeId(getNodeId());
        execution.setStartTime(new Date());
        execution.setStatus("RUNNING");
        return executionManager.saveExecution(execution);
    }

    private ExecuteContext buildExecuteContext(String jobId, String jobType,
            Map<String, Object> jobData, JobExecution execution) {
        ExecuteContext context = new ExecuteContext();
        context.setJobId(jobId);
        context.setExecutionId(execution.getId());
        context.setJobType(jobType);
        context.setJobData(jobData);
        context.setExecution(execution);
        return context;
    }

    private void updateExecution(JobExecution execution, ExecuteResult result) {
        execution.setEndTime(new Date());
        execution.setStatus(result.isSuccess() ? "SUCCESS" : "FAILED");
        execution.setResult(result.getResult());
        execution.setError(result.getError());
        executionManager.saveExecution(execution);
    }

    private void failExecution(JobExecution execution, Exception e) {
        execution.setEndTime(new Date());
        execution.setStatus("FAILED");
        execution.setError(e.getMessage());
        executionManager.saveExecution(execution);
    }

    private String getNodeId() {
        return System.getenv().getOrDefault("HOSTNAME", "unknown");
    }
}

```



```java
package com.study.scheduler.core.handler;

import com.study.scheduler.extension.variable.provider.VariableProvider;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import java.util.List;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

@Component
public class VariableHandler {

    private static final Pattern VARIABLE_PATTERN = Pattern.compile("\\$\\{([^}]+)}");

    @Autowired
    private List<VariableProvider> providers;

    public String handleVariables(String content, Map<String, Object> parameters) {
        if (content == null) {
            return null;
        }

        StringBuffer result = new StringBuffer();
        Matcher matcher = VARIABLE_PATTERN.matcher(content);

        while (matcher.find()) {
            String variable = matcher.group(1);
            String value = resolveVariable(variable, parameters);
            matcher.appendReplacement(result, Matcher.quoteReplacement(value));
        }
        matcher.appendTail(result);

        return result.toString();
    }

    private String resolveVariable(String variable, Map<String, Object> parameters) {
        // 处理参数变量
        if (parameters != null && parameters.containsKey(variable)) {
            return String.valueOf(parameters.get(variable));
        }

        // 处理提供者变量
        String[] parts = variable.split(":", 2);
        String providerName = parts[0];
        String key = parts.length > 1 ? parts[1] : "";

        return providers.stream()
                .filter(p -> p.supports(providerName))
                .findFirst()
                .map(p -> p.getValue(key))
                .orElse(variable);
    }
}

@Component
public class ParamHandler {

    private static final Pattern EXPRESSION_PATTERN = Pattern.compile("\\$\\{([^}]+)}");

    public Map<String, Object> handleParameters(Map<String, Object> template,
            Map<String, Object> parameters) {
        Map<String, Object> result = new HashMap<>();
        
        template.forEach((key, value) -> {
            if (value instanceof String) {
                result.put(key, handleStringValue((String) value, parameters));
            } else if (value instanceof Map) {
                @SuppressWarnings("unchecked")
                Map<String, Object> nestedMap = (Map<String, Object>) value;
                result.put(key, handleParameters(nestedMap, parameters));
            } else if (value instanceof List) {
                result.put(key, handleList((List<?>) value, parameters));
            } else {
                result.put(key, value);
            }
        });

        return result;
    }

    private String handleStringValue(String value, Map<String, Object> parameters) {
        Matcher matcher = EXPRESSION_PATTERN.matcher(value);
        StringBuffer result = new StringBuffer();

        while (matcher.find()) {
            String expression = matcher.group(1);
            Object paramValue = evaluateExpression(expression, parameters);
            matcher.appendReplacement(result, 
                    Matcher.quoteReplacement(String.valueOf(paramValue)));
        }
        matcher.appendTail(result);

        return result.toString();
    }

    private List<Object> handleList(List<?> list, Map<String, Object> parameters) {
        return list.stream()
                .map(item -> {
                    if (item instanceof String) {
                        return handleStringValue((String) item, parameters);
                    } else if (item instanceof Map) {
                        @SuppressWarnings("unchecked")
                        Map<String, Object> map = (Map<String, Object>) item;
                        return handleParameters(map, parameters);
                    } else {
                        return item;
                    }
                })
                .collect(Collectors.toList());
    }

    private Object evaluateExpression(String expression, Map<String, Object> parameters) {
        // 支持点号访问嵌套属性
        String[] parts = expression.split("\\.");
        Object current = parameters;

        for (String part : parts) {
            if (current instanceof Map) {
                @SuppressWarnings("unchecked")
                Map<String, Object> map = (Map<String, Object>) current;
                current = map.get(part);
            } else {
                return null;
            }
        }

        return current != null ? current : expression;
    }
}

```

接下来需要我实现管理器(manager)模块吗？包括JobManager、ExecutionManager等核心管理组件。好的，让我们实现管理器(manager)模块的核心组件：



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.api.model.request.job.JobRegisterRequest;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.scheduler.JobScheduler;
import com.study.scheduler.domain.entity.job.JobDefinition;
import com.study.scheduler.domain.repository.JobRepository;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

@Slf4j
@Component
public class JobManager {

    @Autowired
    private JobRepository jobRepository;

    @Autowired
    private JobScheduler jobScheduler;

    @Autowired
    private ExecutionManager executionManager;

    @Transactional
    public JobVO registerJob(JobRegisterRequest request) {
        log.info("Registering job: {}", request);
        
        // 创建任务定义
        JobDefinition jobDef = createJobDefinition(request);
        
        // 保存到数据库
        jobDef = jobRepository.save(jobDef);
        
        // 如果启用则调度任务
        if (request.getEnabled()) {
            scheduleJob(jobDef);
        }
        
        return convertToJobVO(jobDef);
    }

    @Transactional
    public List<JobVO> batchRegisterJobs(List<JobRegisterRequest> requests) {
        List<JobVO> results = new ArrayList<>();
        
        for (JobRegisterRequest request : requests) {
            try {
                JobVO job = registerJob(request);
                results.add(job);
            } catch (Exception e) {
                log.error("Failed to register job: " + request, e);
                // 继续处理其他任务
            }
        }
        
        return results;
    }

    @Transactional
    public void enableJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if ("DISABLED".equals(jobDef.getStatus())) {
            jobDef.setStatus("ENABLED");
            jobRepository.save(jobDef);
            scheduleJob(jobDef);
        }
    }

    @Transactional
    public void disableJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if ("ENABLED".equals(jobDef.getStatus())) {
            jobDef.setStatus("DISABLED");
            jobRepository.save(jobDef);
            jobScheduler.deleteJob(jobId);
        }
    }

    public List<String> getSupportedJobTypes() {
        return Arrays.asList("HTTP", "SHELL", "BATCH", "DEFAULT");
    }

    private JobDefinition createJobDefinition(JobRegisterRequest request) {
        JobDefinition jobDef = new JobDefinition();
        jobDef.setId(UUID.randomUUID().toString());
        jobDef.setName(request.getName());
        jobDef.setDescription(request.getDescription());
        jobDef.setJobType(request.getJobType());
        jobDef.setCronExpression(request.getCronExpression());
        jobDef.setFixedDelay(request.getFixedDelay());
        jobDef.setTimeout(request.getTimeout());
        jobDef.setMaxRetries(request.getMaxRetries());
        jobDef.setRetryInterval(request.getRetryInterval());
        jobDef.setJobData(request.getJobData());
        jobDef.setStatus(request.getEnabled() ? "ENABLED" : "DISABLED");
        jobDef.setCreateTime(new Date());
        jobDef.setUpdateTime(new Date());
        return jobDef;
    }

    private void scheduleJob(JobDefinition jobDef) {
        try {
            jobScheduler.scheduleJob(jobDef);
        } catch (Exception e) {
            log.error("Failed to schedule job: " + jobDef.getId(), e);
            jobDef.setStatus("SCHEDULE_FAILED");
            jobRepository.save(jobDef);
            throw e;
        }
    }

    private JobDefinition getJobDefinition(String jobId) {
        return jobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
    }

    private JobVO convertToJobVO(JobDefinition jobDef) {
        JobVO vo = new JobVO();
        vo.setId(jobDef.getId());
        vo.setName(jobDef.getName());
        vo.setDescription(jobDef.getDescription());
        vo.setJobType(jobDef.getJobType());
        vo.setCronExpression(jobDef.getCronExpression());
        vo.setFixedDelay(jobDef.getFixedDelay());
        vo.setStatus(jobDef.getStatus());
        vo.setNextFireTime(jobScheduler.getNextFireTime(jobDef.getId()));
        vo.setCreateTime(jobDef.getCreateTime());
        vo.setUpdateTime(jobDef.getUpdateTime());
        return vo;
    }
}

```



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.domain.entity.job.JobExecution;
import com.study.scheduler.domain.entity.job.JobLog;
import com.study.scheduler.domain.repository.ExecutionRepository;
import com.study.scheduler.domain.repository.JobLogRepository;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.Date;
import java.util.List;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

@Slf4j
@Component
public class ExecutionManager {

    @Autowired
    private ExecutionRepository executionRepository;
    
    @Autowired
    private JobLogRepository jobLogRepository;

    // 执行中的任务缓存
    private final ConcurrentMap<String, JobExecution> runningExecutions = new ConcurrentHashMap<>();

    @Transactional
    public JobExecution saveExecution(JobExecution execution) {
        execution = executionRepository.save(execution);
        
        if ("RUNNING".equals(execution.getStatus())) {
            runningExecutions.put(execution.getId(), execution);
        } else {
            runningExecutions.remove(execution.getId());
        }
        
        return execution;
    }

    @Transactional
    public void logExecution(String executionId, String logType, String content) {
        JobLog log = new JobLog();
        log.setId(UUID.randomUUID().toString());
        log.setExecutionId(executionId);
        log.setLogType(logType);
        log.setContent(content);
        log.setCreateTime(new Date());
        jobLogRepository.save(log);
    }

    public JobExecution getExecution(String executionId) {
        // 先查缓存
        JobExecution execution = runningExecutions.get(executionId);
        if (execution != null) {
            return execution;
        }
        
        // 再查数据库
        return executionRepository.findById(executionId).orElse(null);
    }

    public List<JobExecution> getJobExecutions(String jobId) {
        return executionRepository.findByJobId(jobId);
    }

    public List<JobLog> getExecutionLogs(String executionId) {
        return jobLogRepository.findByExecutionId(executionId);
    }

    public boolean isJobRunning(String jobId) {
        return runningExecutions.values().stream()
                .anyMatch(e -> e.getJobId().equals(jobId));
    }

    @Transactional
    public void cleanupExecutions(Date before) {
        log.info("Cleaning up executions before: {}", before);
        
        // 清理执行记录
        int execCount = executionRepository.deleteByEndTimeBefore(before);
        
        // 清理日志记录
        int logCount = jobLogRepository.deleteByCreateTimeBefore(before);
        
        log.info("Cleaned up {} executions and {} logs", execCount, logCount);
    }

    public void registerExecutionCallback(String executionId, Runnable callback) {
        JobExecution execution = getExecution(executionId);
        if (execution != null && !"RUNNING".equals(execution.getStatus())) {
            callback.run();
        } else {
            // 将回调添加到监听列表
            getCallbacks(executionId).add(callback);
        }
    }

    public void handleExecutionComplete(String executionId) {
        // 触发所有注册的回调
        List<Runnable> callbacks = getCallbacks(executionId);
        callbacks.forEach(callback -> {
            try {
                callback.run();
            } catch (Exception e) {
                log.error("Execution callback failed", e);
            }
        });
        callbacks.clear();
    }

    private List<Runnable> getCallbacks(String executionId) {
        return executionCallbacks.computeIfAbsent(executionId, k -> new ArrayList<>());
    }

    private final ConcurrentMap<String, List<Runnable>> executionCallbacks = new ConcurrentHashMap<>();
}

```

要继续实现JobTemplateManager和AlertManager吗？好的，让我们继续实现模板管理和告警管理组件：



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.api.model.request.job.JobTemplateRequest;
import com.study.scheduler.api.model.vo.job.JobTemplateVO;
import com.study.scheduler.api.model.vo.job.JobVO;
import com.study.scheduler.core.handler.VariableHandler;
import com.study.scheduler.domain.entity.job.JobTemplate;
import com.study.scheduler.domain.repository.JobTemplateRepository;
import com.study.scheduler.extension.template.TemplateEngine;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

@Slf4j
@Component
public class JobTemplateManager {

    @Autowired
    private JobTemplateRepository templateRepository;

    @Autowired
    private JobManager jobManager;

    @Autowired
    private TemplateEngine templateEngine;

    @Autowired
    private VariableHandler variableHandler;

    @Transactional
    public JobTemplateVO createTemplate(JobTemplateRequest request) {
        validateTemplate(request.getTemplateContent());

        JobTemplate template = new JobTemplate();
        template.setId(UUID.randomUUID().toString());
        template.setName(request.getName());
        template.setDescription(request.getDescription());
        template.setTemplateContent(request.getTemplateContent());
        template.setVariables(request.getVariables());
        template.setCreateTime(new Date());
        template.setUpdateTime(new Date());

        template = templateRepository.save(template);
        return convertToTemplateVO(template);
    }

    @Transactional
    public JobTemplateVO updateTemplate(String id, JobTemplateRequest request) {
        JobTemplate template = getTemplate(id);
        validateTemplate(request.getTemplateContent());

        template.setName(request.getName());
        template.setDescription(request.getDescription());
        template.setTemplateContent(request.getTemplateContent());
        template.setVariables(request.getVariables());
        template.setUpdateTime(new Date());

        template = templateRepository.save(template);
        return convertToTemplateVO(template);
    }

    @Transactional
    public void deleteTemplate(String id) {
        templateRepository.deleteById(id);
    }

    public JobTemplateVO getTemplate(String id) {
        JobTemplate template = findTemplate(id);
        return convertToTemplateVO(template);
    }

    public List<JobTemplateVO> listTemplates() {
        return templateRepository.findAll().stream()
                .map(this::convertToTemplateVO)
                .toList();
    }

    @Transactional
    public JobVO applyTemplate(String templateId, Map<String, Object> variables) {
        // 获取模板
        JobTemplate template = findTemplate(templateId);
        
        // 验证必需变量
        validateVariables(template, variables);
        
        // 解析模板
        String processedContent = templateEngine.process(
            template.getTemplateContent(), 
            variables
        );
        
        // 转换为任务请求
        JobRegisterRequest jobRequest = convertToJobRequest(processedContent);
        
        // 注册任务
        return jobManager.registerJob(jobRequest);
    }

    public Map<String, String> getTemplateVariables(String templateId) {
        JobTemplate template = findTemplate(templateId);
        return template.getVariables();
    }

    private void validateTemplate(String templateContent) {
        try {
            templateEngine.validate(templateContent);
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid template content: " + e.getMessage());
        }
    }

    private void validateVariables(JobTemplate template, Map<String, Object> variables) {
        Set<String> requiredVars = new HashSet<>(template.getVariables().keySet());
        requiredVars.removeAll(variables.keySet());
        
        if (!requiredVars.isEmpty()) {
            throw new IllegalArgumentException(
                "Missing required variables: " + String.join(", ", requiredVars));
        }
    }

    private JobTemplate findTemplate(String id) {
        return templateRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Template not found: " + id));
    }

    private JobRegisterRequest convertToJobRequest(String content) {
        try {
            return objectMapper.readValue(content, JobRegisterRequest.class);
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid job configuration: " + e.getMessage());
        }
    }

    private JobTemplateVO convertToTemplateVO(JobTemplate template) {
        JobTemplateVO vo = new JobTemplateVO();
        vo.setId(template.getId());
        vo.setName(template.getName());
        vo.setDescription(template.getDescription());
        vo.setTemplateContent(template.getTemplateContent());
        vo.setVariables(template.getVariables());
        vo.setCreateTime(template.getCreateTime());
        vo.setUpdateTime(template.getUpdateTime());
        return vo;
    }
}

```



```java
package com.study.scheduler.core.manager;

import com.study.scheduler.api.model.request.monitor.AlertRequest;
import com.study.scheduler.api.model.vo.monitor.AlertVO;
import com.study.scheduler.domain.entity.monitor.AlertRecord;
import com.study.scheduler.domain.repository.AlertRepository;
import com.study.scheduler.core.mq.producer.AlertProducer;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;
import java.util.concurrent.TimeUnit;

@Slf4j
@Component
public class AlertManager {

    private static final String ALERT_RULE_KEY = "scheduler:alert:rule:";
    private static final String ALERT_SILENCE_KEY = "scheduler:alert:silence:";

    @Autowired
    private AlertRepository alertRepository;

    @Autowired
    private AlertProducer alertProducer;

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    @Transactional
    public void createAlertRule(AlertRequest request) {
        validateRule(request);

        AlertRecord rule = new AlertRecord();
        rule.setId(UUID.randomUUID().toString());
        rule.setName(request.getName());
        rule.setLevel(request.getLevel());
        rule.setMetricName(request.getMetricName());
        rule.setThreshold(request.getThreshold());
        rule.setOperator(request.getOperator());
        rule.setDescription(request.getDescription());
        rule.setNotifyChannels(request.getNotifyChannels());
        rule.setLabels(request.getLabels());
        rule.setEnabled(request.getEnabled());
        rule.setCreateTime(new Date());
        rule.setUpdateTime(new Date());

        rule = alertRepository.save(rule);
        cacheAlertRule(rule);
    }

    public List<AlertVO> getAlertRules() {
        return alertRepository.findAll().stream()
                .map(this::convertToAlertVO)
                .toList();
    }

    public List<AlertVO> getActiveAlerts() {
        return alertRepository.findByStatus("ACTIVE").stream()
                .map(this::convertToAlertVO)
                .toList();
    }

    public List<AlertVO> getAlertHistory(String level, Long startTime, Long endTime) {
        return alertRepository.findAlertHistory(level, new Date(startTime), new Date(endTime))
                .stream()
                .map(this::convertToAlertVO)
                .toList();
    }

    @Transactional
    public void handleAlert(String metricName, double value, Map<String, String> labels) {
        // 查找匹配的规则
        List<AlertRecord> rules = findMatchingRules(metricName, labels);
        
        for (AlertRecord rule : rules) {
            if (isThresholdExceeded(rule, value)) {
                // 检查是否在静默期
                if (!isSilenced(rule.getId())) {
                    // 创建新告警
                    createAlert(rule, value);
                }
            }
        }
    }

    @Transactional
    public void acknowledgeAlert(String alertId) {
        AlertRecord alert = findAlert(alertId);
        
        // 更新状态
        alert.setStatus("ACKNOWLEDGED");
        alert.setUpdateTime(new Date());
        alertRepository.save(alert);
        
        // 设置静默期
        setSilenced(alert.getId(), alert.getSilenceDuration());
    }

    @Transactional
    public void resolveAlert(String alertId) {
        AlertRecord alert = findAlert(alertId);
        
        // 更新状态
        alert.setStatus("RESOLVED");
        alert.setUpdateTime(new Date());
        alertRepository.save(alert);
        
        // 发送恢复通知
        sendRecoveryNotification(alert);
    }

    private void validateRule(AlertRequest request) {
        // 验证阈值运算符
        if (!Arrays.asList(">", ">=", "<", "<=", "==").contains(request.getOperator())) {
            throw new IllegalArgumentException("Invalid operator: " + request.getOperator());
        }
        
        // 验证告警级别
        if (!Arrays.asList("INFO", "WARNING", "ERROR", "CRITICAL").contains(request.getLevel())) {
            throw new IllegalArgumentException("Invalid alert level: " + request.getLevel());
        }
    }

    private void cacheAlertRule(AlertRecord rule) {
        String key = ALERT_RULE_KEY + rule.getMetricName();
        redisTemplate.opsForList().rightPush(key, rule);
    }

    private List<AlertRecord> findMatchingRules(String metricName, Map<String, String> labels) {
        String key = ALERT_RULE_KEY + metricName;
        List<Object> rules = redisTemplate.opsForList().range(key, 0, -1);
        
        return rules.stream()
                .map(obj -> (AlertRecord) obj)
                .filter(rule -> matchLabels(rule.getLabels(), labels))
                .filter(AlertRecord::getEnabled)
                .toList();
    }

    private boolean matchLabels(Map<String, String> ruleLabels, Map<String, String> targetLabels) {
        return ruleLabels.entrySet().stream()
                .allMatch(entry -> 
                    targetLabels.containsKey(entry.getKey()) && 
                    targetLabels.get(entry.getKey()).equals(entry.getValue())
                );
    }

    private boolean isThresholdExceeded(AlertRecord rule, double value) {
        return switch (rule.getOperator()) {
            case ">" -> value > rule.getThreshold();
            case ">=" -> value >= rule.getThreshold();
            case "<" -> value < rule.getThreshold();
            case "<=" -> value <= rule.getThreshold();
            case "==" -> value == rule.getThreshold();
            default -> false;
        };
    }

    private boolean isSilenced(String alertId) {
        return redisTemplate.hasKey(ALERT_SILENCE_KEY + alertId);
    }

    private void setSilenced(String alertId, long duration) {
        redisTemplate.opsForValue().set(
            ALERT_SILENCE_KEY + alertId,
            "SILENCED",
            duration,
            TimeUnit.SECONDS
        );
    }

    private void createAlert(AlertRecord rule, double value) {
        AlertRecord alert = new AlertRecord();
        alert.setId(UUID.randomUUID().toString());
        alert.setRuleId(rule.getId());
        alert.setName(rule.getName());
        alert.setLevel(rule.getLevel());
        alert.setMetricName(rule.getMetricName());
        alert.setThreshold(rule.getThreshold());
        alert.setValue(value);
        alert.setStatus("ACTIVE");
        alert.setCreateTime(new Date());
        
        alert = alertRepository.save(alert);
        
        // 发送告警通知
        sendAlertNotification(alert);
    }

    private void sendAlertNotification(AlertRecord alert) {
        alert.getNotifyChannels().forEach(channel -> {
            try {
                alertProducer.sendAlert(channel, alert);
            } catch (Exception e) {
                log.error("Failed to send alert notification", e);
            }
        });
    }

    private void sendRecoveryNotification(AlertRecord alert) {
        alert.getNotifyChannels().forEach(channel -> {
            try {
                alertProducer.sendRecovery(channel, alert);
            } catch (Exception e) {
                log.error("Failed to send recovery notification", e);
            }
        });
    }

    private AlertRecord findAlert(String alertId) {
        return alertRepository.findById(alertId)
                .orElseThrow(() -> new IllegalArgumentException("Alert not found: " + alertId));
    }

    private AlertVO convertToAlertVO(AlertRecord alert) {
        AlertVO vo = new AlertVO();
        vo.setId(alert.getId());
        vo.setName(alert.getName());
        vo.setLevel(alert.getLevel());
        vo.setMetricName(alert.getMetricName());
        vo.setThreshold(alert.getThreshold());
        vo.setOperator(alert.getOperator());
        vo.setDescription(alert.getDescription());
        vo.setNotifyChannels(alert.getNotifyChannels());
        vo.setLabels(alert.getLabels());
        vo.setEnabled(alert.getEnabled());
        vo.setCreateTime(alert.getCreateTime());
        vo.setUpdateTime(alert.getUpdateTime());
        return vo;
    }
}

```

需要我继续实现Domain层的实体和仓储接口吗？好的，让我们实现Domain层的实体和仓储接口，从核心任务实体开始：



```java
package com.study.scheduler.domain.entity.job;

import lombok.Data;
import java.util.Date;
import java.util.Map;

@Data
public class JobDefinition {
    private String id;
    private String name;
    private String description;
    private String jobType;
    private String cronExpression;
    private Long fixedDelay;
    private Long timeout;
    private Integer maxRetries;
    private Long retryInterval;
    private Map<String, Object> jobData;
    private String status;
    private Date createTime;
    private Date updateTime;

    public boolean isEnabled() {
        return "ENABLED".equals(status);
    }

    public boolean canRetry() {
        return maxRetries != null && maxRetries > 0;
    }
}

@Data
public class JobExecution {
    private String id;
    private String jobId;
    private String nodeId;
    private Date startTime;
    private Date endTime;
    private String status;
    private String result;
    private String error;
    private Integer retryCount;
    private String traceId;
    private Date createTime;
    private Date updateTime;

    public boolean isCompleted() {
        return "SUCCESS".equals(status) || "FAILED".equals(status);
    }

    public long getDuration() {
        if (startTime != null && endTime != null) {
            return endTime.getTime() - startTime.getTime();
        }
        return 0;
    }
}

@Data
public class JobLog {
    private String id;
    private String executionId;
    private String jobId;
    private String logType;
    private String content;
    private Date createTime;
}

@Data
public class JobTemplate {
    private String id;
    private String name;
    private String description;
    private String templateContent;
    private Map<String, String> variables;
    private String tags;
    private Date createTime;
    private Date updateTime;
}

package com.study.scheduler.domain.entity.monitor;

@Data
public class AlertRecord {
    private String id;
    private String ruleId;
    private String name;
    private String level;
    private String metricName;
    private Double threshold;
    private Double value;
    private String operator;
    private String description;
    private List<String> notifyChannels;
    private Map<String, String> labels;
    private Boolean enabled;
    private String status;
    private Long silenceDuration;
    private Date createTime;
    private Date updateTime;
}

@Data
public class MetricsRecord {
    private String id;
    private String metricName;
    private Double value;
    private String nodeId;
    private Map<String, String> tags;
    private Date timestamp;
    private Date createTime;
}

```

接下来是仓储接口定义：



```java
package com.study.scheduler.domain.repository;

import com.study.scheduler.domain.entity.job.JobDefinition;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import java.util.List;
import java.util.Date;

public interface JobRepository extends JpaRepository<JobDefinition, String> {
    
    List<JobDefinition> findByStatus(String status);
    
    List<JobDefinition> findByJobType(String jobType);
    
    @Query("SELECT j FROM JobDefinition j WHERE " +
           "(:name IS NULL OR j.name LIKE %:name%) AND " +
           "(:jobType IS NULL OR j.jobType = :jobType) AND " +
           "(:status IS NULL OR j.status = :status) AND " +
           "j.createTime BETWEEN :startTime AND :endTime")
    List<JobDefinition> findJobs(
        @Param("name") String name,
        @Param("jobType") String jobType,
        @Param("status") String status,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
    
    @Query("SELECT COUNT(j) FROM JobDefinition j WHERE j.status = :status")
    long countByStatus(@Param("status") String status);
}

public interface ExecutionRepository extends JpaRepository<JobExecution, String> {
    
    List<JobExecution> findByJobId(String jobId);
    
    List<JobExecution> findByStatus(String status);
    
    List<JobExecution> findByJobIdAndStatus(String jobId, String status);
    
    @Query("SELECT e FROM JobExecution e WHERE " +
           "e.jobId = :jobId AND e.startTime BETWEEN :startTime AND :endTime")
    List<JobExecution> findExecutions(
        @Param("jobId") String jobId,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
    
    int deleteByEndTimeBefore(Date time);
}

public interface JobLogRepository extends JpaRepository<JobLog, String> {
    
    List<JobLog> findByExecutionId(String executionId);
    
    List<JobLog> findByJobId(String jobId);
    
    List<JobLog> findByLogType(String logType);
    
    @Query("SELECT l FROM JobLog l WHERE " +
           "l.jobId = :jobId AND l.createTime BETWEEN :startTime AND :endTime")
    List<JobLog> findLogs(
        @Param("jobId") String jobId,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
    
    int deleteByCreateTimeBefore(Date time);
}

public interface JobTemplateRepository extends JpaRepository<JobTemplate, String> {
    
    List<JobTemplate> findByNameContaining(String name);
    
    @Query("SELECT t FROM JobTemplate t WHERE " + 
           "t.tags LIKE %:tag%")
    List<JobTemplate> findByTag(@Param("tag") String tag);
}

public interface AlertRepository extends JpaRepository<AlertRecord, String> {
    
    List<AlertRecord> findByLevel(String level);
    
    List<AlertRecord> findByStatus(String status);
    
    List<AlertRecord> findByRuleId(String ruleId);
    
    @Query("SELECT a FROM AlertRecord a WHERE " +
           "(:level IS NULL OR a.level = :level) AND " +
           "a.createTime BETWEEN :startTime AND :endTime")
    List<AlertRecord> findAlertHistory(
        @Param("level") String level,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
}

public interface MetricsRepository extends JpaRepository<MetricsRecord, String> {
    
    List<MetricsRecord> findByMetricName(String metricName);
    
    List<MetricsRecord> findByNodeId(String nodeId);
    
    @Query("SELECT m FROM MetricsRecord m WHERE " +
           "m.metricName = :metricName AND " +
           "m.timestamp BETWEEN :startTime AND :endTime")
    List<MetricsRecord> findMetricsHistory(
        @Param("metricName") String metricName,
        @Param("startTime") Date startTime,
        @Param("endTime") Date endTime
    );
}

```

需要我继续实现Domain层的服务类(DomainService)吗？这些服务类包含了核心的业务逻辑。好的，让我们实现Domain层的服务类，先从任务相关的领域服务开始：



```java
package com.study.scheduler.domain.service;

import com.study.scheduler.api.model.request.job.*;
import com.study.scheduler.api.model.vo.job.*;
import com.study.scheduler.core.scheduler.JobScheduler;
import com.study.scheduler.domain.entity.job.*;
import com.study.scheduler.domain.repository.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

@Slf4j
@Service
public class JobDomainService {

    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private JobLogRepository jobLogRepository;
    
    @Autowired
    private JobScheduler jobScheduler;
    
    @Autowired
    private ExecutionDomainService executionService;

    @Transactional
    public JobVO createJob(JobCreateRequest request) {
        // 校验请求
        validateJobRequest(request);
        
        // 创建任务定义
        JobDefinition jobDef = new JobDefinition();
        jobDef.setId(UUID.randomUUID().toString());
        jobDef.setName(request.getName());
        jobDef.setDescription(request.getDescription());
        jobDef.setJobType(request.getJobType());
        jobDef.setCronExpression(request.getCronExpression());
        jobDef.setFixedDelay(request.getFixedDelay());
        jobDef.setTimeout(request.getTimeout());
        jobDef.setMaxRetries(request.getMaxRetries());
        jobDef.setRetryInterval(request.getRetryInterval());
        jobDef.setJobData(request.getJobData());
        jobDef.setStatus("CREATED");
        jobDef.setCreateTime(new Date());
        jobDef.setUpdateTime(new Date());
        
        // 保存任务
        jobDef = jobRepository.save(jobDef);
        log.info("Created job: {}", jobDef.getId());
        
        return convertToJobVO(jobDef);
    }

    @Transactional
    public JobVO updateJob(String jobId, JobUpdateRequest request) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 更新字段
        if (request.getName() != null) {
            jobDef.setName(request.getName());
        }
        if (request.getDescription() != null) {
            jobDef.setDescription(request.getDescription());
        }
        if (request.getCronExpression() != null) {
            jobDef.setCronExpression(request.getCronExpression());
        }
        if (request.getFixedDelay() != null) {
            jobDef.setFixedDelay(request.getFixedDelay());
        }
        if (request.getTimeout() != null) {
            jobDef.setTimeout(request.getTimeout());
        }
        if (request.getMaxRetries() != null) {
            jobDef.setMaxRetries(request.getMaxRetries());
        }
        if (request.getRetryInterval() != null) {
            jobDef.setRetryInterval(request.getRetryInterval());
        }
        if (request.getJobData() != null) {
            jobDef.setJobData(request.getJobData());
        }
        
        jobDef.setUpdateTime(new Date());
        
        // 保存更新
        jobDef = jobRepository.save(jobDef);
        
        // 如果任务已调度，则更新调度信息
        if (jobDef.isEnabled()) {
            jobScheduler.updateJob(jobDef);
        }
        
        log.info("Updated job: {}", jobId);
        return convertToJobVO(jobDef);
    }

    @Transactional
    public void deleteJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 如果任务正在执行，则不允许删除
        if (executionService.isJobRunning(jobId)) {
            throw new IllegalStateException("Cannot delete running job: " + jobId);
        }
        
        // 删除调度信息
        if (jobDef.isEnabled()) {
            jobScheduler.deleteJob(jobId);
        }
        
        // 删除任务定义
        jobRepository.deleteById(jobId);
        
        log.info("Deleted job: {}", jobId);
    }

    public JobDetailVO getJobDetail(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        return convertToJobDetailVO(jobDef);
    }

    public List<JobVO> queryJobs(JobQueryRequest request) {
        List<JobDefinition> jobs = jobRepository.findJobs(
            request.getName(),
            request.getJobType(),
            request.getStatus(),
            new Date(request.getStartTime()),
            new Date(request.getEndTime())
        );
        
        return jobs.stream()
                .map(this::convertToJobVO)
                .toList();
    }

    public List<JobLogVO> getJobLogs(String jobId) {
        List<JobLog> logs = jobLogRepository.findByJobId(jobId);
        return logs.stream()
                .map(this::convertToJobLogVO)
                .toList();
    }

    @Transactional
    public void pauseJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if (jobDef.isEnabled()) {
            jobDef.setStatus("DISABLED");
            jobDef.setUpdateTime(new Date());
            jobRepository.save(jobDef);
            
            jobScheduler.pauseJob(jobId);
            log.info("Paused job: {}", jobId);
        }
    }

    @Transactional
    public void resumeJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        if (!jobDef.isEnabled()) {
            jobDef.setStatus("ENABLED");
            jobDef.setUpdateTime(new Date());
            jobRepository.save(jobDef);
            
            jobScheduler.resumeJob(jobId);
            log.info("Resumed job: {}", jobId);
        }
    }

    private void validateJobRequest(JobCreateRequest request) {
        // 校验CRON表达式
        if (request.getCronExpression() != null) {
            validateCronExpression(request.getCronExpression());
        }
        
        // 校验固定延迟
        if (request.getFixedDelay() != null && request.getFixedDelay() <= 0) {
            throw new IllegalArgumentException("Fixed delay must be positive");
        }
        
        // 校验超时时间
        if (request.getTimeout() != null && request.getTimeout() <= 0) {
            throw new IllegalArgumentException("Timeout must be positive");
        }
        
        // 校验重试配置
        if (request.getMaxRetries() != null && request.getMaxRetries() < 0) {
            throw new IllegalArgumentException("Max retries cannot be negative");
        }
        
        if (request.getRetryInterval() != null && request.getRetryInterval() <= 0) {
            throw new IllegalArgumentException("Retry interval must be positive");
        }
    }

    private void validateCronExpression(String cronExpression) {
        try {
            new CronExpression(cronExpression);
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid cron expression: " + e.getMessage());
        }
    }

    private JobDefinition getJobDefinition(String jobId) {
        return jobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
    }

    private JobVO convertToJobVO(JobDefinition jobDef) {
        JobVO vo = new JobVO();
        vo.setId(jobDef.getId());
        vo.setName(jobDef.getName());
        vo.setDescription(jobDef.getDescription());
        vo.setJobType(jobDef.getJobType());
        vo.setCronExpression(jobDef.getCronExpression());
        vo.setFixedDelay(jobDef.getFixedDelay());
        vo.setStatus(jobDef.getStatus());
        vo.setNextFireTime(jobScheduler.getNextFireTime(jobDef.getId()));
        vo.setCreateTime(jobDef.getCreateTime());
        vo.setUpdateTime(jobDef.getUpdateTime());
        return vo;
    }

    private JobDetailVO convertToJobDetailVO(JobDefinition jobDef) {
        JobDetailVO vo = new JobDetailVO();
        // 复制基本字段
        BeanUtils.copyProperties(convertToJobVO(jobDef), vo);
        // 添加详细信息
        vo.setTimeout(jobDef.getTimeout());
        vo.setMaxRetries(jobDef.getMaxRetries());
        vo.setRetryInterval(jobDef.getRetryInterval());
        vo.setJobData(jobDef.getJobData());
        // 获取最后一次执行记录
        vo.setLastExecution(executionService.getLastExecution(jobDef.getId()));
        // 获取统计信息
        vo.setStatistics(executionService.getJobStatistics(jobDef.getId()));
        return vo;
    }

    private JobLogVO convertToJobLogVO(JobLog log) {
        JobLogVO vo = new JobLogVO();
        vo.setId(log.getId());
        vo.setExecutionId(log.getExecutionId());
        vo.setJobId(log.getJobId());
        vo.setLogType(log.getLogType());
        vo.setContent(log.getContent());
        vo.setCreateTime(log.getCreateTime());
        return vo;
    }
}

```

让我继续实现执行相关的领域服务：

```java
package com.study.scheduler.domain.service;

import com.study.scheduler.api.model.request.job.JobExecuteRequest;
import com.study.scheduler.core.executor.*;
import com.study.scheduler.domain.entity.job.*;
import com.study.scheduler.domain.repository.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;
import java.util.concurrent.CompletableFuture;

@Slf4j
@Service
public class ExecutionDomainService {

    @Autowired
    private ExecutionRepository executionRepository;
    
    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private List<JobExecutor> jobExecutors;

    @Transactional
    public ExecuteResult executeJob(String jobId, JobExecuteRequest request) {
        // 获取任务定义
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 创建执行记录
        JobExecution execution = createExecution(jobDef);
        
        try {
            // 获取执行器
            JobExecutor executor = findExecutor(jobDef.getJobType());
            
            // 构建执行上下文
            ExecuteContext context = buildExecuteContext(jobDef, execution, request);
            
            // 异步执行
            if (request.getAsync()) {
                CompletableFuture.runAsync(() -> {
                    executeWithContext(executor, context);
                });
                return ExecuteResult.success("Job execution started");
            }
            
            // 同步执行
            return executeWithContext(executor, context);
            
        } catch (Exception e) {
            log.error("Job execution failed: " + jobId, e);
            failExecution(execution, e);
            return ExecuteResult.failure(e.getMessage());
        }
    }

    public void stopJob(String jobId) {
        List<JobExecution> runningExecutions = executionRepository
                .findByJobIdAndStatus(jobId, "RUNNING");
                
        for (JobExecution execution : runningExecutions) {
            stopExecution(execution);
        }
    }

    @Transactional
    public ExecuteResult retryJob(String jobId) {
        JobDefinition jobDef = getJobDefinition(jobId);
        
        // 检查是否可以重试
        if (!jobDef.canRetry()) {
            throw new IllegalStateException("Job is not configured for retry: " + jobId);
        }
        
        // 获取最后一次执行
        JobExecution lastExecution = getLastExecution(jobId);
        if (lastExecution == null || !lastExecution.isCompleted()) {
            throw new IllegalStateException("No failed execution to retry");
        }
        
        // 检查重试次数
        if (lastExecution.getRetryCount() >= jobDef.getMaxRetries()) {
            throw new IllegalStateException("Max retry attempts exceeded");
        }
        
        // 创建重试请求
        JobExecuteRequest request = new JobExecuteRequest();
        request.setParameters(Collections.emptyMap());
        request.setTimeout(jobDef.getTimeout());
        
        return executeJob(jobId, request);
    }

    public String getJobStatus(String jobId) {
        JobExecution lastExecution = getLastExecution(jobId);
        return lastExecution != null ? lastExecution.getStatus() : "UNKNOWN";
    }

    public boolean isJobRunning(String jobId) {
        return executionRepository.findByJobIdAndStatus(jobId, "RUNNING")
                .stream()
                .findAny()
                .isPresent();
    }

    public JobExecution getLastExecution(String jobId) {
        return executionRepository.findByJobId(jobId).stream()
                .max(Comparator.comparing(JobExecution::getStartTime))
                .orElse(null);
    }

    public JobStatisticsVO getJobStatistics(String jobId) {
        List<JobExecution> executions = executionRepository.findByJobId(jobId);
        
        JobStatisticsVO stats = new JobStatisticsVO();
        stats.setTotalExecutions((long) executions.size());
        stats.setSuccessCount(executions.stream()
                .filter(e -> "SUCCESS".equals(e.getStatus()))
                .count());
        stats.setFailureCount(executions.stream()
                .filter(e -> "FAILED".equals(e.getStatus()))
                .count());
        
        // 计算平均执行时间
        Double avgDuration = executions.stream()
                .mapToLong(JobExecution::getDuration)
                .average()
                .orElse(0.0);
        stats.setAverageDuration(avgDuration);
        
        // 获取最后成功和失败时间
        executions.stream()
                .filter(e -> "SUCCESS".equals(e.getStatus()))
                .max(Comparator.comparing(JobExecution::getEndTime))
                .ifPresent(e -> stats.setLastSuccessTime(
                    e.getEndTime().getTime
```好的，让我们继续完成ExecutionDomainService中未完成的部分：



```java
// ExecutionDomainService.java继续...
    
    private JobDefinition getJobDefinition(String jobId) {
        return jobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
    }

    private JobExecutor findExecutor(String jobType) {
        return jobExecutors.stream()
                .filter(executor -> executor.supports(jobType))
                .findFirst()
                .orElseThrow(() -> new IllegalArgumentException(
                    "No executor found for job type: " + jobType));
    }

    private JobExecution createExecution(JobDefinition jobDef) {
        JobExecution execution = new JobExecution();
        execution.setId(UUID.randomUUID().toString());
        execution.setJobId(jobDef.getId());
        execution.setNodeId(getNodeId());
        execution.setStartTime(new Date());
        execution.setStatus("RUNNING");
        execution.setRetryCount(0);
        execution.setTraceId(generateTraceId());
        execution.setCreateTime(new Date());
        execution.setUpdateTime(new Date());
        
        return executionRepository.save(execution);
    }

    private ExecuteContext buildExecuteContext(
            JobDefinition jobDef, 
            JobExecution execution,
            JobExecuteRequest request) {
        ExecuteContext context = new ExecuteContext();
        context.setJobId(jobDef.getId());
        context.setExecutionId(execution.getId());
        context.setJobType(jobDef.getJobType());
        context.setJobData(jobDef.getJobData());
        context.setParameters(request.getParameters());
        context.setTimeout(request.getTimeout() != null ? 
                request.getTimeout() : jobDef.getTimeout());
        context.setExecution(execution);
        return context;
    }

    private ExecuteResult executeWithContext(JobExecutor executor, ExecuteContext context) {
        try {
            // 执行前处理
            executor.beforeExecute(context);
            
            // 执行任务
            ExecuteResult result = executor.execute(context);
            
            // 执行后处理
            executor.afterExecute(context, result);
            
            // 更新执行状态
            if (result.isSuccess()) {
                completeExecution(context.getExecution(), result);
            } else {
                failExecution(context.getExecution(), new RuntimeException(result.getError()));
            }
            
            return result;
            
        } catch (Exception e) {
            log.error("Job execution failed", e);
            failExecution(context.getExecution(), e);
            return ExecuteResult.failure(e.getMessage());
        }
    }

    private void completeExecution(JobExecution execution, ExecuteResult result) {
        execution.setEndTime(new Date());
        execution.setStatus("SUCCESS");
        execution.setResult(result.getResult());
        execution.setUpdateTime(new Date());
        executionRepository.save(execution);
    }

    private void failExecution(JobExecution execution, Exception e) {
        execution.setEndTime(new Date());
        execution.setStatus("FAILED");
        execution.setError(e.getMessage());
        execution.setUpdateTime(new Date());
        executionRepository.save(execution);
    }

    private void stopExecution(JobExecution execution) {
        // 只能停止运行中的任务
        if ("RUNNING".equals(execution.getStatus())) {
            execution.setEndTime(new Date());
            execution.setStatus("STOPPED");
            execution.setError("Execution stopped by user");
            execution.setUpdateTime(new Date());
            executionRepository.save(execution);
        }
    }

    private String getNodeId() {
        return System.getenv().getOrDefault("HOSTNAME", "unknown");
    }

    private String generateTraceId() {
        return UUID.randomUUID().toString();
    }
}

```

现在我们实现监控领域服务：

```java
package com.study.scheduler.domain.service;

import com.study.scheduler.domain.entity.monitor.*;
import com.study.scheduler.domain.repository.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import java.util.*;

@Slf4j
@Service
public class MonitorDomainService {

    @Autowired
    private AlertRepository alertRepository;
    
    @Autowired
    private MetricsRepository metricsRepository;

    @Transactional
    public void recordMetrics(String metricName, double value, String nodeId, 
            Map<String, String> tags) {
        MetricsRecord record = new MetricsRecord();
        record.setId(UUID.randomUUID().toString());
        record.setMetricName(metricName);
        record.setValue(value);
        record.setNodeId(nodeId);
        record.setTags(tags);
        record.setTimestamp(new Date());
        record.setCreateTime(new Date());
        
        metricsRepository.save(record);
        
        // 检查告警规则
        checkAlertRules(metricName, value, tags);
    }

    public List<MetricsRecord> getMetricsHistory(String metricName, 
            Date startTime, Date endTime) {
        return metricsRepository.findMetricsHistory(metricName, startTime, endTime);
    }

    @Transactional
    public void createAlert(AlertRecord alert) {
        alert.setId(UUID.randomUUID().toString());
        alert.setStatus("ACTIVE");
        alert.setCreateTime(new Date());
        alert.setUpdateTime(new Date());
        
        alertRepository.save(alert);
    }

    @Transactional
    public void acknowledgeAlert(String alertId) {
        AlertRecord alert = getAlert(alertId);
        
        if ("ACTIVE".equals(alert.getStatus())) {
            alert.setStatus("ACKNOWLEDGED");
            alert.setUpdateTime(new Date());
            alertRepository.save(alert);
        }
    }

    @Transactional
    public void resolveAlert(String alertId) {
        AlertRecord alert = getAlert(alertId);
        
        if (!alert.getStatus().equals("RESOLVED")) {
            alert.setStatus("RESOLVED");
            alert.setUpdateTime(new Date());
            alertRepository.save(alert);
        }
    }

    public List<AlertRecord> getActiveAlerts() {
        return alertRepository.findByStatus("ACTIVE");
    }

    public List<AlertRecord> getAlertHistory(String level, Date startTime, Date endTime) {
        return alertRepository.findAlertHistory(level, startTime, endTime);
    }

    private void checkAlertRules(String metricName, double value, Map<String, String> tags) {
        List<AlertRecord> rules = alertRepository.findByMetricName(metricName);
        
        for (AlertRecord rule : rules) {
            if (isRuleMatched(rule, value, tags)) {
                createAlert(buildAlert(rule, value));
            }
        }
    }

    private boolean isRuleMatched(AlertRecord rule, double value, Map<String, String> tags) {
        // 检查标签匹配
        if (!matchLabels(rule.getLabels(), tags)) {
            return false;
        }
        
        // 检查阈值条件
        return switch (rule.getOperator()) {
            case ">" -> value > rule.getThreshold();
            case ">=" -> value >= rule.getThreshold();
            case "<" -> value < rule.getThreshold();
            case "<=" -> value <= rule.getThreshold();
            case "==" -> value == rule.getThreshold();
            default -> false;
        };
    }

    private boolean matchLabels(Map<String, String> ruleLabels, Map<String, String> tags) {
        return ruleLabels.entrySet().stream()
                .allMatch(entry -> 
                    tags.containsKey(entry.getKey()) && 
                    tags.get(entry.getKey()).equals(entry.getValue())
                );
    }

    private AlertRecord buildAlert(AlertRecord rule, double value) {
        AlertRecord alert = new AlertRecord();
        alert.setRuleId(rule.getId());
        alert.setName(rule.getName());
        alert.setLevel(rule.getLevel());
        alert.setMetricName(rule.getMetricName());
        alert.setThreshold(rule.getThreshold());
        alert.setValue(value);
        alert.setOperator(rule.getOperator());
        alert.setLabels(rule.getLabels());
        alert.setNotifyChannels(rule.getNotifyChannels());
        return alert;
    }

    private AlertRecord getAlert(String alertId) {
        return alertRepository.findById(alertId)
                .orElseThrow(() -> new IllegalArgumentException("Alert not found: " + alertId));
    }
}

```

需要我继续实现基础设施层(Infrastructure)的组件吗？包括持久化实现、消息队列等。好的，让我们开始实现基础设施层的组件，首先从配置类开始：



```java
package com.study.scheduler.infra.config;

import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import javax.sql.DataSource;

@Configuration
public class DatabaseConfig {
    
    @Value("${spring.datasource.url}")
    private String url;
    
    @Value("${spring.datasource.username}")
    private String username;
    
    @Value("${spring.datasource.password}")
    private String password;
    
    @Value("${spring.datasource.hikari.maximum-pool-size}")
    private int maxPoolSize;
    
    @Bean
    @Primary
    public DataSource dataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl(url);
        config.setUsername(username);
        config.setPassword(password);
        config.setMaximumPoolSize(maxPoolSize);
        config.setConnectionTestQuery("SELECT 1");
        config.addDataSourceProperty("cachePrepStmts", "true");
        config.addDataSourceProperty("prepStmtCacheSize", "250");
        config.addDataSourceProperty("prepStmtCacheSqlLimit", "2048");
        
        return new HikariDataSource(config);
    }
}

@Configuration
@EnableRedisRepositories
public class RedisConfig {
    
    @Value("${spring.data.redis.cluster.nodes}")
    private List<String> nodes;
    
    @Value("${spring.data.redis.password}")
    private String password;
    
    @Bean
    public RedisConnectionFactory redisConnectionFactory() {
        RedisClusterConfiguration config = new RedisClusterConfiguration(nodes);
        config.setPassword(password);
        
        return new LettuceConnectionFactory(config);
    }
    
    @Bean
    public RedisTemplate<String, Object> redisTemplate(
            RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);
        template.setKeySerializer(new StringRedisSerializer());
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());
        return template;
    }
}

@Configuration
public class RabbitConfig {
    
    @Value("${spring.rabbitmq.host}")
    private String host;
    
    @Value("${spring.rabbitmq.port}")
    private int port;
    
    @Value("${spring.rabbitmq.username}")
    private String username;
    
    @Value("${spring.rabbitmq.password}")
    private String password;
    
    @Bean
    public ConnectionFactory rabbitConnectionFactory() {
        CachingConnectionFactory factory = new CachingConnectionFactory();
        factory.setHost(host);
        factory.setPort(port);
        factory.setUsername(username);
        factory.setPassword(password);
        factory.setPublisherConfirmType(CachingConnectionFactory.ConfirmType.CORRELATED);
        factory.setPublisherReturns(true);
        return factory;
    }
    
    @Bean
    public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) {
        RabbitTemplate template = new RabbitTemplate(connectionFactory);
        template.setMandatory(true);
        template.setMessageConverter(new Jackson2JsonMessageConverter());
        
        template.setConfirmCallback((correlation, ack, reason) -> {
            if (!ack) {
                log.error("Message send failed: {}", reason);
            }
        });
        
        template.setReturnsCallback(returned -> {
            log.error("Message returned: {}", returned.getMessage());
        });
        
        return template;
    }
    
    @Bean
    public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(
            ConnectionFactory connectionFactory) {
        SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory();
        factory.setConnectionFactory(connectionFactory);
        factory.setConcurrentConsumers(3);
        factory.setMaxConcurrentConsumers(10);
        factory.setPrefetchCount(1);
        factory.setMessageConverter(new Jackson2JsonMessageConverter());
        factory.setAcknowledgeMode(AcknowledgeMode.MANUAL);
        return factory;
    }
}

@Configuration
public class ThreadPoolConfig {
    
    @Value("${scheduler.execution.pool.core-size}")
    private int coreSize;
    
    @Value("${scheduler.execution.pool.max-size}")
    private int maxSize;
    
    @Value("${scheduler.execution.pool.queue-capacity}")
    private int queueCapacity;
    
    @Value("${scheduler.execution.pool.keep-alive}")
    private int keepAlive;
    
    @Bean
    public ThreadPoolExecutor executorService() {
        return new ThreadPoolExecutor(
            coreSize,
            maxSize,
            keepAlive,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(queueCapacity),
            new ThreadFactoryBuilder()
                .setNameFormat("job-executor-%d")
                .setDaemon(true)
                .build(),
            new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }
}

```

接下来实现仓储的具体实现类：

```java
package com.study.scheduler.infra.persistence.repository;

import com.study.scheduler.domain.entity.job.JobDefinition;
import com.study.scheduler.domain.repository.JobRepository;
import com.study.scheduler.infra.persistence.entity.JobDefinitionDO;
import com.study.scheduler.infra.persistence.mapper.JobMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Repository;

@Repository
public class JobRepositoryImpl implements JobRepository {

    @Autowired
    private JobMapper jobMapper;
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    private static final String CACHE_KEY = "scheduler:job:";
    private static final Duration CACHE_TTL = Duration.ofMinutes(5);

    @Override
    public JobDefinition save(JobDefinition jobDef) {
        // 转换为DO对象
        JobDefinitionDO jobDO = convertToDO(jobDef);
        
        if (jobDO.getId() == null) {
            // 新增
            jobMapper.insert(jobDO);
        } else {
            // 更新
            jobMapper.update(jobDO);
        }
        
        // 更新缓存
        jobDef.setId(jobDO.getId());
        updateCache(jobDef);
        
        return jobDef;
    }

    @Override
    public Optional<JobDefinition> findById(String id) {
        // 先查缓存
        String key = CACHE_KEY + id;
        Object cached = redisTemplate.opsForValue().get(key);
        if (cached != null) {
            return Optional.of((JobDefinition) cached);
        }
        
        // 查数据库
        JobDefinitionDO jobDO = jobMapper.findById(id);
        if (jobDO == null) {
            return Optional.empty();
        }
        
        // 转换并缓存
        JobDefinition jobDef = convertToEntity(jobDO);
        updateCache(jobDef);
        
        return Optional.of(jobDef);
    }

    @Override
    public List<JobDefinition> findByStatus(String status) {
        return jobMapper.findByStatus(status).stream()
                .map(this::convertToEntity)
                .collect(Collectors.toList());
    }

    @Override
    public void deleteById(String id) {
        jobMapper.deleteById(id);
        redisTemplate.delete(CACHE_KEY + id);
    }

    private void updateCache(JobDefinition jobDef) {
        String key = CACHE_KEY + jobDef.getId();
        redisTemplate.opsForValue().set(key, jobDef, CACHE_TTL);
    }

    private JobDefinitionDO convertToDO(JobDefinition entity) {
        JobDefinitionDO DO = new JobDefinitionDO();
        BeanUtils.copyProperties(entity, DO);
        DO.setJobDataJson(JsonUtils.toJson(entity.getJobData()));
        return DO;
    }

    private JobDefinition convertToEntity(JobDefinitionDO DO) {
        JobDefinition entity = new JobDefinition();
        BeanUtils.copyProperties(DO, entity);
        entity.setJobData(JsonUtils.fromJson(DO.getJobDataJson(), Map.class));
        return entity;
    }
}

@Repository
public class ExecutionRepositoryImpl implements ExecutionRepository {

    @Autowired
    private MongoTemplate mongoTemplate;

    @Override
    public JobExecution save(JobExecution execution) {
        return mongoTemplate.save(execution);
    }

    @Override
    public Optional<JobExecution> findById(String id) {
        JobExecution execution = mongoTemplate.findById(id, JobExecution.class);
        return Optional.ofNullable(execution);
    }

    @Override
    public List<JobExecution> findByJobId(String jobId) {
        Query query = Query.query(Criteria.where("jobId").is(jobId));
        return mongoTemplate.find(query, JobExecution.class);
    }

    @Override
    public List<JobExecution> findByStatus(String status) {
        Query query = Query.query(Criteria.where("status").is(status));
        return mongoTemplate.find(query, JobExecution.class);
    }

    @Override
    public int deleteByEndTimeBefore(Date time) {
        Query query = Query.query(Criteria.where("endTime").lt(time));
        DeleteResult result = mongoTemplate.remove(query, JobExecution.class);
        return (int) result.getDeletedCount();
    }
}

```

需要我继续实现消息队列相关的组件吗？包括生产者和消费者。