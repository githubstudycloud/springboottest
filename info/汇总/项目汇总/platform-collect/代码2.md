好的，让我们实现DataSyncService - 数据同步领域服务。



```java
package com.platform.collect.domain.service.sync;

import com.platform.collect.domain.entity.sync.*;
import com.platform.collect.domain.repository.sync.SyncRepository;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

/**
 * 数据同步领域服务
 */
@Slf4j
@Service
public class DataSyncService {

    @Autowired
    private SyncRepository syncRepository;

    @Autowired
    private DataComparator dataComparator;

    @Autowired
    private ConsistencyChecker consistencyChecker;

    @Autowired
    private TransactionManager transactionManager;

    /**
     * 提交同步任务
     */
    @Transactional
    public String submitSyncTask(SyncRequest request) {
        try {
            // 1. 验证请求
            validateSyncRequest(request);

            // 2. 创建同步任务
            SyncTask task = createSyncTask(request);
            syncRepository.saveTask(task);

            // 3. 异步执行同步
            submitSyncExecution(task);

            return task.getTaskId();

        } catch (Exception e) {
            log.error("Submit sync task failed", e);
            throw new SyncException("Submit sync task failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取同步状态
     */
    public Map<String, Object> getSyncStatus(String syncId) {
        try {
            // 1. 获取任务信息
            SyncTask task = getTask(syncId);

            // 2. 获取进度信息
            SyncProgress progress = syncRepository.getProgress(syncId);

            // 3. 构建状态信息
            return buildSyncStatus(task, progress);

        } catch (Exception e) {
            log.error("Get sync status failed, syncId: {}", syncId, e);
            throw new SyncException("Get sync status failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行数据对比
     */
    public DataCompareVO compareData(CompareRequest request) {
        try {
            // 1. 获取源数据
            List<Map<String, Object>> sourceData = getSourceData(
                request.getSourceId(),
                request.getVersion()
            );

            // 2. 获取目标数据
            List<Map<String, Object>> targetData = getTargetData(
                request.getTargetId(),
                request.getVersion()
            );

            // 3. 执行数据对比
            return dataComparator.compare(sourceData, targetData, request.getCompareType());

        } catch (Exception e) {
            log.error("Compare data failed", e);
            throw new SyncException("Compare data failed: " + e.getMessage(), e);
        }
    }

    /**
     * 刷新数据
     */
    @Transactional
    public String refreshData(String sourceId) {
        try {
            // 1. 创建刷新任务
            RefreshTask task = createRefreshTask(sourceId);
            syncRepository.saveRefreshTask(task);

            // 2. 执行刷新
            executeRefresh(task);

            return task.getTaskId();

        } catch (Exception e) {
            log.error("Refresh data failed, sourceId: {}", sourceId, e);
            throw new SyncException("Refresh data failed: " + e.getMessage(), e);
        }
    }

    /**
     * 验证同步结果
     */
    public Map<String, Object> verifySyncResult(String syncId) {
        try {
            // 1. 获取同步任务
            SyncTask task = getTask(syncId);

            // 2. 执行一致性检查
            ConsistencyCheckResult checkResult = consistencyChecker.check(
                task.getSourceId(),
                task.getTargetId(),
                task.getVersion()
            );

            // 3. 更新验证状态
            updateVerificationStatus(task, checkResult);

            return buildVerificationResult(checkResult);

        } catch (Exception e) {
            log.error("Verify sync result failed, syncId: {}", syncId, e);
            throw new SyncException("Verify sync result failed: " + e.getMessage(), e);
        }
    }

    /**
     * 回滚同步
     */
    @Transactional
    public void revertSync(String syncId) {
        try {
            // 1. 获取同步任务
            SyncTask task = getTask(syncId);

            // 2. 验证是否可回滚
            validateRevertable(task);

            // 3. 执行回滚
            executeRevert(task);

        } catch (Exception e) {
            log.error("Revert sync failed, syncId: {}", syncId, e);
            throw new SyncException("Revert sync failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行同步
     */
    private void executeSync(SyncTask task) {
        // 1. 获取源数据
        List<Map<String, Object>> sourceData = getSourceData(
            task.getSourceId(),
            task.getVersion()
        );

        // 2. 计算增量数据
        List<Map<String, Object>> incrementalData = calculateIncrementalData(
            sourceData,
            task.getTargetId(),
            task.getVersion()
        );

        // 3. 同步数据
        syncData(task, incrementalData);
    }

    /**
     * 同步数据
     */
    private void syncData(SyncTask task, List<Map<String, Object>> data) {
        TransactionStatus tx = transactionManager.beginTransaction();
        try {
            // 1. 备份目标数据
            backupTargetData(task);

            // 2. 执行同步
            doSync(task, data);

            // 3. 提交事务
            transactionManager.commit(tx);

            // 4. 更新同步状态
            updateSyncSuccess(task);

        } catch (Exception e) {
            // 5. 回滚事务
            transactionManager.rollback(tx);
            updateSyncFailed(task, e);
            throw e;
        }
    }

    /**
     * 执行回滚
     */
    private void executeRevert(SyncTask task) {
        TransactionStatus tx = transactionManager.beginTransaction();
        try {
            // 1. 恢复备份数据
            restoreBackupData(task);

            // 2. 更新状态
            updateRevertStatus(task);

            // 3. 提交事务
            transactionManager.commit(tx);

        } catch (Exception e) {
            // 4. 回滚事务
            transactionManager.rollback(tx);
            handleRevertError(task, e);
            throw e;
        }
    }

    /**
     * 验证同步请求
     */
    private void validateSyncRequest(SyncRequest request) {
        if (request.getSourceId() == null) {
            throw new IllegalArgumentException("Source id is required");
        }
        if (request.getTimeout() != null && request.getTimeout() < 0) {
            throw new IllegalArgumentException("Invalid timeout value");
        }
    }

    /**
     * 获取同步任务
     */
    private SyncTask getTask(String syncId) {
        SyncTask task = syncRepository.findById(syncId);
        if (task == null) {
            throw new TaskNotFoundException("Sync task not found: " + syncId);
        }
        return task;
    }

    /**
     * 验证是否可回滚
     */
    private void validateRevertable(SyncTask task) {
        if (task.getStatus() != SyncStatus.COMPLETED && 
            task.getStatus() != SyncStatus.FAILED) {
            throw new IllegalStateException("Task is not revertable: " + task.getStatus());
        }
        if (!task.getHasBackup()) {
            throw new IllegalStateException("No backup data available");
        }
    }
}

```

接下来我们需要实现Infrastructure层吗？这一层包含了具体的基础设施实现，如MongoTemplate、RedisTemplate等。
好的，让我们开始实现Infrastructure层，先从MongoDB的实现开始。



```java
package com.platform.collect.infrastructure.persistent.mongo.template;

import com.platform.collect.domain.entity.task.TreeNode;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.mongodb.core.MongoTemplate;
import org.springframework.data.mongodb.core.query.Criteria;
import org.springframework.data.mongodb.core.query.Query;
import org.springframework.data.mongodb.core.query.Update;
import org.springframework.stereotype.Component;

/**
 * MongoDB树形数据操作模板
 */
@Slf4j
@Component
public class TreeTemplate {

    @Autowired
    private MongoTemplate mongoTemplate;

    /**
     * 保存节点
     */
    public void saveNode(TreeNode node) {
        try {
            // 1. 检查节点是否存在
            if (exists(node.getNodeId())) {
                // 更新节点
                Update update = new Update();
                update.set("attributes", node.getAttributes());
                update.set("hasChildren", node.getHasChildren());
                update.set("updateTime", new Date());
                
                mongoTemplate.updateFirst(
                    Query.query(Criteria.where("_id").is(node.getNodeId())),
                    update,
                    "tree_nodes"
                );
            } else {
                // 新增节点
                mongoTemplate.save(convertToDocument(node), "tree_nodes");
            }
        } catch (Exception e) {
            log.error("Save node failed, nodeId: {}", node.getNodeId(), e);
            throw new MongoOperationException("Save node failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量保存节点
     */
    public void saveNodes(List<TreeNode> nodes) {
        try {
            List<Document> documents = nodes.stream()
                .map(this::convertToDocument)
                .collect(Collectors.toList());
                
            mongoTemplate.insertAll(documents);
        } catch (Exception e) {
            log.error("Batch save nodes failed", e);
            throw new MongoOperationException("Batch save nodes failed: " + e.getMessage(), e);
        }
    }

    /**
     * 查询节点
     */
    public TreeNode findNode(String nodeId) {
        try {
            Document doc = mongoTemplate.findById(
                nodeId, 
                Document.class, 
                "tree_nodes"
            );
            return doc != null ? convertToNode(doc) : null;
        } catch (Exception e) {
            log.error("Find node failed, nodeId: {}", nodeId, e);
            throw new MongoOperationException("Find node failed: " + e.getMessage(), e);
        }
    }

    /**
     * 查询子节点
     */
    public List<TreeNode> findChildren(String parentId) {
        try {
            Query query = Query.query(
                Criteria.where("parentId").is(parentId)
            );
            
            List<Document> docs = mongoTemplate.find(
                query, 
                Document.class, 
                "tree_nodes"
            );
            
            return docs.stream()
                .map(this::convertToNode)
                .collect(Collectors.toList());
        } catch (Exception e) {
            log.error("Find children failed, parentId: {}", parentId, e);
            throw new MongoOperationException("Find children failed: " + e.getMessage(), e);
        }
    }

    /**
     * 分页查询子节点
     */
    public List<TreeNode> findChildrenByPage(String parentId, int pageNum, int pageSize) {
        try {
            Query query = Query.query(
                Criteria.where("parentId").is(parentId)
            );
            query.skip((pageNum - 1) * pageSize).limit(pageSize);
            
            List<Document> docs = mongoTemplate.find(
                query, 
                Document.class, 
                "tree_nodes"
            );
            
            return docs.stream()
                .map(this::convertToNode)
                .collect(Collectors.toList());
        } catch (Exception e) {
            log.error("Find children by page failed, parentId: {}", parentId, e);
            throw new MongoOperationException("Find children by page failed: " + e.getMessage(), e);
        }
    }

    /**
     * 查询节点路径
     */
    public List<TreeNode> findPath(String nodeId) {
        List<TreeNode> path = new ArrayList<>();
        try {
            TreeNode node = findNode(nodeId);
            while (node != null) {
                path.add(0, node);
                if (node.getParentId() != null) {
                    node = findNode(node.getParentId());
                } else {
                    break;
                }
            }
            return path;
        } catch (Exception e) {
            log.error("Find path failed, nodeId: {}", nodeId, e);
            throw new MongoOperationException("Find path failed: " + e.getMessage(), e);
        }
    }

    /**
     * 删除节点
     */
    public void deleteNode(String nodeId) {
        try {
            // 1. 删除当前节点
            mongoTemplate.remove(
                Query.query(Criteria.where("_id").is(nodeId)),
                "tree_nodes"
            );
            
            // 2. 删除子节点
            deleteChildren(nodeId);
        } catch (Exception e) {
            log.error("Delete node failed, nodeId: {}", nodeId, e);
            throw new MongoOperationException("Delete node failed: " + e.getMessage(), e);
        }
    }

    /**
     * 删除子节点
     */
    private void deleteChildren(String parentId) {
        mongoTemplate.remove(
            Query.query(Criteria.where("parentId").is(parentId)),
            "tree_nodes"
        );
    }

    /**
     * 移动节点
     */
    public void moveNode(String nodeId, String newParentId) {
        try {
            // 1. 验证移动操作
            validateMove(nodeId, newParentId);
            
            // 2. 更新父节点
            Update update = new Update().set("parentId", newParentId);
            mongoTemplate.updateFirst(
                Query.query(Criteria.where("_id").is(nodeId)),
                update,
                "tree_nodes"
            );
        } catch (Exception e) {
            log.error("Move node failed, nodeId: {}", nodeId, e);
            throw new MongoOperationException("Move node failed: " + e.getMessage(), e);
        }
    }

    /**
     * 检查节点是否存在
     */
    private boolean exists(String nodeId) {
        return mongoTemplate.exists(
            Query.query(Criteria.where("_id").is(nodeId)),
            "tree_nodes"
        );
    }

    /**
     * 验证移动操作
     */
    private void validateMove(String nodeId, String newParentId) {
        // 1. 检查新父节点是否存在
        if (!exists(newParentId)) {
            throw new IllegalArgumentException("New parent node not found: " + newParentId);
        }
        
        // 2. 检查是否移动到子节点
        if (isDescendant(nodeId, newParentId)) {
            throw new IllegalArgumentException("Cannot move node to its descendant");
        }
    }

    /**
     * 检查是否是后代节点
     */
    private boolean isDescendant(String ancestorId, String nodeId) {
        TreeNode node = findNode(nodeId);
        while (node != null && node.getParentId() != null) {
            if (node.getParentId().equals(ancestorId)) {
                return true;
            }
            node = findNode(node.getParentId());
        }
        return false;
    }

    /**
     * 转换为文档
     */
    private Document convertToDocument(TreeNode node) {
        Document doc = new Document();
        doc.put("_id", node.getNodeId());
        doc.put("parentId", node.getParentId());
        doc.put("level", node.getLevel());
        doc.put("hasChildren", node.getHasChildren());
        doc.put("attributes", node.getAttributes());
        doc.put("createTime", node.getCreateTime());
        doc.put("updateTime", new Date());
        return doc;
    }

    /**
     * 转换为节点
     */
    private TreeNode convertToNode(Document doc) {
        return TreeNode.builder()
            .nodeId(doc.getString("_id"))
            .parentId(doc.getString("parentId"))
            .level(doc.getInteger("level"))
            .hasChildren(doc.getBoolean("hasChildren"))
            .attributes((Map<String, Object>) doc.get("attributes"))
            .createTime(doc.getDate("createTime"))
            .build();
    }
}

```

接下来要实现ListTemplate - MongoDB列表数据操作模板吗？
好的，让我们实现ListTemplate - MongoDB列表数据操作模板。



```java
package com.platform.collect.infrastructure.persistent.mongo.template;

import com.platform.collect.domain.entity.data.ListData;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.domain.Sort;
import org.springframework.data.mongodb.core.MongoTemplate;
import org.springframework.data.mongodb.core.query.Criteria;
import org.springframework.data.mongodb.core.query.Query;
import org.springframework.data.mongodb.core.query.Update;
import org.springframework.stereotype.Component;

/**
 * MongoDB列表数据操作模板
 */
@Slf4j
@Component
public class ListTemplate {

    @Autowired
    private MongoTemplate mongoTemplate;

    private static final String COLLECTION_PREFIX = "list_data_";

    /**
     * 批量保存数据
     */
    public void saveBatch(String sourceId, List<Map<String, Object>> dataList) {
        try {
            // 1. 准备批量插入文档
            List<Document> documents = dataList.stream()
                .map(data -> convertToDocument(data, sourceId))
                .collect(Collectors.toList());

            // 2. 执行批量插入
            mongoTemplate.insertAll(documents);

            // 3. 更新统计信息
            updateStats(sourceId, documents.size());

        } catch (Exception e) {
            log.error("Batch save data failed, sourceId: {}", sourceId, e);
            throw new MongoOperationException("Batch save data failed: " + e.getMessage(), e);
        }
    }

    /**
     * 分页查询数据
     */
    public PageResult<Map<String, Object>> queryByPage(ListQueryRequest request) {
        try {
            // 1. 构建查询条件
            Query query = buildQuery(request);

            // 2. 查询总数
            long total = mongoTemplate.count(query, getCollectionName(request.getSourceId()));

            // 3. 执行分页查询
            query.skip((request.getPageNum() - 1) * request.getPageSize())
                 .limit(request.getPageSize());

            // 4. 添加排序
            if (request.getSortField() != null) {
                query.with(Sort.by(
                    request.getSortOrder() == SortOrder.DESC ? 
                        Sort.Direction.DESC : Sort.Direction.ASC,
                    request.getSortField()
                ));
            }

            List<Document> documents = mongoTemplate.find(
                query,
                Document.class,
                getCollectionName(request.getSourceId())
            );

            // 5. 转换结果
            List<Map<String, Object>> dataList = documents.stream()
                .map(this::convertToMap)
                .collect(Collectors.toList());

            return new PageResult<>(dataList, total, request.getPageNum(), request.getPageSize());

        } catch (Exception e) {
            log.error("Query data by page failed", e);
            throw new MongoOperationException("Query data by page failed: " + e.getMessage(), e);
        }
    }

    /**
     * 增量查询数据
     */
    public List<Map<String, Object>> queryIncremental(IncrementalQueryRequest request) {
        try {
            // 1. 构建增量查询条件
            Query query = buildIncrementalQuery(request);

            // 2. 执行查询
            return mongoTemplate.find(
                query,
                Document.class,
                getCollectionName(request.getSourceId())
            ).stream()
            .map(this::convertToMap)
            .collect(Collectors.toList());

        } catch (Exception e) {
            log.error("Query incremental data failed", e);
            throw new MongoOperationException("Query incremental data failed: " + e.getMessage(), e);
        }
    }

    /**
     * 聚合统计
     */
    public Map<String, Object> aggregate(AggregateRequest request) {
        try {
            // 1. 构建聚合管道
            List<AggregationOperation> operations = buildAggregationPipeline(request);

            // 2. 执行聚合查询
            AggregationResults<Document> results = mongoTemplate.aggregate(
                Aggregation.newAggregation(operations),
                getCollectionName(request.getSourceId()),
                Document.class
            );

            // 3. 处理结果
            return processAggregationResults(results);

        } catch (Exception e) {
            log.error("Aggregate data failed", e);
            throw new MongoOperationException("Aggregate data failed: " + e.getMessage(), e);
        }
    }

    /**
     * 构建查询条件
     */
    private Query buildQuery(ListQueryRequest request) {
        Criteria criteria = new Criteria();
        
        // 1. 添加基础条件
        if (request.getConditions() != null) {
            request.getConditions().forEach((field, value) -> {
                if (value instanceof Map) {
                    // 处理复杂查询条件
                    addComplexCondition(criteria, field, (Map<String, Object>) value);
                } else {
                    // 处理简单等值条件
                    criteria.and(field).is(value);
                }
            });
        }

        // 2. 添加时间范围
        if (request.getStartTime() != null) {
            criteria.and("createTime").gte(request.getStartTime());
        }
        if (request.getEndTime() != null) {
            criteria.and("createTime").lte(request.getEndTime());
        }

        return Query.query(criteria);
    }

    /**
     * 添加复杂查询条件
     */
    private void addComplexCondition(Criteria criteria, String field, Map<String, Object> condition) {
        condition.forEach((operator, value) -> {
            switch (operator.toLowerCase()) {
                case "$gt":
                    criteria.and(field).gt(value);
                    break;
                case "$gte":
                    criteria.and(field).gte(value);
                    break;
                case "$lt":
                    criteria.and(field).lt(value);
                    break;
                case "$lte":
                    criteria.and(field).lte(value);
                    break;
                case "$ne":
                    criteria.and(field).ne(value);
                    break;
                case "$in":
                    criteria.and(field).in((List<?>) value);
                    break;
                case "$nin":
                    criteria.and(field).nin((List<?>) value);
                    break;
                case "$regex":
                    criteria.and(field).regex(value.toString());
                    break;
                default:
                    log.warn("Unsupported operator: {}", operator);
            }
        });
    }

    /**
     * 构建增量查询条件
     */
    private Query buildIncrementalQuery(IncrementalQueryRequest request) {
        Criteria criteria = new Criteria();

        // 1. 添加版本条件
        if (request.getVersion() != null) {
            criteria.and("version").gt(request.getVersion());
        }

        // 2. 添加时间戳条件
        if (request.getTimestamp() != null) {
            criteria.and("updateTime").gt(new Date(request.getTimestamp()));
        }

        // 3. 添加其他条件
        if (request.getConditions() != null) {
            request.getConditions().forEach((field, value) -> 
                criteria.and(field).is(value)
            );
        }

        return Query.query(criteria);
    }

    /**
     * 更新统计信息
     */
    private void updateStats(String sourceId, int count) {
        Update update = new Update()
            .inc("totalCount", count)
            .set("lastUpdateTime", new Date());

        mongoTemplate.upsert(
            Query.query(Criteria.where("sourceId").is(sourceId)),
            update,
            "list_stats"
        );
    }

    /**
     * 获取集合名称
     */
    private String getCollectionName(String sourceId) {
        return COLLECTION_PREFIX + sourceId;
    }

    /**
     * 转换为文档
     */
    private Document convertToDocument(Map<String, Object> data, String sourceId) {
        Document doc = new Document(data);
        doc.put("sourceId", sourceId);
        doc.put("createTime", new Date());
        doc.put("updateTime", new Date());
        return doc;
    }

    /**
     * 转换为Map
     */
    private Map<String, Object> convertToMap(Document doc) {
        Map<String, Object> data = new HashMap<>(doc);
        data.remove("_id");
        data.remove("sourceId");
        return data;
    }
}

```

接下来要实现RedisTemplate - Redis数据操作模板吗？这个模板负责缓存的各种操作。
好的，让我们实现RedisTemplate - Redis数据操作模板。



```java
package com.platform.collect.infrastructure.persistent.redis.template;

import com.platform.collect.infrastructure.cache.CacheTemplate;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;

/**
 * Redis数据操作模板
 */
@Slf4j
@Component
public class CacheTemplate {

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    private static final String KEY_PREFIX = "collect:";
    private static final long DEFAULT_TIMEOUT = 24 * 60 * 60; // 默认24小时

    /**
     * 写入缓存
     */
    public void set(String key, Object value) {
        try {
            String cacheKey = buildKey(key);
            redisTemplate.opsForValue().set(cacheKey, value, DEFAULT_TIMEOUT, TimeUnit.SECONDS);
        } catch (Exception e) {
            log.error("Set cache failed, key: {}", key, e);
            throw new CacheException("Set cache failed: " + e.getMessage(), e);
        }
    }

    /**
     * 写入缓存并设置过期时间
     */
    public void set(String key, Object value, long timeout, TimeUnit unit) {
        try {
            String cacheKey = buildKey(key);
            redisTemplate.opsForValue().set(cacheKey, value, timeout, unit);
        } catch (Exception e) {
            log.error("Set cache with timeout failed, key: {}", key, e);
            throw new CacheException("Set cache failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取缓存
     */
    public <T> T get(String key) {
        try {
            String cacheKey = buildKey(key);
            return (T) redisTemplate.opsForValue().get(cacheKey);
        } catch (Exception e) {
            log.error("Get cache failed, key: {}", key, e);
            throw new CacheException("Get cache failed: " + e.getMessage(), e);
        }
    }

    /**
     * 删除缓存
     */
    public void delete(String key) {
        try {
            String cacheKey = buildKey(key);
            redisTemplate.delete(cacheKey);
        } catch (Exception e) {
            log.error("Delete cache failed, key: {}", key, e);
            throw new CacheException("Delete cache failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量删除缓存
     */
    public void deletePattern(String pattern) {
        try {
            String cachePattern = buildKey(pattern);
            Set<String> keys = redisTemplate.keys(cachePattern);
            if (!CollectionUtils.isEmpty(keys)) {
                redisTemplate.delete(keys);
            }
        } catch (Exception e) {
            log.error("Delete pattern cache failed, pattern: {}", pattern, e);
            throw new CacheException("Delete pattern cache failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取分布式锁
     */
    public boolean lock(String key, long timeout, TimeUnit unit) {
        try {
            String lockKey = buildLockKey(key);
            return redisTemplate.opsForValue()
                .setIfAbsent(lockKey, "1", timeout, unit);
        } catch (Exception e) {
            log.error("Get lock failed, key: {}", key, e);
            throw new CacheException("Get lock failed: " + e.getMessage(), e);
        }
    }

    /**
     * 释放分布式锁
     */
    public void unlock(String key) {
        try {
            String lockKey = buildLockKey(key);
            redisTemplate.delete(lockKey);
        } catch (Exception e) {
            log.error("Release lock failed, key: {}", key, e);
            throw new CacheException("Release lock failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量写入Hash
     */
    public void hMSet(String key, Map<String, Object> map) {
        try {
            String cacheKey = buildKey(key);
            redisTemplate.opsForHash().putAll(cacheKey, map);
            redisTemplate.expire(cacheKey, DEFAULT_TIMEOUT, TimeUnit.SECONDS);
        } catch (Exception e) {
            log.error("Batch set hash failed, key: {}", key, e);
            throw new CacheException("Batch set hash failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取Hash
     */
    public Map<String, Object> hGetAll(String key) {
        try {
            String cacheKey = buildKey(key);
            return redisTemplate.opsForHash().entries(cacheKey);
        } catch (Exception e) {
            log.error("Get hash failed, key: {}", key, e);
            throw new CacheException("Get hash failed: " + e.getMessage(), e);
        }
    }

    /**
     * 列表左侧插入
     */
    public void lPush(String key, Object value) {
        try {
            String cacheKey = buildKey(key);
            redisTemplate.opsForList().leftPush(cacheKey, value);
        } catch (Exception e) {
            log.error("Left push failed, key: {}", key, e);
            throw new CacheException("Left push failed: " + e.getMessage(), e);
        }
    }

    /**
     * 列表右侧弹出
     */
    public <T> T rPop(String key) {
        try {
            String cacheKey = buildKey(key);
            return (T) redisTemplate.opsForList().rightPop(cacheKey);
        } catch (Exception e) {
            log.error("Right pop failed, key: {}", key, e);
            throw new CacheException("Right pop failed: " + e.getMessage(), e);
        }
    }

    /**
     * 添加集合元素
     */
    public void sAdd(String key, Object... values) {
        try {
            String cacheKey = buildKey(key);
            redisTemplate.opsForSet().add(cacheKey, values);
        } catch (Exception e) {
            log.error("Add set failed, key: {}", key, e);
            throw new CacheException("Add set failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取集合所有元素
     */
    public <T> Set<T> sMembers(String key) {
        try {
            String cacheKey = buildKey(key);
            return (Set<T>) redisTemplate.opsForSet().members(cacheKey);
        } catch (Exception e) {
            log.error("Get set members failed, key: {}", key, e);
            throw new CacheException("Get set members failed: " + e.getMessage(), e);
        }
    }

    /**
     * 递增
     */
    public Long increment(String key, long delta) {
        try {
            String cacheKey = buildKey(key);
            return redisTemplate.opsForValue().increment(cacheKey, delta);
        } catch (Exception e) {
            log.error("Increment failed, key: {}", key, e);
            throw new CacheException("Increment failed: " + e.getMessage(), e);
        }
    }

    /**
     * 设置过期时间
     */
    public boolean expire(String key, long timeout, TimeUnit unit) {
        try {
            String cacheKey = buildKey(key);
            return redisTemplate.expire(cacheKey, timeout, unit);
        } catch (Exception e) {
            log.error("Set expire failed, key: {}", key, e);
            throw new CacheException("Set expire failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取过期时间
     */
    public long getExpire(String key) {
        try {
            String cacheKey = buildKey(key);
            return redisTemplate.getExpire(cacheKey);
        } catch (Exception e) {
            log.error("Get expire failed, key: {}", key, e);
            throw new CacheException("Get expire failed: " + e.getMessage(), e);
        }
    }

    /**
     * 构建缓存键
     */
    private String buildKey(String key) {
        return KEY_PREFIX + key;
    }

    /**
     * 构建锁键
     */
    private String buildLockKey(String key) {
        return KEY_PREFIX + "lock:" + key;
    }
}

```

接下来要实现RabbitMQ的消息生产者和消费者模板吗？这些模板负责消息的发送和接收处理。
好的，让我们先实现RabbitMQ的消息生产者模板。



```java
package com.platform.collect.infrastructure.mq.producer;

import com.platform.collect.infrastructure.mq.message.CollectMessage;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.amqp.rabbit.connection.CorrelationData;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * RabbitMQ消息生产者
 */
@Slf4j
@Component
public class MessageProducer {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    // 消息确认回调
    private final RabbitTemplate.ConfirmCallback confirmCallback = (correlationData, ack, cause) -> {
        if (!ack) {
            handleSendFailure(correlationData, cause);
        }
    };

    // 消息返回回调
    private final RabbitTemplate.ReturnCallback returnCallback = (message, replyCode, replyText, 
            exchange, routingKey) -> {
        handleMessageReturn(message, replyCode, replyText, exchange, routingKey);
    };

    /**
     * 初始化回调设置
     */
    @PostConstruct
    public void init() {
        rabbitTemplate.setConfirmCallback(confirmCallback);
        rabbitTemplate.setReturnCallback(returnCallback);
    }

    /**
     * 发送任务消息
     */
    public void sendTaskMessage(CollectMessage message) {
        try {
            // 1. 构建相关数据
            CorrelationData correlationData = new CorrelationData(message.getMessageId());
            correlationData.getFuture().addCallback(
                success -> handleSendSuccess(message, success),
                failure -> handleSendError(message, failure)
            );

            // 2. 发送消息
            rabbitTemplate.convertAndSend(
                message.getExchange(),
                message.getRoutingKey(),
                message,
                correlationData
            );

            // 3. 记录发送日志
            logMessageSend(message);

        } catch (Exception e) {
            log.error("Send task message failed", e);
            throw new MessageSendException("Send message failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量发送消息
     */
    public void sendBatchMessages(List<CollectMessage> messages) {
        try {
            for (CollectMessage message : messages) {
                sendTaskMessage(message);
            }
        } catch (Exception e) {
            log.error("Send batch messages failed", e);
            throw new MessageSendException("Send batch messages failed: " + e.getMessage(), e);
        }
    }

    /**
     * 发送延迟消息
     */
    public void sendDelayMessage(CollectMessage message, long delayMillis) {
        try {
            message.setDelay(delayMillis);
            rabbitTemplate.convertAndSend(
                message.getExchange(),
                message.getRoutingKey(),
                message,
                msg -> {
                    msg.getMessageProperties().setDelay((int) delayMillis);
                    return msg;
                }
            );
        } catch (Exception e) {
            log.error("Send delay message failed", e);
            throw new MessageSendException("Send delay message failed: " + e.getMessage(), e);
        }
    }

    /**
     * 处理发送成功
     */
    private void handleSendSuccess(CollectMessage message, CorrelationData.Confirm result) {
        if (result.isAck()) {
            log.info("Message sent successfully: {}", message.getMessageId());
        } else {
            log.warn("Message not confirmed: {}, cause: {}", 
                message.getMessageId(), result.getReason());
            handleMessageRetry(message);
        }
    }

    /**
     * 处理发送错误
     */
    private void handleSendError(CollectMessage message, Throwable failure) {
        log.error("Message send failed: {}", message.getMessageId(), failure);
        handleMessageRetry(message);
    }

    /**
     * 处理消息返回
     */
    private void handleMessageReturn(Message returnedMessage, int replyCode, 
            String replyText, String exchange, String routingKey) {
        log.warn("Message returned: exchange={}, routingKey={}, replyCode={}, replyText={}", 
            exchange, routingKey, replyCode, replyText);
        
        try {
            CollectMessage message = (CollectMessage) rabbitTemplate.getMessageConverter()
                .fromMessage(returnedMessage);
            handleMessageRetry(message);
        } catch (Exception e) {
            log.error("Handle returned message failed", e);
        }
    }

    /**
     * 处理消息重试
     */
    private void handleMessageRetry(CollectMessage message) {
        // 检查重试次数
        if (message.getRetryCount() >= message.getMaxRetries()) {
            handleMaxRetriesExceeded(message);
            return;
        }

        // 增加重试次数
        message.setRetryCount(message.getRetryCount() + 1);

        // 计算延迟时间
        long delayMillis = calculateRetryDelay(message);

        try {
            // 发送延迟消息
            sendDelayMessage(message, delayMillis);
        } catch (Exception e) {
            log.error("Retry message failed", e);
            handleMaxRetriesExceeded(message);
        }
    }

    /**
     * 计算重试延迟
     */
    private long calculateRetryDelay(CollectMessage message) {
        // 指数退避策略
        return 1000L * (long) Math.pow(2, message.getRetryCount() - 1);
    }

    /**
     * 处理超过最大重试次数
     */
    private void handleMaxRetriesExceeded(CollectMessage message) {
        log.error("Message retry count exceeded: {}", message.getMessageId());
        // 发送到死信队列
        rabbitTemplate.convertAndSend(
            "collect.dlx",
            "collect.dlq",
            message
        );
    }

    /**
     * 记录消息发送日志
     */
    private void logMessageSend(CollectMessage message) {
        MessageLog messageLog = MessageLog.builder()
            .messageId(message.getMessageId())
            .exchange(message.getExchange())
            .routingKey(message.getRoutingKey())
            .messageType(message.getMessageType())
            .sendTime(new Date())
            .build();
        
        // 异步保存日志
        CompletableFuture.runAsync(() -> {
            try {
                messageLogService.saveLog(messageLog);
            } catch (Exception e) {
                log.error("Save message log failed", e);
            }
        });
    }
}

```

接下来要实现RabbitMQ的消息消费者模板吗？这个模板负责消息的接收和处理。
好的，让我们实现RabbitMQ的消息消费者模板。



```java
package com.platform.collect.infrastructure.mq.consumer;

import com.platform.collect.infrastructure.mq.message.CollectMessage;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * RabbitMQ消息消费者
 */
@Slf4j
@Component
public class MessageConsumer {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Autowired
    private TaskExecutor taskExecutor;

    @Autowired
    private MessageProcessor messageProcessor;

    /**
     * 处理采集任务消息
     */
    @RabbitListener(
        queues = "${rabbitmq.queue.collect-task}",
        containerFactory = "collectTaskListenerFactory"
    )
    public void handleCollectTask(CollectMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive collect task message: {}", messageId);

        try {
            // 1. 消息预处理
            preprocessMessage(message);

            // 2. 异步处理消息
            taskExecutor.submit(() -> processMessage(message));

        } catch (Exception e) {
            log.error("Handle collect task message failed: {}", messageId, e);
            handleProcessError(message, e);
        }
    }

    /**
     * 处理结果回调消息
     */
    @RabbitListener(
        queues = "${rabbitmq.queue.collect-result}",
        containerFactory = "collectResultListenerFactory"
    )
    public void handleCollectResult(CollectMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive collect result message: {}", messageId);

        try {
            // 1. 验证结果消息
            validateResultMessage(message);

            // 2. 处理结果
            processCollectResult(message);

        } catch (Exception e) {
            log.error("Handle collect result message failed: {}", messageId, e);
            handleProcessError(message, e);
        }
    }

    /**
     * 消息预处理
     */
    private void preprocessMessage(CollectMessage message) {
        // 1. 检查消息有效性
        if (!isValidMessage(message)) {
            throw new InvalidMessageException("Invalid message: " + message.getMessageId());
        }

        // 2. 检查消息重复性
        if (isDuplicateMessage(message)) {
            throw new DuplicateMessageException("Duplicate message: " + message.getMessageId());
        }

        // 3. 记录消息接收
        logMessageReceive(message);
    }

    /**
     * 处理消息
     */
    private void processMessage(CollectMessage message) {
        try {
            // 1. 设置处理上下文
            MessageContext context = buildMessageContext(message);

            // 2. 执行处理
            messageProcessor.process(context);

            // 3. 发送处理结果
            sendProcessResult(message, context.getResult());

        } catch (Exception e) {
            log.error("Process message failed: {}", message.getMessageId(), e);
            handleProcessError(message, e);
        }
    }

    /**
     * 处理采集结果
     */
    private void processCollectResult(CollectMessage message) {
        try {
            // 1. 解析结果数据
            CollectResult result = parseCollectResult(message);

            // 2. 更新任务状态
            updateTaskStatus(message.getTaskId(), result);

            // 3. 发送通知
            sendResultNotification(message.getTaskId(), result);

        } catch (Exception e) {
            log.error("Process collect result failed: {}", message.getMessageId(), e);
            handleResultError(message, e);
        }
    }

    /**
     * 发送处理结果
     */
    private void sendProcessResult(CollectMessage message, ProcessResult result) {
        try {
            // 1. 构建结果消息
            CollectMessage resultMessage = buildResultMessage(message, result);

            // 2. 发送结果
            rabbitTemplate.convertAndSend(
                resultMessage.getExchange(),
                resultMessage.getRoutingKey(),
                resultMessage
            );

        } catch (Exception e) {
            log.error("Send process result failed: {}", message.getMessageId(), e);
        }
    }

    /**
     * 处理错误
     */
    private void handleProcessError(CollectMessage message, Exception e) {
        try {
            // 1. 记录错误日志
            logProcessError(message, e);

            // 2. 发送错误通知
            sendErrorNotification(message, e);

            // 3. 检查重试
            if (shouldRetry(message, e)) {
                handleMessageRetry(message);
            } else {
                handleProcessFailure(message, e);
            }

        } catch (Exception ex) {
            log.error("Handle process error failed", ex);
        }
    }

    /**
     * 检查是否需要重试
     */
    private boolean shouldRetry(CollectMessage message, Exception e) {
        // 1. 检查重试次数
        if (message.getRetryCount() >= message.getMaxRetries()) {
            return false;
        }

        // 2. 检查异常类型
        if (e instanceof NonRetryableException) {
            return false;
        }

        return true;
    }

    /**
     * 处理消息重试
     */
    private void handleMessageRetry(CollectMessage message) {
        // 1. 增加重试次数
        message.setRetryCount(message.getRetryCount() + 1);

        // 2. 计算延迟时间
        long delayMillis = calculateRetryDelay(message);

        try {
            // 3. 发送延迟消息
            rabbitTemplate.convertAndSend(
                message.getExchange(),
                message.getRoutingKey(),
                message,
                msg -> {
                    msg.getMessageProperties().setDelay((int) delayMillis);
                    return msg;
                }
            );
        } catch (Exception e) {
            log.error("Retry message failed", e);
            handleProcessFailure(message, e);
        }
    }

    /**
     * 处理最终失败
     */
    private void handleProcessFailure(CollectMessage message, Exception e) {
        // 1. 更新任务状态
        updateTaskStatus(message.getTaskId(), TaskStatus.FAILED);

        // 2. 发送失败通知
        sendFailureNotification(message, e);

        // 3. 发送到死信队列
        sendToDLQ(message);
    }

    /**
     * 记录消息接收日志
     */
    private void logMessageReceive(CollectMessage message) {
        MessageLog messageLog = MessageLog.builder()
            .messageId(message.getMessageId())
            .messageType(message.getMessageType())
            .receiveTime(new Date())
            .build();

        // 异步保存日志
        CompletableFuture.runAsync(() -> {
            try {
                messageLogService.saveLog(messageLog);
            } catch (Exception e) {
                log.error("Save message log failed", e);
            }
        });
    }
}

```

接下来要实现Infrastructure层的监控相关组件吗？比如MetricsCollector(指标采集器)和AlertNotifier(告警通知器)。
好的，让我们先实现MetricsCollector - 指标采集器。



```java
package com.platform.collect.infrastructure.monitor.metrics;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

/**
 * 指标采集器
 */
@Slf4j
@Component
public class MetricsCollector {

    @Autowired
    private TimeSeriesDB timeSeriesDB;

    @Autowired
    private MetricsRepository metricsRepository;

    // 实时指标缓存
    private final Map<String, AtomicLong> counters = new ConcurrentHashMap<>();
    private final Map<String, Histogram> histograms = new ConcurrentHashMap<>();
    private final Map<String, Timer> timers = new ConcurrentHashMap<>();

    /**
     * 记录计数指标
     */
    public void incrementCounter(String name, long delta) {
        try {
            counters.computeIfAbsent(name, k -> new AtomicLong())
                   .addAndGet(delta);
        } catch (Exception e) {
            log.error("Increment counter failed: {}", name, e);
        }
    }

    /**
     * 记录统计指标
     */
    public void recordValue(String name, double value) {
        try {
            histograms.computeIfAbsent(name, k -> new Histogram())
                     .update(value);
        } catch (Exception e) {
            log.error("Record value failed: {}", name, e);
        }
    }

    /**
     * 记录时间指标
     */
    public void recordTime(String name, long timeInMs) {
        try {
            timers.computeIfAbsent(name, k -> new Timer())
                  .update(timeInMs);
        } catch (Exception e) {
            log.error("Record time failed: {}", name, e);
        }
    }

    /**
     * 记录任务指标
     */
    public void recordTaskMetrics(TaskMetrics metrics) {
        try {
            // 记录任务计数
            incrementCounter("task.total", 1);
            incrementCounter("task." + metrics.getStatus().name().toLowerCase(), 1);

            // 记录处理时间
            recordTime("task.process.time", metrics.getProcessTime());

            // 记录数据量
            recordValue("task.data.size", metrics.getDataSize());

            // 保存详细指标
            saveTaskMetrics(metrics);

        } catch (Exception e) {
            log.error("Record task metrics failed", e);
        }
    }

    /**
     * 记录系统指标
     */
    @Scheduled(fixedRate = 60000) // 每分钟
    public void collectSystemMetrics() {
        try {
            // 1. 采集JVM指标
            collectJvmMetrics();

            // 2. 采集系统指标
            collectOsMetrics();

            // 3. 采集业务指标
            collectBusinessMetrics();

        } catch (Exception e) {
            log.error("Collect system metrics failed", e);
        }
    }

    /**
     * 采集JVM指标
     */
    private void collectJvmMetrics() {
        // 内存使用
        recordValue("jvm.memory.used", getUsedMemory());
        recordValue("jvm.memory.total", getTotalMemory());

        // GC统计
        Map<String, Long> gcStats = getGcStats();
        gcStats.forEach((name, value) -> 
            recordValue("jvm.gc." + name, value));

        // 线程统计
        recordValue("jvm.threads.count", getThreadCount());
        recordValue("jvm.threads.peak", getPeakThreadCount());
    }

    /**
     * 采集系统指标
     */
    private void collectOsMetrics() {
        // CPU使用率
        recordValue("system.cpu.usage", getCpuUsage());

        // 内存使用
        recordValue("system.memory.used", getSystemMemoryUsed());
        recordValue("system.memory.total", getSystemMemoryTotal());

        // 磁盘使用
        recordValue("system.disk.used", getDiskUsed());
        recordValue("system.disk.total", getDiskTotal());
    }

    /**
     * 采集业务指标
     */
    private void collectBusinessMetrics() {
        // 处理中的任务数
        recordValue("business.tasks.running", getRunningTaskCount());

        // 队列积压数
        recordValue("business.queue.size", getQueueSize());

        // 处理速率
        recordValue("business.process.rate", getProcessRate());
    }

    /**
     * 定期保存指标数据
     */
    @Scheduled(fixedRate = 10000) // 每10秒
    public void persistMetrics() {
        try {
            // 1. 保存计数器数据
            saveCounters();

            // 2. 保存直方图数据
            saveHistograms();

            // 3. 保存定时器数据
            saveTimers();

            // 4. 清理缓存数据
            resetMetrics();

        } catch (Exception e) {
            log.error("Persist metrics failed", e);
        }
    }

    /**
     * 保存计数器数据
     */
    private void saveCounters() {
        long timestamp = System.currentTimeMillis();
        counters.forEach((name, counter) -> {
            long value = counter.get();
            if (value > 0) {
                timeSeriesDB.record(MetricPoint.builder()
                    .name(name)
                    .value(value)
                    .timestamp(timestamp)
                    .build());
            }
        });
    }

    /**
     * 保存直方图数据
     */
    private void saveHistograms() {
        long timestamp = System.currentTimeMillis();
        histograms.forEach((name, histogram) -> {
            HistogramSnapshot snapshot = histogram.snapshot();
            timeSeriesDB.record(Arrays.asList(
                MetricPoint.builder()
                    .name(name + ".avg")
                    .value(snapshot.getMean())
                    .timestamp(timestamp)
                    .build(),
                MetricPoint.builder()
                    .name(name + ".max")
                    .value(snapshot.getMax())
                    .timestamp(timestamp)
                    .build(),
                MetricPoint.builder()
                    .name(name + ".min")
                    .value(snapshot.getMin())
                    .timestamp(timestamp)
                    .build(),
                MetricPoint.builder()
                    .name(name + ".p95")
                    .value(snapshot.get95thPercentile())
                    .timestamp(timestamp)
                    .build()
            ));
        });
    }

    /**
     * 保存定时器数据
     */
    private void saveTimers() {
        long timestamp = System.currentTimeMillis();
        timers.forEach((name, timer) -> {
            TimerSnapshot snapshot = timer.snapshot();
            timeSeriesDB.record(Arrays.asList(
                MetricPoint.builder()
                    .name(name + ".count")
                    .value(snapshot.getCount())
                    .timestamp(timestamp)
                    .build(),
                MetricPoint.builder()
                    .name(name + ".avg")
                    .value(snapshot.getMean())
                    .timestamp(timestamp)
                    .build(),
                MetricPoint.builder()
                    .name(name + ".max")
                    .value(snapshot.getMax())
                    .timestamp(timestamp)
                    .build()
            ));
        });
    }

    /**
     * 重置指标数据
     */
    private void resetMetrics() {
        counters.clear();
        histograms.clear();
        timers.clear();
    }
}

```

接下来要实现AlertNotifier - 告警通知器吗？这个组件负责告警信息的分发和通知。
好的，让我们实现AlertNotifier - 告警通知器。



```java
package com.platform.collect.infrastructure.monitor.alert;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 告警通知器
 */
@Slf4j
@Component
public class AlertNotifier {

    @Autowired
    private AlertRepository alertRepository;

    @Autowired
    private NotifierFactory notifierFactory;

    @Autowired
    private TemplateEngine templateEngine;

    @Autowired
    private RetryTemplate retryTemplate;

    /**
     * 发送告警
     */
    public void sendAlert(Alert alert) {
        try {
            // 1. 保存告警记录
            alertRepository.save(alert);

            // 2. 获取通知配置
            NotifyConfig config = getNotifyConfig(alert);

            // 3. 执行通知
            executeNotification(alert, config);

        } catch (Exception e) {
            log.error("Send alert failed: {}", alert.getAlertId(), e);
            handleAlertError(alert, e);
        }
    }

    /**
     * 执行通知
     */
    private void executeNotification(Alert alert, NotifyConfig config) {
        // 1. 获取通知通道
        List<String> channels = getNotifyChannels(alert, config);

        // 2. 并行发送通知
        CompletableFuture.allOf(
            channels.stream()
                .map(channel -> sendNotification(alert, channel))
                .toArray(CompletableFuture[]::new)
        ).join();

        // 3. 更新通知状态
        updateAlertStatus(alert);
    }

    /**
     * 发送单个通知
     */
    private CompletableFuture<Void> sendNotification(Alert alert, String channel) {
        return CompletableFuture.runAsync(() -> {
            try {
                // 1. 获取通知器
                Notifier notifier = notifierFactory.getNotifier(channel);

                // 2. 准备通知内容
                NotifyContent content = prepareNotifyContent(alert, channel);

                // 3. 执行通知(带重试)
                retryTemplate.execute(context -> {
                    notifier.notify(content);
                    return null;
                });

                // 4. 记录通知记录
                recordNotification(alert, channel, true, null);

            } catch (Exception e) {
                log.error("Send notification failed, channel: {}", channel, e);
                recordNotification(alert, channel, false, e.getMessage());
                throw e;
            }
        });
    }

    /**
     * 准备通知内容
     */
    private NotifyContent prepareNotifyContent(Alert alert, String channel) {
        // 1. 获取模板
        Template template = templateEngine.getTemplate(channel, alert.getAlertType());

        // 2. 构建模板上下文
        Map<String, Object> context = buildTemplateContext(alert);

        // 3. 渲染内容
        String content = templateEngine.process(template, context);

        return NotifyContent.builder()
            .alertId(alert.getAlertId())
            .channel(channel)
            .title(buildAlertTitle(alert))
            .content(content)
            .targets(getNotifyTargets(alert, channel))
            .build();
    }

    /**
     * 获取通知通道
     */
    private List<String> getNotifyChannels(Alert alert, NotifyConfig config) {
        // 1. 获取告警级别配置的通道
        List<String> channels = config.getChannelsByLevel(alert.getLevel());

        // 2. 检查通道可用性
        return channels.stream()
            .filter(channel -> isChannelAvailable(channel))
            .collect(Collectors.toList());
    }

    /**
     * 获取通知目标
     */
    private List<String> getNotifyTargets(Alert alert, String channel) {
        try {
            // 1. 获取默认通知组
            List<String> targets = getDefaultTargets(channel);

            // 2. 获取告警相关的通知组
            List<String> alertTargets = getAlertTargets(alert, channel);
            if (!CollectionUtils.isEmpty(alertTargets)) {
                targets.addAll(alertTargets);
            }

            // 3. 去重
            return targets.stream().distinct().collect(Collectors.toList());

        } catch (Exception e) {
            log.error("Get notify targets failed", e);
            return Collections.emptyList();
        }
    }

    /**
     * 记录通知记录
     */
    private void recordNotification(Alert alert, String channel, boolean success, String error) {
        NotifyRecord record = NotifyRecord.builder()
            .alertId(alert.getAlertId())
            .channel(channel)
            .success(success)
            .error(error)
            .notifyTime(new Date())
            .build();
            
        alertRepository.saveNotifyRecord(record);
    }

    /**
     * 构建告警标题
     */
    private String buildAlertTitle(Alert alert) {
        StringBuilder title = new StringBuilder();
        
        // 1. 添加告警级别
        title.append("[").append(alert.getLevel()).append("]");
        
        // 2. 添加告警类型
        title.append("[").append(alert.getAlertType()).append("]");
        
        // 3. 添加告警源
        if (alert.getSource() != null) {
            title.append("[").append(alert.getSource()).append("]");
        }
        
        // 4. 添加告警描述
        title.append(" ").append(alert.getDescription());
        
        return title.toString();
    }

    /**
     * 更新告警状态
     */
    private void updateAlertStatus(Alert alert) {
        try {
            // 1. 更新通知时间
            alert.setNotifyTime(new Date());
            
            // 2. 更新状态
            alert.setStatus(AlertStatus.NOTIFIED);
            
            // 3. 保存更新
            alertRepository.update(alert);
            
        } catch (Exception e) {
            log.error("Update alert status failed", e);
        }
    }

    /**
     * 处理告警错误
     */
    private void handleAlertError(Alert alert, Exception e) {
        try {
            // 1. 更新告警状态
            alert.setStatus(AlertStatus.FAILED);
            alert.setError(e.getMessage());
            alertRepository.update(alert);
            
            // 2. 记录错误日志
            AlertError error = AlertError.builder()
                .alertId(alert.getAlertId())
                .errorType(e.getClass().getSimpleName())
                .errorMsg(e.getMessage())
                .timestamp(new Date())
                .build();
            alertRepository.saveAlertError(error);
            
        } catch (Exception ex) {
            log.error("Handle alert error failed", ex);
        }
    }
}

```

接下来要实现Infrastructure层的分布式锁组件吗？包括RedisLock (Redis分布式锁)和ZkLock (ZooKeeper分布式锁)。
好的，让我们先实现RedisLock - Redis分布式锁实现。



```java
package com.platform.collect.infrastructure.lock.impl;

import com.platform.collect.infrastructure.lock.DistributedLock;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;

/**
 * Redis分布式锁实现
 */
@Slf4j
@Component
public class RedisLock implements DistributedLock {

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    private static final String LOCK_PREFIX = "lock:";
    private static final long DEFAULT_EXPIRE = 30000; // 默认30秒
    private static final long WATCH_DOG_TIMEOUT = 10000; // 看门狗超时时间10秒

    // 看门狗线程池
    private final ScheduledExecutorService watchDogExecutor = Executors.newScheduledThreadPool(1);
    
    // 当前持有的锁
    private final Map<String, LockContext> currentLocks = new ConcurrentHashMap<>();

    @Override
    public boolean tryLock(String lockKey, long timeout, TimeUnit unit) {
        String key = buildLockKey(lockKey);
        String value = buildLockValue();
        long timeoutMillis = unit.toMillis(timeout);
        
        try {
            long startTime = System.currentTimeMillis();
            
            // 循环尝试获取锁
            while (System.currentTimeMillis() - startTime < timeoutMillis) {
                if (obtainLock(key, value, DEFAULT_EXPIRE)) {
                    // 记录锁信息
                    recordLock(key, value);
                    // 启动看门狗
                    startWatchDog(key, value);
                    return true;
                }
                Thread.sleep(100);
            }
            
            return false;
            
        } catch (Exception e) {
            log.error("Try lock failed: {}", key, e);
            return false;
        }
    }

    @Override
    public void unlock(String lockKey) {
        String key = buildLockKey(lockKey);
        try {
            // 1. 获取锁信息
            LockContext context = currentLocks.get(key);
            if (context == null) {
                return;
            }

            // 2. 验证锁的持有者
            String currentValue = (String) redisTemplate.opsForValue().get(key);
            if (!context.getValue().equals(currentValue)) {
                log.warn("Lock already expired or been released: {}", key);
                return;
            }

            // 3. 删除锁
            redisTemplate.delete(key);
            
            // 4. 清理锁信息
            cleanupLock(key);
            
        } catch (Exception e) {
            log.error("Unlock failed: {}", key, e);
            throw new LockException("Unlock failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取锁
     */
    private boolean obtainLock(String key, String value, long expireTime) {
        String script = 
            "if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then" +
            "   redis.call('pexpire', KEYS[1], ARGV[2])" +
            "   return 1" +
            "else" +
            "   return 0" +
            "end";

        try {
            DefaultRedisScript<Long> redisScript = new DefaultRedisScript<>();
            redisScript.setScriptText(script);
            redisScript.setResultType(Long.class);

            Long result = redisTemplate.execute(
                redisScript,
                Collections.singletonList(key),
                value,
                String.valueOf(expireTime)
            );

            return result != null && result == 1;
            
        } catch (Exception e) {
            log.error("Execute lock script failed", e);
            return false;
        }
    }

    /**
     * 续期锁
     */
    private boolean renewLock(String key, String value, long expireTime) {
        String script = 
            "if redis.call('get', KEYS[1]) == ARGV[1] then" +
            "   redis.call('pexpire', KEYS[1], ARGV[2])" +
            "   return 1" +
            "else" +
            "   return 0" +
            "end";

        try {
            DefaultRedisScript<Long> redisScript = new DefaultRedisScript<>();
            redisScript.setScriptText(script);
            redisScript.setResultType(Long.class);

            Long result = redisTemplate.execute(
                redisScript,
                Collections.singletonList(key),
                value,
                String.valueOf(expireTime)
            );

            return result != null && result == 1;
            
        } catch (Exception e) {
            log.error("Execute renew script failed", e);
            return false;
        }
    }

    /**
     * 启动看门狗
     */
    private void startWatchDog(String key, String value) {
        LockContext context = currentLocks.get(key);
        if (context == null) {
            return;
        }

        // 创建续期任务
        ScheduledFuture<?> watchDog = watchDogExecutor.scheduleAtFixedRate(() -> {
            try {
                if (!renewLock(key, value, DEFAULT_EXPIRE)) {
                    log.warn("Renew lock failed, lock may be expired: {}", key);
                    cleanupLock(key);
                }
            } catch (Exception e) {
                log.error("Watch dog error", e);
            }
        }, WATCH_DOG_TIMEOUT / 3, WATCH_DOG_TIMEOUT / 3, TimeUnit.MILLISECONDS);
        
        context.setWatchDog(watchDog);
    }

    /**
     * 记录锁信息
     */
    private void recordLock(String key, String value) {
        LockContext context = LockContext.builder()
            .key(key)
            .value(value)
            .threadId(Thread.currentThread().getId())
            .startTime(System.currentTimeMillis())
            .build();
            
        currentLocks.put(key, context);
    }

    /**
     * 清理锁信息
     */
    private void cleanupLock(String key) {
        LockContext context = currentLocks.remove(key);
        if (context != null && context.getWatchDog() != null) {
            context.getWatchDog().cancel(false);
        }
    }

    /**
     * 构建锁的key
     */
    private String buildLockKey(String key) {
        return LOCK_PREFIX + key;
    }

    /**
     * 构建锁的值
     */
    private String buildLockValue() {
        return UUID.randomUUID().toString();
    }

    @PreDestroy
    public void destroy() {
        watchDogExecutor.shutdown();
        try {
            if (!watchDogExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                watchDogExecutor.shutdownNow();
            }
        } catch (InterruptedException e) {
            watchDogExecutor.shutdownNow();
            Thread.currentThread().interrupt();
        }
    }

    /**
     * 锁上下文
     */
    @Data
    @Builder
    private static class LockContext {
        private String key;
        private String value;
        private long threadId;
        private long startTime;
        private ScheduledFuture<?> watchDog;
    }
}

```

接下来要实现ZkLock - ZooKeeper分布式锁实现吗？
好的，让我们实现ZkLock - ZooKeeper分布式锁实现。



```java
package com.platform.collect.infrastructure.lock.impl;

import com.platform.collect.infrastructure.lock.DistributedLock;
import lombok.extern.slf4j.Slf4j;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * ZooKeeper分布式锁实现
 */
@Slf4j
@Component
public class ZkLock implements DistributedLock {

    @Autowired
    private CuratorFramework curatorFramework;

    private static final String LOCK_PATH = "/locks/";
    
    // 当前持有的锁
    private final Map<String, LockContext> currentLocks = new ConcurrentHashMap<>();

    @Override
    public boolean tryLock(String lockKey, long timeout, TimeUnit unit) {
        String path = buildLockPath(lockKey);
        InterProcessMutex mutex = new InterProcessMutex(curatorFramework, path);
        
        try {
            // 1. 尝试获取锁
            if (mutex.acquire(timeout, unit)) {
                // 2. 记录锁信息
                recordLock(lockKey, mutex);
                return true;
            }
            return false;
            
        } catch (Exception e) {
            log.error("Try lock failed: {}", path, e);
            return false;
        }
    }

    @Override
    public void unlock(String lockKey) {
        try {
            // 1. 获取锁信息
            LockContext context = currentLocks.get(lockKey);
            if (context == null) {
                return;
            }

            // 2. 释放锁
            context.getMutex().release();
            
            // 3. 清理锁信息
            cleanupLock(lockKey);
            
        } catch (Exception e) {
            log.error("Unlock failed: {}", lockKey, e);
            throw new LockException("Unlock failed: " + e.getMessage(), e);
        }
    }

    /**
     * 记录锁信息
     */
    private void recordLock(String lockKey, InterProcessMutex mutex) {
        LockContext context = LockContext.builder()
            .lockKey(lockKey)
            .mutex(mutex)
            .threadId(Thread.currentThread().getId())
            .startTime(System.currentTimeMillis())
            .build();
            
        currentLocks.put(lockKey, context);
    }

    /**
     * 清理锁信息
     */
    private void cleanupLock(String lockKey) {
        currentLocks.remove(lockKey);
    }

    /**
     * 构建锁路径
     */
    private String buildLockPath(String lockKey) {
        return LOCK_PATH + lockKey;
    }

    /**
     * 检查路径是否存在
     */
    private void ensurePath(String path) throws Exception {
        try {
            if (curatorFramework.checkExists().forPath(path) == null) {
                curatorFramework.create()
                    .creatingParentsIfNeeded()
                    .forPath(path);
            }
        } catch (Exception e) {
            log.error("Ensure path failed: {}", path, e);
            throw e;
        }
    }

    @PreDestroy
    public void destroy() {
        // 释放所有锁
        currentLocks.forEach((key, context) -> {
            try {
                context.getMutex().release();
            } catch (Exception e) {
                log.error("Release lock failed on destroy: {}", key, e);
            }
        });
        currentLocks.clear();
    }

    /**
     * 锁上下文
     */
    @Data
    @Builder
    private static class LockContext {
        private String lockKey;
        private InterProcessMutex mutex;
        private long threadId;
        private long startTime;
    }

    /**
     * 初始化
     */
    @PostConstruct
    public void init() {
        try {
            // 确保锁根路径存在
            ensurePath(LOCK_PATH);
            
            log.info("ZkLock initialized successfully");
        } catch (Exception e) {
            log.error("Initialize ZkLock failed", e);
            throw new LockException("Initialize ZkLock failed: " + e.getMessage(), e);
        }
    }

    /**
     * 监控锁的状态
     */
    @Scheduled(fixedRate = 60000) // 每分钟
    public void monitorLocks() {
        try {
            long now = System.currentTimeMillis();
            
            // 检查长时间持有的锁
            currentLocks.forEach((key, context) -> {
                long holdTime = now - context.getStartTime();
                if (holdTime > 300000) { // 持有超过5分钟
                    log.warn("Lock held for too long: {}, holdTime: {}ms", key, holdTime);
                }
            });
            
        } catch (Exception e) {
            log.error("Monitor locks failed", e);
        }
    }

    /**
     * 获取锁持有信息
     */
    public List<LockInfo> getLockInfo() {
        return currentLocks.entrySet().stream()
            .map(entry -> LockInfo.builder()
                .lockKey(entry.getKey())
                .threadId(entry.getValue().getThreadId())
                .holdTime(System.currentTimeMillis() - entry.getValue().getStartTime())
                .build())
            .collect(Collectors.toList());
    }

    /**
     * 锁信息
     */
    @Data
    @Builder
    public static class LockInfo {
        private String lockKey;
        private long threadId;
        private long holdTime;
    }

    /**
     * 强制释放锁
     */
    public void forceUnlock(String lockKey) {
        try {
            String path = buildLockPath(lockKey);
            
            // 检查节点是否存在
            if (curatorFramework.checkExists().forPath(path) != null) {
                // 删除锁节点
                curatorFramework.delete().forPath(path);
                log.warn("Force unlocked: {}", lockKey);
            }
            
            // 清理本地缓存
            cleanupLock(lockKey);
            
        } catch (Exception e) {
            log.error("Force unlock failed: {}", lockKey, e);
            throw new LockException("Force unlock failed: " + e.getMessage(), e);
        }
    }
}

```

接下来我们要实现Infrastructure层的MQ消费者组件吗？比如TaskConsumer用于处理任务相关的消息。
好的，让我们实现TaskConsumer - 任务消息消费者。



```java
package com.platform.collect.infrastructure.mq.consumer;

import com.platform.collect.infrastructure.mq.message.TaskMessage;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 任务消息消费者
 */
@Slf4j
@Component
public class TaskConsumer {

    @Autowired
    private TaskExecutor taskExecutor;

    @Autowired
    private StateManager stateManager;

    @Autowired
    private TransactionManager transactionManager;

    /**
     * 处理任务创建消息
     */
    @RabbitListener(
        queues = "${mq.queue.task-create}",
        containerFactory = "taskListenerFactory"
    )
    public void handleTaskCreate(TaskMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive task create message: {}", messageId);

        TransactionStatus tx = null;
        try {
            // 1. 开启事务
            tx = transactionManager.beginTransaction();

            // 2. 预处理消息
            preprocessMessage(message);

            // 3. 处理任务创建
            handleCreate(message);

            // 4. 提交事务
            transactionManager.commit(tx);

        } catch (Exception e) {
            // 5. 回滚事务
            if (tx != null) {
                transactionManager.rollback(tx);
            }
            handleError(message, e);
        }
    }

    /**
     * 处理任务执行消息
     */
    @RabbitListener(
        queues = "${mq.queue.task-execute}",
        containerFactory = "taskListenerFactory"
    )
    public void handleTaskExecute(TaskMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive task execute message: {}", messageId);

        try {
            // 1. 验证消息
            validateMessage(message);

            // 2. 异步执行任务
            taskExecutor.submit(() -> executeTask(message));

        } catch (Exception e) {
            handleError(message, e);
        }
    }

    /**
     * 处理任务取消消息
     */
    @RabbitListener(
        queues = "${mq.queue.task-cancel}",
        containerFactory = "taskListenerFactory"
    )
    public void handleTaskCancel(TaskMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive task cancel message: {}", messageId);

        try {
            // 1. 检查任务状态
            if (!isTaskCancellable(message.getTaskId())) {
                log.warn("Task is not cancellable: {}", message.getTaskId());
                return;
            }

            // 2. 执行取消
            cancelTask(message);

        } catch (Exception e) {
            handleError(message, e);
        }
    }

    /**
     * 预处理消息
     */
    private void preprocessMessage(TaskMessage message) {
        // 1. 检查消息有效性
        if (!isValidMessage(message)) {
            throw new InvalidMessageException("Invalid message: " + message.getMessageId());
        }

        // 2. 检查重复消息
        if (isDuplicateMessage(message)) {
            throw new DuplicateMessageException("Duplicate message: " + message.getMessageId());
        }

        // 3. 记录消息接收
        recordMessageReceive(message);
    }

    /**
     * 处理任务创建
     */
    private void handleCreate(TaskMessage message) {
        try {
            // 1. 创建任务
            CollectTask task = createTask(message);

            // 2. 保存任务
            taskRepository.save(task);

            // 3. 更新状态
            stateManager.updateTaskStatus(task.getTaskId(), TaskStatus.CREATED);

            // 4. 发送任务创建事件
            publishTaskCreatedEvent(task);

        } catch (Exception e) {
            log.error("Handle task create failed: {}", message.getTaskId(), e);
            throw e;
        }
    }

    /**
     * 执行任务
     */
    private void executeTask(TaskMessage message) {
        try {
            // 1. 更新状态为执行中
            stateManager.updateTaskStatus(message.getTaskId(), TaskStatus.RUNNING);

            // 2. 执行任务
            TaskResult result = taskExecutor.execute(message.getTaskId());

            // 3. 处理执行结果
            handleTaskResult(message.getTaskId(), result);

        } catch (Exception e) {
            log.error("Execute task failed: {}", message.getTaskId(), e);
            handleTaskError(message.getTaskId(), e);
        }
    }

    /**
     * 取消任务
     */
    private void cancelTask(TaskMessage message) {
        try {
            // 1. 停止任务执行
            taskExecutor.stop(message.getTaskId());

            // 2. 更新任务状态
            stateManager.updateTaskStatus(message.getTaskId(), TaskStatus.CANCELED);

            // 3. 发送任务取消事件
            publishTaskCanceledEvent(message.getTaskId());

        } catch (Exception e) {
            log.error("Cancel task failed: {}", message.getTaskId(), e);
            throw e;
        }
    }

    /**
     * 处理任务结果
     */
    private void handleTaskResult(String taskId, TaskResult result) {
        try {
            // 1. 更新任务状态
            TaskStatus status = result.isSuccess() ? TaskStatus.COMPLETED : TaskStatus.FAILED;
            stateManager.updateTaskStatus(taskId, status);

            // 2. 保存任务结果
            taskRepository.saveResult(taskId, result);

            // 3. 发送任务完成事件
            publishTaskCompletedEvent(taskId, result);

        } catch (Exception e) {
            log.error("Handle task result failed: {}", taskId, e);
            handleTaskError(taskId, e);
        }
    }

    /**
     * 处理错误
     */
    private void handleError(TaskMessage message, Exception e) {
        try {
            // 1. 记录错误日志
            logError(message, e);

            // 2. 检查重试
            if (shouldRetry(message, e)) {
                handleRetry(message);
            } else {
                handleFinalError(message, e);
            }

        } catch (Exception ex) {
            log.error("Handle error failed", ex);
        }
    }

    /**
     * 处理最终错误
     */
    private void handleFinalError(TaskMessage message, Exception e) {
        try {
            // 1. 更新任务状态
            stateManager.updateTaskStatus(message.getTaskId(), TaskStatus.FAILED);

            // 2. 保存错误信息
            stateManager.updateTaskError(message.getTaskId(), e.getMessage());

            // 3. 发送任务失败事件
            publishTaskFailedEvent(message.getTaskId(), e);

        } catch (Exception ex) {
            log.error("Handle final error failed", ex);
        }
    }
}

```

接下来要实现ResultConsumer - 结果消息消费者吗？这个组件负责处理任务执行结果相关的消息。
好的，让我们实现ResultConsumer - 结果消息消费者。



```java
package com.platform.collect.infrastructure.mq.consumer;

import com.platform.collect.infrastructure.mq.message.ResultMessage;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 结果消息消费者
 */
@Slf4j
@Component
public class ResultConsumer {

    @Autowired
    private ResultProcessor resultProcessor;

    @Autowired
    private StateManager stateManager;

    @Autowired
    private NotificationService notificationService;

    /**
     * 处理采集结果消息
     */
    @RabbitListener(
        queues = "${mq.queue.collect-result}",
        containerFactory = "resultListenerFactory"
    )
    public void handleCollectResult(ResultMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive collect result message: {}", messageId);

        try {
            // 1. 验证结果消息
            validateResultMessage(message);

            // 2. 处理采集结果
            handleResult(message);

            // 3. 发送结果通知
            sendResultNotification(message);

        } catch (Exception e) {
            log.error("Handle collect result failed", e);
            handleError(message, e);
        }
    }

    /**
     * 处理同步结果消息
     */
    @RabbitListener(
        queues = "${mq.queue.sync-result}",
        containerFactory = "resultListenerFactory"
    )
    public void handleSyncResult(ResultMessage message) {
        String messageId = message.getMessageId();
        log.info("Receive sync result message: {}", messageId);

        try {
            // 1. 验证同步结果
            validateSyncResult(message);

            // 2. 处理同步结果
            handleSyncResult(message);

            // 3. 更新同步状态
            updateSyncStatus(message);

        } catch (Exception e) {
            log.error("Handle sync result failed", e);
            handleError(message, e);
        }
    }

    /**
     * 验证结果消息
     */
    private void validateResultMessage(ResultMessage message) {
        // 1. 检查消息完整性
        if (!isValidMessage(message)) {
            throw new InvalidMessageException("Invalid result message: " + message.getMessageId());
        }

        // 2. 检查任务状态
        String taskId = message.getTaskId();
        TaskStatus status = stateManager.getTaskStatus(taskId);
        if (!isValidTaskStatus(status)) {
            throw new InvalidTaskStatusException("Invalid task status: " + status);
        }

        // 3. 验证结果数据
        validateResultData(message.getResult());
    }

    /**
     * 处理采集结果
     */
    private void handleResult(ResultMessage message) {
        try {
            // 1. 解析结果数据
            CollectResult result = parseResult(message);

            // 2. 保存结果数据
            resultProcessor.processResult(result);

            // 3. 更新任务状态
            updateTaskStatus(message.getTaskId(), result);

            // 4. 发布结果事件
            publishResultEvent(message.getTaskId(), result);

        } catch (Exception e) {
            log.error("Process result failed: {}", message.getTaskId(), e);
            throw e;
        }
    }

    /**
     * 处理同步结果
     */
    private void handleSyncResult(ResultMessage message) {
        try {
            // 1. 验证数据一致性
            validateDataConsistency(message);

            // 2. 更新同步记录
            updateSyncRecord(message);

            // 3. 处理差异数据
            handleDiffData(message);

        } catch (Exception e) {
            log.error("Handle sync result failed: {}", message.getTaskId(), e);
            throw e;
        }
    }

    /**
     * 发送结果通知
     */
    private void sendResultNotification(ResultMessage message) {
        try {
            // 1. 构建通知内容
            NotifyContent content = buildNotifyContent(message);

            // 2. 获取通知配置
            NotifyConfig config = getNotifyConfig(message);

            // 3. 发送通知
            notificationService.sendNotification(content, config);

        } catch (Exception e) {
            log.error("Send result notification failed", e);
        }
    }

    /**
     * 更新任务状态
     */
    private void updateTaskStatus(String taskId, CollectResult result) {
        // 1. 确定任务状态
        TaskStatus status = determineTaskStatus(result);

        // 2. 更新状态
        stateManager.updateTaskStatus(taskId, status);

        // 3. 更新统计信息
        updateTaskStats(taskId, result);
    }

    /**
     * 验证数据一致性
     */
    private void validateDataConsistency(ResultMessage message) {
        SyncResult syncResult = message.getSyncResult();
        
        // 1. 检查数据量
        if (!isDataCountMatch(syncResult)) {
            throw new DataInconsistencyException("Data count mismatch");
        }

        // 2. 检查数据校验和
        if (!isChecksumMatch(syncResult)) {
            throw new DataInconsistencyException("Data checksum mismatch");
        }

        // 3. 检查关键字段
        validateKeyFields(syncResult);
    }

    /**
     * 处理差异数据
     */
    private void handleDiffData(ResultMessage message) {
        SyncResult syncResult = message.getSyncResult();
        
        // 1. 保存差异记录
        saveDiffRecord(syncResult);

        // 2. 是否需要自动修复
        if (shouldAutoFix(syncResult)) {
            // 提交修复任务
            submitFixTask(syncResult);
        }

        // 3. 发送差异报告
        sendDiffReport(syncResult);
    }

    /**
     * 处理错误
     */
    private void handleError(ResultMessage message, Exception e) {
        try {
            // 1. 记录错误日志
            logProcessError(message, e);

            // 2. 更新处理状态
            updateErrorStatus(message, e);

            // 3. 发送错误通知
            sendErrorNotification(message, e);

        } catch (Exception ex) {
            log.error("Handle error failed", ex);
        }
    }

    /**
     * 更新错误状态
     */
    private void updateErrorStatus(ResultMessage message, Exception e) {
        ErrorInfo error = ErrorInfo.builder()
            .messageId(message.getMessageId())
            .taskId(message.getTaskId())
            .errorType(e.getClass().getSimpleName())
            .errorMessage(e.getMessage())
            .timestamp(new Date())
            .build();

        stateManager.updateErrorStatus(error);
    }

    /**
     * 记录处理错误
     */
    private void logProcessError(ResultMessage message, Exception e) {
        ProcessError error = ProcessError.builder()
            .messageId(message.getMessageId())
            .taskId(message.getTaskId())
            .phase("RESULT_PROCESS")
            .error(e.getMessage())
            .timestamp(new Date())
            .build();

        errorLogService.logError(error);
    }
}

```

接下来要实现Infrastructure层的其他组件吗？比如配置加载器(ConfigLoader)或监控组件(MonitorService)等。
好的，让我们先实现ConfigLoader - 配置加载器组件。



```java
package com.platform.collect.infrastructure.config;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 配置加载器
 */
@Slf4j
@Component
public class ConfigLoader {

    @Autowired
    private NacosConfigManager nacosConfigManager;

    @Autowired
    private ConfigRepository configRepository;

    // 配置缓存
    private final Cache<String, ConfigItem> configCache;

    // 监听器映射
    private final Map<String, List<ConfigChangeListener>> listenerMap = new ConcurrentHashMap<>();

    public ConfigLoader() {
        this.configCache = CacheBuilder.newBuilder()
            .expireAfterWrite(5, TimeUnit.MINUTES)
            .maximumSize(1000)
            .build();
    }

    /**
     * 初始化配置
     */
    @PostConstruct
    public void init() {
        try {
            // 1. 加载本地配置
            loadLocalConfig();

            // 2. 加载远程配置
            loadRemoteConfig();

            // 3. 注册配置监听
            registerConfigListener();

            log.info("Config loader initialized successfully");
        } catch (Exception e) {
            log.error("Initialize config loader failed", e);
            throw new ConfigException("Initialize config loader failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取配置
     */
    public <T> T getConfig(String key, Class<T> type) {
        try {
            ConfigItem item = configCache.get(key, () -> loadConfig(key));
            return convertValue(item.getValue(), type);
        } catch (Exception e) {
            log.error("Get config failed: {}", key, e);
            throw new ConfigException("Get config failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取配置(带默认值)
     */
    public <T> T getConfig(String key, Class<T> type, T defaultValue) {
        try {
            ConfigItem item = configCache.getIfPresent(key);
            if (item == null) {
                return defaultValue;
            }
            return convertValue(item.getValue(), type);
        } catch (Exception e) {
            log.error("Get config with default failed: {}", key, e);
            return defaultValue;
        }
    }

    /**
     * 添加配置变更监听器
     */
    public void addChangeListener(String key, ConfigChangeListener listener) {
        listenerMap.computeIfAbsent(key, k -> new CopyOnWriteArrayList<>())
                  .add(listener);
    }

    /**
     * 移除配置变更监听器
     */
    public void removeChangeListener(String key, ConfigChangeListener listener) {
        List<ConfigChangeListener> listeners = listenerMap.get(key);
        if (listeners != null) {
            listeners.remove(listener);
        }
    }

    /**
     * 加载本地配置
     */
    private void loadLocalConfig() {
        try {
            // 1. 读取配置文件
            Properties properties = new Properties();
            properties.load(new FileInputStream("config/application.properties"));

            // 2. 解析配置项
            for (String key : properties.stringPropertyNames()) {
                String value = properties.getProperty(key);
                ConfigItem item = ConfigItem.builder()
                    .key(key)
                    .value(value)
                    .source("local")
                    .updateTime(new Date())
                    .build();
                configCache.put(key, item);
            }
        } catch (Exception e) {
            log.error("Load local config failed", e);
            throw e;
        }
    }

    /**
     * 加载远程配置
     */
    private void loadRemoteConfig() {
        try {
            // 1. 获取远程配置
            List<ConfigItem> remoteConfigs = nacosConfigManager.getAllConfigs();

            // 2. 更新缓存
            for (ConfigItem item : remoteConfigs) {
                configCache.put(item.getKey(), item);
            }
        } catch (Exception e) {
            log.error("Load remote config failed", e);
            throw e;
        }
    }

    /**
     * 注册配置监听
     */
    private void registerConfigListener() {
        nacosConfigManager.addListener(event -> {
            String key = event.getKey();
            String value = event.getValue();
            
            try {
                // 1. 更新缓存
                updateConfig(key, value);
                
                // 2. 通知监听器
                notifyConfigChange(key, value);
                
            } catch (Exception e) {
                log.error("Handle config change failed: {}", key, e);
            }
        });
    }

    /**
     * 更新配置
     */
    private void updateConfig(String key, String value) {
        ConfigItem item = ConfigItem.builder()
            .key(key)
            .value(value)
            .source("remote")
            .updateTime(new Date())
            .build();
            
        configCache.put(key, item);
        
        // 保存配置历史
        saveConfigHistory(item);
    }

    /**
     * 通知配置变更
     */
    private void notifyConfigChange(String key, String value) {
        List<ConfigChangeListener> listeners = listenerMap.get(key);
        if (listeners != null) {
            ConfigChangeEvent event = new ConfigChangeEvent(key, value);
            for (ConfigChangeListener listener : listeners) {
                try {
                    listener.onChange(event);
                } catch (Exception e) {
                    log.error("Notify config change failed", e);
                }
            }
        }
    }

    /**
     * 保存配置历史
     */
    private void saveConfigHistory(ConfigItem item) {
        ConfigHistory history = ConfigHistory.builder()
            .key(item.getKey())
            .value(item.getValue())
            .source(item.getSource())
            .changeTime(new Date())
            .build();
            
        configRepository.saveHistory(history);
    }

    /**
     * 加载配置
     */
    private ConfigItem loadConfig(String key) throws Exception {
        // 1. 尝试从本地加载
        ConfigItem item = loadLocalConfig(key);
        if (item != null) {
            return item;
        }

        // 2. 从远程加载
        item = nacosConfigManager.getConfig(key);
        if (item != null) {
            return item;
        }

        throw new ConfigNotFoundException("Config not found: " + key);
    }

    /**
     * 转换配置值类型
     */
    private <T> T convertValue(String value, Class<T> type) {
        if (String.class.equals(type)) {
            return (T) value;
        } else if (Integer.class.equals(type)) {
            return (T) Integer.valueOf(value);
        } else if (Long.class.equals(type)) {
            return (T) Long.valueOf(value);
        } else if (Boolean.class.equals(type)) {
            return (T) Boolean.valueOf(value);
        }
        throw new IllegalArgumentException("Unsupported type: " + type);
    }
}

```

接下来要实现MonitorService - 监控服务组件吗？这个组件负责系统状态的监控和指标收集。
好的，让我们实现MonitorService - 监控服务组件。



```java
package com.platform.collect.infrastructure.monitor;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

/**
 * 监控服务组件
 */
@Slf4j
@Component
public class MonitorService {

    @Autowired
    private MetricsCollector metricsCollector;

    @Autowired
    private AlertManager alertManager;

    @Autowired
    private MonitorRepository monitorRepository;

    // 系统状态信息
    private final Map<String, SystemStatus> systemStatusMap = new ConcurrentHashMap<>();
    
    // 组件健康状态
    private final Map<String, HealthStatus> healthStatusMap = new ConcurrentHashMap<>();

    /**
     * 系统状态监控
     */
    @Scheduled(fixedRate = 30000) // 每30秒
    public void monitorSystemStatus() {
        try {
            // 1. 收集系统状态
            SystemStatus status = collectSystemStatus();
            
            // 2. 更新状态记录
            updateSystemStatus(status);
            
            // 3. 检查告警条件
            checkAlertConditions(status);
            
        } catch (Exception e) {
            log.error("Monitor system status failed", e);
        }
    }

    /**
     * 组件健康检查
     */
    @Scheduled(fixedRate = 60000) // 每60秒
    public void checkComponentHealth() {
        try {
            // 1. 检查数据库连接
            checkDatabaseHealth();
            
            // 2. 检查缓存服务
            checkCacheHealth();
            
            // 3. 检查消息队列
            checkMessageQueueHealth();
            
            // 4. 检查存储服务
            checkStorageHealth();
            
        } catch (Exception e) {
            log.error("Check component health failed", e);
        }
    }

    /**
     * 性能数据采集
     */
    @Scheduled(fixedRate = 5000) // 每5秒
    public void collectPerformanceMetrics() {
        try {
            // 1. 采集JVM指标
            collectJvmMetrics();
            
            // 2. 采集业务指标
            collectBusinessMetrics();
            
            // 3. 采集资源指标
            collectResourceMetrics();
            
        } catch (Exception e) {
            log.error("Collect performance metrics failed", e);
        }
    }

    /**
     * 收集系统状态
     */
    private SystemStatus collectSystemStatus() {
        return SystemStatus.builder()
            .cpuUsage(getCpuUsage())
            .memoryUsage(getMemoryUsage())
            .diskUsage(getDiskUsage())
            .threadCount(getThreadCount())
            .taskCount(getTaskCount())
            .queueSize(getQueueSize())
            .errorCount(getErrorCount())
            .timestamp(new Date())
            .build();
    }

    /**
     * 更新系统状态
     */
    private void updateSystemStatus(SystemStatus status) {
        // 1. 更新内存状态
        systemStatusMap.put("current", status);
        
        // 2. 保存历史记录
        monitorRepository.saveSystemStatus(status);
        
        // 3. 更新统计信息
        updateStatusStatistics(status);
    }

    /**
     * 检查告警条件
     */
    private void checkAlertConditions(SystemStatus status) {
        // 1. 检查CPU使用率
        if (status.getCpuUsage() > 80) {
            Alert alert = Alert.builder()
                .type(AlertType.HIGH_CPU_USAGE)
                .level(AlertLevel.WARNING)
                .message("High CPU usage: " + status.getCpuUsage() + "%")
                .timestamp(new Date())
                .build();
            alertManager.sendAlert(alert);
        }
        
        // 2. 检查内存使用率
        if (status.getMemoryUsage() > 85) {
            Alert alert = Alert.builder()
                .type(AlertType.HIGH_MEMORY_USAGE)
                .level(AlertLevel.WARNING)
                .message("High memory usage: " + status.getMemoryUsage() + "%")
                .timestamp(new Date())
                .build();
            alertManager.sendAlert(alert);
        }
        
        // 3. 检查错误数
        if (status.getErrorCount() > 100) {
            Alert alert = Alert.builder()
                .type(AlertType.HIGH_ERROR_COUNT)
                .level(AlertLevel.ERROR)
                .message("High error count: " + status.getErrorCount())
                .timestamp(new Date())
                .build();
            alertManager.sendAlert(alert);
        }
    }

    /**
     * 检查数据库健康状态
     */
    private void checkDatabaseHealth() {
        try {
            // 1. 执行心跳检查
            boolean isHealthy = isDatabaseHealthy();
            
            // 2. 更新状态
            updateComponentHealth("database", isHealthy);
            
            // 3. 处理不健康状态
            if (!isHealthy) {
                handleUnhealthyComponent("database");
            }
        } catch (Exception e) {
            log.error("Check database health failed", e);
            updateComponentHealth("database", false);
        }
    }

    /**
     * 采集JVM指标
     */
    private void collectJvmMetrics() {
        // 1. 内存使用
        metricsCollector.recordValue("jvm.memory.used", getUsedMemory());
        metricsCollector.recordValue("jvm.memory.total", getTotalMemory());
        
        // 2. GC统计
        Map<String, Long> gcStats = getGcStats();
        gcStats.forEach((name, value) -> 
            metricsCollector.recordValue("jvm.gc." + name, value));
            
        // 3. 线程统计
        metricsCollector.recordValue("jvm.threads.count", getThreadCount());
        metricsCollector.recordValue("jvm.threads.peak", getPeakThreadCount());
    }

    /**
     * 处理不健康组件
     */
    private void handleUnhealthyComponent(String component) {
        // 1. 发送告警
        Alert alert = Alert.builder()
            .type(AlertType.COMPONENT_UNHEALTHY)
            .level(AlertLevel.ERROR)
            .message("Component unhealthy: " + component)
            .timestamp(new Date())
            .build();
        alertManager.sendAlert(alert);
        
        // 2. 记录事件
        MonitorEvent event = MonitorEvent.builder()
            .type(EventType.COMPONENT_UNHEALTHY)
            .component(component)
            .timestamp(new Date())
            .build();
        monitorRepository.saveEvent(event);
        
        // 3. 执行恢复操作
        triggerComponentRecovery(component);
    }

    /**
     * 更新组件健康状态
     */
    private void updateComponentHealth(String component, boolean healthy) {
        HealthStatus status = HealthStatus.builder()
            .component(component)
            .healthy(healthy)
            .lastCheckTime(new Date())
            .build();
            
        healthStatusMap.put(component, status);
    }

    /**
     * 获取系统监控数据
     */
    public Map<String, Object> getMonitorData() {
        Map<String, Object> data = new HashMap<>();
        
        // 1. 系统状态
        data.put("system", systemStatusMap.get("current"));
        
        // 2. 组件健康状态
        data.put("health", healthStatusMap);
        
        // 3. 性能指标
        data.put("metrics", metricsCollector.getCurrentMetrics());
        
        return data;
    }
}

```

接下来要实现系统的其他基础组件吗？比如ZooKeeperClient或者ElasticSearchTemplate等？
好的，让我们先实现ZooKeeperClient - ZooKeeper客户端组件。



```java
```java
package com.platform.collect.infrastructure.zk;

import lombok.extern.slf4j.Slf4j;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.recipes.cache.NodeCache;
import org.apache.curator.framework.recipes.leader.LeaderSelector;
import org.springframework.stereotype.Component;

/**
 * ZooKeeper客户端组件
 */
@Slf4j
@Component
public class ZooKeeperClient {

    private final CuratorFramework client;
    private final String rootPath;
    private final Map<String, NodeCache> nodeCacheMap = new ConcurrentHashMap<>();
    private final Map<String, LeaderSelector> leaderSelectorMap = new ConcurrentHashMap<>();

    public ZooKeeperClient(CuratorFramework client, 
                          @Value("${zookeeper.root-path:/collect}") String rootPath) {
        this.client = client;
        this.rootPath = rootPath;
    }

    /**
     * 初始化
     */
    @PostConstruct
    public void init() {
        try {
            // 1. 确保根节点存在
            ensurePath(rootPath);

            // 2. 注册状态监听
            registerStateListener();

            log.info("ZooKeeper client initialized successfully");
        } catch (Exception e) {
            log.error("Initialize ZooKeeper client failed", e);
            throw new ZkException("Initialize ZooKeeper client failed: " + e.getMessage(), e);
        }
    }

    /**
     * 创建节点
     */
    public void createNode(String path, String data) throws Exception {
        String fullPath = buildPath(path);
        try {
            client.create()
                  .creatingParentsIfNeeded()
                  .forPath(fullPath, data.getBytes());
        } catch (Exception e) {
            log.error("Create node failed: {}", fullPath, e);
            throw e;
        }
    }

    /**
     * 更新节点数据
     */
    public void updateNode(String path, String data) throws Exception {
        String fullPath = buildPath(path);
        try {
            client.setData()
                  .forPath(fullPath, data.getBytes());
        } catch (Exception e) {
            log.error("Update node failed: {}", fullPath, e);
            throw e;
        }
    }

    /**
     * 删除节点
     */
    public void deleteNode(String path) throws Exception {
        String fullPath = buildPath(path);
        try {
            client.delete()
                  .guaranteed()
                  .deletingChildrenIfNeeded()
                  .forPath(fullPath);
        } catch (Exception e) {
            log.error("Delete node failed: {}", fullPath, e);
            throw e;
        }
    }

    /**
     * 获取节点数据
     */
    public String getData(String path) throws Exception {
        String fullPath = buildPath(path);
        try {
            byte[] bytes = client.getData()
                                .forPath(fullPath);
            return new String(bytes);
        } catch (Exception e) {
            log.error("Get node data failed: {}", fullPath, e);
            throw e;
        }
    }

    /**
     * 监听节点变化
     */
    public void watchNode(String path, NodeChangeListener listener) throws Exception {
        String fullPath = buildPath(path);
        try {
            NodeCache nodeCache = new NodeCache(client, fullPath);
            nodeCache.getListenable().addListener(() -> {
                String data = new String(nodeCache.getCurrentData().getData());
                listener.onNodeChanged(data);
            });
            nodeCache.start();
            nodeCacheMap.put(fullPath, nodeCache);
        } catch (Exception e) {
            log.error("Watch node failed: {}", fullPath, e);
            throw e;
        }
    }

    /**
     * 选举Leader
     */
    public void electLeader(String path, LeadershipCallback callback) throws Exception {
        String fullPath = buildPath(path);
        try {
            LeaderSelector selector = new LeaderSelector(client, fullPath, 
                new LeaderSelectorListenerAdapter() {
                    @Override
                    public void takeLeadership(CuratorFramework client) throws Exception {
                        try {
                            callback.onLeaderStart();
                            Thread.sleep(Long.MAX_VALUE);
                        } catch (Exception e) {
                            log.error("Leader execution failed", e);
                            throw e;
                        } finally {
                            callback.onLeaderStop();
                        }
                    }
                });
            selector.autoRequeue();
            selector.start();
            leaderSelectorMap.put(fullPath, selector);
        } catch (Exception e) {
            log.error("Elect leader failed: {}", fullPath, e);
            throw e;
        }
    }

    /**
     * 注册状态监听
     */
    private void registerStateListener() {
        client.getConnectionStateListenable().addListener((client, state) -> {
            log.info("ZooKeeper connection state changed: {}", state);
            switch (state) {
                case LOST:
                    handleConnectionLost();
                    break;
                case RECONNECTED:
                    handleReconnected();
                    break;
                case SUSPENDED:
                    handleConnectionSuspended();
                    break;
                default:
                    break;
            }
        });
    }

    /**
     * 处理连接丢失
     */
    private void handleConnectionLost() {
        try {
            // 1. 停止所有监听器
            stopAllWatchers();
            
            // 2. 清理本地缓存
            clearLocalCache();
            
            // 3. 发送告警
            sendConnectionAlert("Connection Lost");
        } catch (Exception e) {
            log.error("Handle connection lost failed", e);
        }
    }

    /**
     * 处理重连
     */
    private void handleReconnected() {
        try {
            // 1. 恢复监听器
            restoreWatchers();
            
            // 2. 重新注册临时节点
            reregisterEphemeralNodes();
            
            // 3. 恢复选举
            restoreLeaderElections();
        } catch (Exception e) {
            log.error("Handle reconnection failed", e);
        }
    }

    /**
     * 停止所有监听器
     */
    private void stopAllWatchers() {
        nodeCacheMap.values().forEach(nodeCache -> {
            try {
                nodeCache.close();
            } catch (Exception e) {
                log.error("Close node cache failed", e);
            }
        });
        nodeCacheMap.clear();
    }

    /**
     * 恢复监听器
     */
    private void restoreWatchers() {
        // 从本地配置恢复监听器
        watcherConfig.getWatchPaths().forEach(path -> {
            try {
                watchNode(path, watcherConfig.getListener(path));
            } catch (Exception e) {
                log.error("Restore watcher failed: {}", path, e);
            }
        });
    }

    /**
     * 构建完整路径
     */
    private String buildPath(String path) {
        return rootPath + (path.startsWith("/") ? path : "/" + path);
    }

    @PreDestroy
    public void destroy() {
        // 关闭所有监听器
        nodeCacheMap.values().forEach(nodeCache -> {
            try {
                nodeCache.close();
            } catch (Exception e) {
                log.error("Close node cache failed", e);
            }
        });

        // 关闭所有选举器
        leaderSelectorMap.values().forEach(selector -> {
            try {
                selector.close();
            } catch (Exception e) {
                log.error("Close leader selector failed", e);
            }
        });
    }
}
```

```

接下来要实现ElasticSearchTemplate - ElasticSearch操作模板吗？这个组件负责搜索和分析功能。
好的，让我们实现ElasticSearchTemplate - ElasticSearch操作模板。



```java
```java
package com.platform.collect.infrastructure.es;

import lombok.extern.slf4j.Slf4j;
import org.elasticsearch.action.bulk.BulkRequest;
import org.elasticsearch.action.search.SearchRequest;
import org.elasticsearch.client.RestHighLevelClient;
import org.springframework.stereotype.Component;

/**
 * ElasticSearch操作模板
 */
@Slf4j
@Component
public class ElasticSearchTemplate {

    private final RestHighLevelClient client;
    private final String indexPrefix;

    public ElasticSearchTemplate(RestHighLevelClient client,
                               @Value("${elasticsearch.index-prefix:collect_}") String indexPrefix) {
        this.client = client;
        this.indexPrefix = indexPrefix;
    }

    /**
     * 索引文档
     */
    public void indexDocument(String index, String id, Map<String, Object> document) {
        String indexName = buildIndexName(index);
        try {
            // 1. 构建索引请求
            IndexRequest request = new IndexRequest(indexName)
                .id(id)
                .source(document);

            // 2. 执行索引
            client.index(request, RequestOptions.DEFAULT);

        } catch (Exception e) {
            log.error("Index document failed: {}/{}", indexName, id, e);
            throw new EsException("Index document failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量索引文档
     */
    public void bulkIndex(String index, List<IndexData> dataList) {
        String indexName = buildIndexName(index);
        try {
            // 1. 构建批量请求
            BulkRequest bulkRequest = new BulkRequest();
            for (IndexData data : dataList) {
                bulkRequest.add(new IndexRequest(indexName)
                    .id(data.getId())
                    .source(data.getDocument()));
            }

            // 2. 执行批量索引
            BulkResponse response = client.bulk(bulkRequest, RequestOptions.DEFAULT);

            // 3. 检查结果
            if (response.hasFailures()) {
                handleBulkFailures(response);
            }

        } catch (Exception e) {
            log.error("Bulk index failed: {}", indexName, e);
            throw new EsException("Bulk index failed: " + e.getMessage(), e);
        }
    }

    /**
     * 搜索文档
     */
    public SearchResult search(SearchQuery query) {
        String indexName = buildIndexName(query.getIndex());
        try {
            // 1. 构建搜索请求
            SearchRequest request = buildSearchRequest(indexName, query);

            // 2. 执行搜索
            SearchResponse response = client.search(request, RequestOptions.DEFAULT);

            // 3. 解析结果
            return parseSearchResponse(response);

        } catch (Exception e) {
            log.error("Search failed: {}", indexName, e);
            throw new EsException("Search failed: " + e.getMessage(), e);
        }
    }

    /**
     * 聚合分析
     */
    public AggregationResult aggregate(AggregationQuery query) {
        String indexName = buildIndexName(query.getIndex());
        try {
            // 1. 构建聚合请求
            SearchRequest request = buildAggregationRequest(indexName, query);

            // 2. 执行聚合
            SearchResponse response = client.search(request, RequestOptions.DEFAULT);

            // 3. 解析聚合结果
            return parseAggregationResponse(response);

        } catch (Exception e) {
            log.error("Aggregation failed: {}", indexName, e);
            throw new EsException("Aggregation failed: " + e.getMessage(), e);
        }
    }

    /**
     * 构建搜索请求
     */
    private SearchRequest buildSearchRequest(String index, SearchQuery query) {
        SearchRequest request = new SearchRequest(index);
        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();

        // 1. 设置查询条件
        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        
        // 添加精确匹配条件
        query.getTerms().forEach((field, value) ->
            boolQuery.must(QueryBuilders.termQuery(field, value)));
            
        // 添加范围条件
        query.getRanges().forEach((field, range) ->
            boolQuery.must(QueryBuilders.rangeQuery(field)
                .from(range.getFrom())
                .to(range.getTo())));
                
        // 添加全文搜索条件
        if (query.getKeyword() != null) {
            boolQuery.must(QueryBuilders.multiMatchQuery(query.getKeyword(), 
                query.getSearchFields()));
        }

        sourceBuilder.query(boolQuery);

        // 2. 设置分页
        sourceBuilder.from((query.getPageNum() - 1) * query.getPageSize());
        sourceBuilder.size(query.getPageSize());

        // 3. 设置排序
        if (query.getSortField() != null) {
            sourceBuilder.sort(query.getSortField(), 
                query.getSortOrder() == SortOrder.DESC ? SortOrder.DESC : SortOrder.ASC);
        }

        request.source(sourceBuilder);
        return request;
    }

    /**
     * 构建聚合请求
     */
    private SearchRequest buildAggregationRequest(String index, AggregationQuery query) {
        SearchRequest request = new SearchRequest(index);
        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();

        // 1. 设置聚合
        query.getAggregations().forEach(agg -> {
            switch (agg.getType()) {
                case TERMS:
                    sourceBuilder.aggregation(AggregationBuilders
                        .terms(agg.getName())
                        .field(agg.getField())
                        .size(agg.getSize()));
                    break;
                case METRICS:
                    sourceBuilder.aggregation(AggregationBuilders
                        .stats(agg.getName())
                        .field(agg.getField()));
                    break;
                case DATE_HISTOGRAM:
                    sourceBuilder.aggregation(AggregationBuilders
                        .dateHistogram(agg.getName())
                        .field(agg.getField())
                        .fixedInterval(new DateHistogramInterval(agg.getInterval())));
                    break;
            }
        });

        // 2. 设置过滤条件
        if (!query.getFilters().isEmpty()) {
            BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
            query.getFilters().forEach((field, value) ->
                boolQuery.must(QueryBuilders.termQuery(field, value)));
            sourceBuilder.query(boolQuery);
        }

        // 3. 不返回文档内容
        sourceBuilder.size(0);

        request.source(sourceBuilder);
        return request;
    }

    /**
     * 解析搜索响应
     */
    private SearchResult parseSearchResponse(SearchResponse response) {
        SearchHits hits = response.getHits();
        
        // 1. 解析文档
        List<Map<String, Object>> documents = new ArrayList<>();
        for (SearchHit hit : hits.getHits()) {
            documents.add(hit.getSourceAsMap());
        }

        // 2. 构建结果
        return SearchResult.builder()
            .documents(documents)
            .total(hits.getTotalHits().value)
            .maxScore(hits.getMaxScore())
            .took(response.getTook().getMillis())
            .build();
    }

    /**
     * 解析聚合响应
     */
    private AggregationResult parseAggregationResponse(SearchResponse response) {
        Map<String, Object> results = new HashMap<>();
        
        // 解析不同类型的聚合结果
        Aggregations aggregations = response.getAggregations();
        for (Aggregation agg : aggregations) {
            String name = agg.getName();
            if (agg instanceof Terms) {
                results.put(name, parseTermsAggregation((Terms) agg));
            } else if (agg instanceof Stats) {
                results.put(name, parseStatsAggregation((Stats) agg));
            } else if (agg instanceof Histogram) {
                results.put(name, parseHistogramAggregation((Histogram) agg));
            }
        }

        return new AggregationResult(results);
    }

    /**
     * 处理批量操作失败
     */
    private void handleBulkFailures(BulkResponse response) {
        StringBuilder errors = new StringBuilder();
        for (BulkItemResponse itemResponse : response) {
            if (itemResponse.isFailed()) {
                BulkItemResponse.Failure failure = itemResponse.getFailure();
                errors.append("Index ")
                    .append(itemResponse.getIndex())
                    .append(" failed: ")
                    .append(failure.getMessage())
                    .append(";");
            }
        }
        throw new EsException("Bulk operation partially failed: " + errors);
    }

    /**
     * 构建索引名称
     */
    private String buildIndexName(String index) {
        return indexPrefix + index;
    }
}
```

```

接下来要实现系统的其他组件吗？比如KafkaTemplate或者MetricsExporter？
好的，让我们实现KafkaTemplate - Kafka操作模板。



```java
```java
package com.platform.collect.infrastructure.kafka;

import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Component;

/**
 * Kafka操作模板
 */
@Slf4j
@Component
public class KafkaOperationTemplate {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final KafkaStreamsRunner streamsRunner;
    private final MessageConverter messageConverter;

    public KafkaOperationTemplate(KafkaTemplate<String, String> kafkaTemplate,
                                KafkaStreamsRunner streamsRunner,
                                MessageConverter messageConverter) {
        this.kafkaTemplate = kafkaTemplate;
        this.streamsRunner = streamsRunner;
        this.messageConverter = messageConverter;
    }

    /**
     * 发送消息
     */
    public void sendMessage(String topic, Message message) {
        try {
            // 1. 转换消息
            String messageJson = messageConverter.toJson(message);

            // 2. 构建记录
            ProducerRecord<String, String> record = new ProducerRecord<>(
                topic,
                message.getKey(),
                messageJson
            );

            // 3. 设置消息头
            record.headers().add("messageId", message.getMessageId().getBytes());
            record.headers().add("timestamp", String.valueOf(System.currentTimeMillis()).getBytes());

            // 4. 异步发送
            kafkaTemplate.send(record)
                .addCallback(this::handleSuccess, this::handleFailure);

        } catch (Exception e) {
            log.error("Send message failed: {}", message.getMessageId(), e);
            throw new KafkaException("Send message failed: " + e.getMessage(), e);
        }
    }

    /**
     * 同步发送消息
     */
    public SendResult<String, String> sendMessageSync(String topic, Message message) {
        try {
            // 1. 转换消息
            String messageJson = messageConverter.toJson(message);

            // 2. 同步发送
            return kafkaTemplate.send(topic, message.getKey(), messageJson).get();

        } catch (Exception e) {
            log.error("Send message sync failed: {}", message.getMessageId(), e);
            throw new KafkaException("Send message sync failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量发送消息
     */
    public void sendMessages(String topic, List<Message> messages) {
        try {
            // 批量转换和发送
            messages.forEach(message -> {
                try {
                    String messageJson = messageConverter.toJson(message);
                    kafkaTemplate.send(topic, message.getKey(), messageJson);
                } catch (Exception e) {
                    log.error("Send message in batch failed: {}", message.getMessageId(), e);
                }
            });

            // 强制刷新
            kafkaTemplate.flush();

        } catch (Exception e) {
            log.error("Send messages batch failed", e);
            throw new KafkaException("Send messages batch failed: " + e.getMessage(), e);
        }
    }

    /**
     * 启动流处理
     */
    public void startStreaming(String inputTopic, String outputTopic, StreamProcessor processor) {
        try {
            // 1. 构建流处理配置
            StreamsConfig config = StreamsConfig.builder()
                .inputTopic(inputTopic)
                .outputTopic(outputTopic)
                .processor(processor)
                .build();

            // 2. 启动流处理
            streamsRunner.startStreaming(config);

        } catch (Exception e) {
            log.error("Start streaming failed", e);
            throw new KafkaException("Start streaming failed: " + e.getMessage(), e);
        }
    }

    /**
     * 停止流处理
     */
    public void stopStreaming() {
        try {
            streamsRunner.stopStreaming();
        } catch (Exception e) {
            log.error("Stop streaming failed", e);
            throw new KafkaException("Stop streaming failed: " + e.getMessage(), e);
        }
    }

    /**
     * 处理发送成功
     */
    private void handleSuccess(SendResult<String, String> result) {
        ProducerRecord<String, String> record = result.getProducerRecord();
        log.debug("Message sent successfully: {}, partition: {}, offset: {}",
            new String(record.headers().lastHeader("messageId").value()),
            result.getRecordMetadata().partition(),
            result.getRecordMetadata().offset());
        
        // 记录指标
        recordSendMetrics(result);
    }

    /**
     * 处理发送失败
     */
    private void handleFailure(Throwable ex) {
        log.error("Send message failed", ex);
        
        // 记录错误
        recordSendError(ex);
        
        // 发送告警
        sendAlert(ex);
    }

    /**
     * 记录发送指标
     */
    private void recordSendMetrics(SendResult<String, String> result) {
        try {
            // 记录延迟
            long latency = System.currentTimeMillis() - 
                Long.parseLong(new String(result.getProducerRecord()
                    .headers().lastHeader("timestamp").value()));
            metricsCollector.recordValue("kafka.send.latency", latency);

            // 记录成功计数
            metricsCollector.incrementCounter("kafka.send.success", 1);

            // 记录分区分布
            metricsCollector.incrementCounter(
                "kafka.send.partition." + result.getRecordMetadata().partition(), 1);

        } catch (Exception e) {
            log.error("Record send metrics failed", e);
        }
    }

    /**
     * 记录发送错误
     */
    private void recordSendError(Throwable ex) {
        try {
            // 记录错误计数
            metricsCollector.incrementCounter("kafka.send.error", 1);

            // 记录错误类型
            metricsCollector.incrementCounter(
                "kafka.send.error." + ex.getClass().getSimpleName(), 1);

            // 保存错误日志
            errorLogService.logError(MessageError.builder()
                .errorType("KAFKA_SEND_ERROR")
                .errorMessage(ex.getMessage())
                .timestamp(new Date())
                .build());

        } catch (Exception e) {
            log.error("Record send error failed", e);
        }
    }

    /**
     * 发送告警
     */
    private void sendAlert(Throwable ex) {
        try {
            Alert alert = Alert.builder()
                .type(AlertType.KAFKA_SEND_ERROR)
                .level(AlertLevel.ERROR)
                .message("Kafka send message failed: " + ex.getMessage())
                .timestamp(new Date())
                .build();
            alertService.sendAlert(alert);
        } catch (Exception e) {
            log.error("Send alert failed", e);
        }
    }

    @PreDestroy
    public void destroy() {
        try {
            // 停止流处理
            stopStreaming();
            
            // 关闭资源
            kafkaTemplate.flush();
            
        } catch (Exception e) {
            log.error("Destroy kafka template failed", e);
        }
    }
}
```

```

接下来要实现MetricsExporter - 指标导出器吗？这个组件负责将系统指标导出到Prometheus等监控系统。
好的,让我继续按照终稿的目录结构来实现MetricsExporter - 指标导出器。这个组件负责将系统指标导出到Prometheus等监控系统。

```java
package com.platform.collect.infrastructure.monitor.metrics;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import io.prometheus.client.*;

/**
 * 指标导出器
 */
@Slf4j
@Component
public class MetricsExporter {

    @Autowired
    private MetricsCollector metricsCollector;

    // 任务指标
    private final Counter taskCounter = Counter.build()
        .name("collect_task_total")
        .help("Total number of collect tasks")
        .labelNames("status")
        .register();

    private final Gauge taskGauge = Gauge.build()
        .name("collect_task_running")
        .help("Number of running collect tasks")
        .register();

    private final Histogram taskDuration = Histogram.build()
        .name("collect_task_duration_seconds")
        .help("Task execution duration in seconds")
        .buckets(0.1, 0.5, 1.0, 2.0, 5.0, 10.0)
        .register();

    // 数据指标
    private final Counter dataCounter = Counter.build()
        .name("collect_data_total")
        .help("Total number of collected data items")
        .labelNames("type")
        .register();

    private final Gauge dataSize = Gauge.build()
        .name("collect_data_size_bytes")
        .help("Size of collected data in bytes")
        .labelNames("type")
        .register();

    // 系统指标
    private final Gauge cpuUsage = Gauge.build()
        .name("system_cpu_usage")
        .help("CPU usage percentage")
        .register();

    private final Gauge memoryUsage = Gauge.build()
        .name("system_memory_usage")
        .help("Memory usage percentage")
        .register();

    /**
     * 导出任务指标
     */
    public void exportTaskMetrics(TaskMetrics metrics) {
        try {
            // 1. 更新任务计数
            taskCounter.labels(metrics.getStatus().name()).inc();

            // 2. 更新运行中任务数
            taskGauge.set(metrics.getRunningCount());

            // 3. 记录执行时间
            taskDuration.observe(metrics.getDurationInSeconds());

        } catch (Exception e) {
            log.error("Export task metrics failed", e);
        }
    }

    /**
     * 导出数据指标
     */
    public void exportDataMetrics(DataMetrics metrics) {
        try {
            // 1. 更新数据计数
            dataCounter.labels(metrics.getType()).inc(metrics.getCount());

            // 2. 更新数据大小
            dataSize.labels(metrics.getType()).set(metrics.getSizeInBytes());

        } catch (Exception e) {
            log.error("Export data metrics failed", e);
        }
    }

    /**
     * 导出系统指标
     */
    public void exportSystemMetrics(SystemMetrics metrics) {
        try {
            // 1. 更新CPU使用率
            cpuUsage.set(metrics.getCpuUsage());

            // 2. 更新内存使用率
            memoryUsage.set(metrics.getMemoryUsage());

        } catch (Exception e) {
            log.error("Export system metrics failed", e);
        }
    }

    /**
     * 定期导出指标
     */
    @Scheduled(fixedRate = 15000) // 每15秒
    public void exportMetrics() {
        try {
            // 1. 获取当前指标
            Map<String, Object> metrics = metricsCollector.getCurrentMetrics();

            // 2. 导出任务指标
            exportTaskMetrics(buildTaskMetrics(metrics));

            // 3. 导出数据指标
            exportDataMetrics(buildDataMetrics(metrics));

            // 4. 导出系统指标
            exportSystemMetrics(buildSystemMetrics(metrics));

        } catch (Exception e) {
            log.error("Export metrics failed", e);
        }
    }

    /**
     * 构建任务指标
     */
    private TaskMetrics buildTaskMetrics(Map<String, Object> metrics) {
        return TaskMetrics.builder()
            .status(TaskStatus.valueOf(String.valueOf(metrics.get("task.status"))))
            .runningCount((Integer) metrics.get("task.running"))
            .durationInSeconds((Double) metrics.get("task.duration"))
            .build();
    }

    /**
     * 构建数据指标
     */
    private DataMetrics buildDataMetrics(Map<String, Object> metrics) {
        return DataMetrics.builder()
            .type(String.valueOf(metrics.get("data.type")))
            .count((Long) metrics.get("data.count"))
            .sizeInBytes((Long) metrics.get("data.size"))
            .build();
    }

    /**
     * 构建系统指标
     */
    private SystemMetrics buildSystemMetrics(Map<String, Object> metrics) {
        return SystemMetrics.builder()
            .cpuUsage((Double) metrics.get("system.cpu"))
            .memoryUsage((Double) metrics.get("system.memory"))
            .build();
    }

    /**
     * 获取指标快照
     */
    public Map<String, Object> getMetricsSnapshot() {
        Map<String, Object> snapshot = new HashMap<>();
        
        // 1. 获取任务指标快照
        snapshot.put("task.total", taskCounter.collect());
        snapshot.put("task.running", taskGauge.get());
        snapshot.put("task.duration", taskDuration.collect());
        
        // 2. 获取数据指标快照
        snapshot.put("data.total", dataCounter.collect());
        snapshot.put("data.size", dataSize.collect());
        
        // 3. 获取系统指标快照
        snapshot.put("system.cpu", cpuUsage.get());
        snapshot.put("system.memory", memoryUsage.get());
        
        return snapshot;
    }

    /**
     * 重置指标
     */
    public void resetMetrics() {
        try {
            // 1. 重置任务指标
            taskCounter.clear();
            taskGauge.clear();
            taskDuration.clear();

            // 2. 重置数据指标
            dataCounter.clear();
            dataSize.clear();

            // 3. 重置系统指标
            cpuUsage.clear();
            memoryUsage.clear();

        } catch (Exception e) {
            log.error("Reset metrics failed", e);
        }
    }
}
```

接下来要实现哪个组件?
好的,让我们继续实现TaskScheduler - 任务调度器组件。这是一个核心组件,负责任务的调度和分发。

```java
package com.platform.collect.core.scheduler.base;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 任务调度器基类
 */
@Slf4j
@Component
public abstract class AbstractScheduler implements TaskScheduler {

    @Autowired
    private TaskDispatcher dispatcher;

    @Autowired
    private TaskSplitStrategy splitStrategy;

    @Autowired
    private ScheduleMonitor monitor;

    @Autowired
    private StateManager stateManager;

    /**
     * 调度任务
     */
    @Override
    public void schedule(CollectTask task) {
        String taskId = task.getTaskId();
        log.info("Start schedule task: {}", taskId);

        try {
            // 1. 构建调度上下文
            ScheduleContext context = buildContext(task);

            // 2. 执行调度
            doSchedule(context);

            // 3. 更新任务状态
            updateTaskStatus(taskId, TaskStatus.SCHEDULED);

        } catch (Exception e) {
            log.error("Schedule task failed: {}", taskId, e);
            handleScheduleError(task, e);
        }
    }

    /**
     * 取消调度
     */
    @Override
    public void cancel(String taskId) {
        log.info("Cancel task schedule: {}", taskId);

        try {
            // 1. 检查任务状态
            if (!isTaskCancelable(taskId)) {
                throw new IllegalStateException("Task is not cancelable: " + taskId);
            }

            // 2. 执行取消
            doCancel(taskId);

            // 3. 更新状态
            updateTaskStatus(taskId, TaskStatus.CANCELED);

        } catch (Exception e) {
            log.error("Cancel task failed: {}", taskId, e);
            handleCancelError(taskId, e);
        }
    }

    /**
     * 暂停调度
     */
    @Override
    public void pause(String taskId) {
        log.info("Pause task schedule: {}", taskId);

        try {
            // 1. 检查任务状态
            if (!isTaskPausable(taskId)) {
                throw new IllegalStateException("Task is not pausable: " + taskId);
            }

            // 2. 执行暂停
            doPause(taskId);

            // 3. 更新状态
            updateTaskStatus(taskId, TaskStatus.PAUSED);

        } catch (Exception e) {
            log.error("Pause task failed: {}", taskId, e);
            handlePauseError(taskId, e);
        }
    }

    /**
     * 恢复调度
     */
    @Override
    public void resume(String taskId) {
        log.info("Resume task schedule: {}", taskId);

        try {
            // 1. 检查任务状态
            if (!isTaskResumable(taskId)) {
                throw new IllegalStateException("Task is not resumable: " + taskId);
            }

            // 2. 执行恢复
            doResume(taskId);

            // 3. 更新状态
            updateTaskStatus(taskId, TaskStatus.RUNNING);

        } catch (Exception e) {
            log.error("Resume task failed: {}", taskId, e);
            handleResumeError(taskId, e);
        }
    }

    /**
     * 执行调度
     */
    protected void doSchedule(ScheduleContext context) {
        // 1. 任务分片
        List<SubTask> subTasks = splitStrategy.split(context.getTask());

        // 2. 记录分片信息
        recordSplitInfo(context.getTaskId(), subTasks);

        // 3. 分发子任务
        for (SubTask subTask : subTasks) {
            dispatcher.dispatch(subTask);
        }

        // 4. 更新监控信息
        updateMonitorInfo(context);
    }

    /**
     * 执行取消
     */
    protected void doCancel(String taskId) {
        // 1. 获取子任务
        List<SubTask> subTasks = getSubTasks(taskId);

        // 2. 取消子任务
        for (SubTask subTask : subTasks) {
            dispatcher.cancel(subTask.getSubTaskId());
        }

        // 3. 清理任务信息
        cleanupTaskInfo(taskId);
    }

    /**
     * 执行暂停
     */
    protected void doPause(String taskId) {
        // 1. 获取子任务
        List<SubTask> subTasks = getSubTasks(taskId);

        // 2. 暂停子任务
        for (SubTask subTask : subTasks) {
            dispatcher.pause(subTask.getSubTaskId());
        }

        // 3. 保存暂停信息
        savePauseInfo(taskId);
    }

    /**
     * 执行恢复
     */
    protected void doResume(String taskId) {
        // 1. 获取暂停信息
        PauseInfo pauseInfo = getPauseInfo(taskId);

        // 2. 恢复子任务
        List<SubTask> subTasks = getSubTasks(taskId);
        for (SubTask subTask : subTasks) {
            dispatcher.resume(subTask.getSubTaskId());
        }

        // 3. 更新恢复信息
        updateResumeInfo(taskId);
    }

    /**
     * 构建调度上下文
     */
    private ScheduleContext buildContext(CollectTask task) {
        return ScheduleContext.builder()
            .taskId(task.getTaskId())
            .task(task)
            .scheduler(this)
            .createTime(new Date())
            .build();
    }

    /**
     * 记录分片信息
     */
    private void recordSplitInfo(String taskId, List<SubTask> subTasks) {
        SplitInfo splitInfo = SplitInfo.builder()
            .taskId(taskId)
            .totalCount(subTasks.size())
            .subTasks(subTasks)
            .createTime(new Date())
            .build();
        stateManager.saveSplitInfo(splitInfo);
    }

    /**
     * 更新监控信息
     */
    private void updateMonitorInfo(ScheduleContext context) {
        monitor.recordScheduleInfo(ScheduleInfo.builder()
            .taskId(context.getTaskId())
            .scheduleTime(context.getCreateTime())
            .splitCount(context.getTask().getSubTasks().size())
            .build());
    }

    /**
     * 检查任务状态是否可取消
     */
    private boolean isTaskCancelable(String taskId) {
        TaskStatus status = stateManager.getTaskStatus(taskId);
        return status == TaskStatus.SCHEDULED || 
               status == TaskStatus.RUNNING ||
               status == TaskStatus.PAUSED;
    }

    /**
     * 检查任务状态是否可暂停 
     */
    private boolean isTaskPausable(String taskId) {
        TaskStatus status = stateManager.getTaskStatus(taskId);
        return status == TaskStatus.RUNNING;
    }

    /**
     * 检查任务状态是否可恢复
     */
    private boolean isTaskResumable(String taskId) {
        TaskStatus status = stateManager.getTaskStatus(taskId);
        return status == TaskStatus.PAUSED;
    }

    /**
     * 处理调度错误
     */
    private void handleScheduleError(CollectTask task, Exception e) {
        try {
            // 1. 更新任务状态
            updateTaskStatus(task.getTaskId(), TaskStatus.FAILED);

            // 2. 记录错误信息
            recordScheduleError(task, e);

            // 3. 发送告警通知
            sendScheduleAlert(task, e);

        } catch (Exception ex) {
            log.error("Handle schedule error failed", ex);
        }
    }
}
```

继续实现TaskDispatcher - 任务分发器组件吗？这个组件负责任务的具体分发。
好的,让我们实现TaskDispatcher - 任务分发器组件。该组件负责将子任务分发到具体的执行节点。

```java
package com.platform.collect.core.scheduler.dispatch;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 任务分发器
 */
@Slf4j
@Component
public class TaskDispatcher {
    
    @Autowired
    private DispatchStrategy dispatchStrategy;

    @Autowired
    private ExecutorRegistry executorRegistry;

    @Autowired
    private LoadBalancer loadBalancer;
    
    @Autowired
    private StateManager stateManager;

    /**
     * 分发任务
     */
    public void dispatch(SubTask subTask) {
        String subTaskId = subTask.getSubTaskId();
        log.info("Start dispatch subtask: {}", subTaskId);

        try {
            // 1. 获取可用执行器
            List<ExecutorInfo> executors = getAvailableExecutors();

            // 2. 选择目标执行器
            ExecutorInfo executor = selectExecutor(executors, subTask);

            // 3. 执行分发
            doDispatch(executor, subTask);

            // 4. 更新分发状态
            updateDispatchStatus(subTaskId, executor);

        } catch (Exception e) {
            log.error("Dispatch subtask failed: {}", subTaskId, e);
            handleDispatchError(subTask, e);
        }
    }

    /**
     * 批量分发
     */
    public void dispatchBatch(List<SubTask> subTasks) {
        try {
            // 1. 获取可用执行器
            List<ExecutorInfo> executors = getAvailableExecutors();

            // 2. 分批执行分发
            List<List<SubTask>> batches = splitBatches(subTasks);
            for (List<SubTask> batch : batches) {
                dispatchBatchInternal(executors, batch);
            }

        } catch (Exception e) {
            log.error("Dispatch batch tasks failed", e);
            handleBatchDispatchError(subTasks, e);
        }
    }

    /**
     * 取消分发
     */
    public void cancel(String subTaskId) {
        log.info("Cancel dispatch subtask: {}", subTaskId);

        try {
            // 1. 获取执行器信息
            ExecutorInfo executor = getExecutorInfo(subTaskId);
            if (executor == null) {
                log.warn("Executor not found for subtask: {}", subTaskId);
                return;
            }

            // 2. 执行取消
            executor.getClient().cancelTask(subTaskId);

            // 3. 更新状态
            updateCancelStatus(subTaskId);

        } catch (Exception e) {
            log.error("Cancel dispatch failed: {}", subTaskId, e);
            handleCancelError(subTaskId, e);
        }
    }

    /**
     * 暂停分发
     */
    public void pause(String subTaskId) {
        log.info("Pause dispatch subtask: {}", subTaskId);

        try {
            // 1. 获取执行器信息
            ExecutorInfo executor = getExecutorInfo(subTaskId);
            if (executor == null) {
                log.warn("Executor not found for subtask: {}", subTaskId);
                return;
            }

            // 2. 执行暂停
            executor.getClient().pauseTask(subTaskId);

            // 3. 更新状态
            updatePauseStatus(subTaskId);

        } catch (Exception e) {
            log.error("Pause dispatch failed: {}", subTaskId, e);
            handlePauseError(subTaskId, e);
        }
    }

    /**
     * 选择执行器
     */
    private ExecutorInfo selectExecutor(List<ExecutorInfo> executors, SubTask subTask) {
        // 1. 检查亲和性调度
        ExecutorInfo affinityExecutor = checkAffinitySchedule(executors, subTask);
        if (affinityExecutor != null) {
            return affinityExecutor;
        }

        // 2. 执行负载均衡
        return loadBalancer.select(executors, subTask);
    }

    /**
     * 执行分发
     */
    private void doDispatch(ExecutorInfo executor, SubTask subTask) {
        try {
            // 1. 构建分发请求
            DispatchRequest request = buildDispatchRequest(subTask);

            // 2. 发送到执行器
            executor.getClient().submitTask(request);

            // 3. 记录分发信息
            recordDispatchInfo(executor, subTask);

        } catch (Exception e) {
            log.error("Do dispatch failed: {}", subTask.getSubTaskId(), e);
            throw new DispatchException("Do dispatch failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量分发内部实现
     */
    private void dispatchBatchInternal(List<ExecutorInfo> executors, List<SubTask> batch) {
        // 1. 构建分发映射
        Map<ExecutorInfo, List<SubTask>> dispatchMap = new HashMap<>();
        
        // 2. 任务分组
        for (SubTask subTask : batch) {
            ExecutorInfo executor = selectExecutor(executors, subTask);
            dispatchMap.computeIfAbsent(executor, k -> new ArrayList<>())
                      .add(subTask);
        }

        // 3. 并行分发
        CompletableFuture.allOf(
            dispatchMap.entrySet().stream()
                .map(entry -> CompletableFuture.runAsync(() -> {
                    dispatchToExecutor(entry.getKey(), entry.getValue());
                }))
                .toArray(CompletableFuture[]::new)
        ).join();
    }

    /**
     * 分发到执行器
     */
    private void dispatchToExecutor(ExecutorInfo executor, List<SubTask> subTasks) {
        try {
            // 1. 构建批量请求
            BatchDispatchRequest request = buildBatchRequest(subTasks);

            // 2. 发送到执行器
            executor.getClient().submitBatch(request);

            // 3. 记录分发信息
            recordBatchDispatch(executor, subTasks);

        } catch (Exception e) {
            log.error("Dispatch to executor failed: {}", executor.getId(), e);
            handleExecutorDispatchError(executor, subTasks, e);
        }
    }

    /**
     * 检查亲和性调度
     */
    private ExecutorInfo checkAffinitySchedule(List<ExecutorInfo> executors, SubTask subTask) {
        // 1. 获取历史执行器
        String historyExecutorId = getHistoryExecutor(subTask);
        if (historyExecutorId == null) {
            return null;
        }

        // 2. 查找执行器
        return executors.stream()
            .filter(e -> e.getId().equals(historyExecutorId))
            .findFirst()
            .orElse(null);
    }

    /**
     * 记录分发信息
     */
    private void recordDispatchInfo(ExecutorInfo executor, SubTask subTask) {
        DispatchInfo info = DispatchInfo.builder()
            .subTaskId(subTask.getSubTaskId())
            .executorId(executor.getId())
            .dispatchTime(new Date())
            .build();
            
        stateManager.saveDispatchInfo(info);
    }

    /**
     * 更新分发状态
     */
    private void updateDispatchStatus(String subTaskId, ExecutorInfo executor) {
        try {
            // 1. 更新任务状态
            stateManager.updateSubTaskStatus(subTaskId, SubTaskStatus.DISPATCHED);

            // 2. 更新执行器状态
            executor.incrementTaskCount();
            executorRegistry.updateExecutor(executor);

        } catch (Exception e) {
            log.error("Update dispatch status failed", e);
        }
    }
}
```

这个分发器实现了以下主要功能：
1. 任务分发 - 将子任务分发到合适的执行器
2. 批量分发 - 支持批量任务的并行分发
3. 任务取消和暂停
4. 负载均衡和亲和性调度
5. 分发状态管理

接下来要实现LoadBalancer - 负载均衡器组件吗？这个组件负责执行器节点的负载均衡。
好的,让我们实现LoadBalancer - 负载均衡器组件。它负责在多个执行器节点间实现负载均衡。

```java
package com.platform.collect.core.scheduler.elastic;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 负载均衡器
 */
@Slf4j
@Component
public class LoadBalancer {

    @Autowired
    private ExecutorRegistry executorRegistry;

    @Autowired
    private MetricsCollector metricsCollector;

    // 负载均衡策略映射
    private final Map<String, LoadBalanceStrategy> strategyMap = new ConcurrentHashMap<>();

    /**
     * 初始化
     */
    @PostConstruct
    public void init() {
        // 注册负载均衡策略
        registerStrategies();
    }

    /**
     * 选择执行器
     */
    public ExecutorInfo select(List<ExecutorInfo> executors, SubTask subTask) {
        try {
            // 1. 过滤可用执行器
            List<ExecutorInfo> availableExecutors = filterAvailableExecutors(executors);
            if (CollectionUtils.isEmpty(availableExecutors)) {
                throw new NoAvailableExecutorException("No available executor");
            }

            // 2. 获取负载均衡策略
            LoadBalanceStrategy strategy = getStrategy(subTask);

            // 3. 选择执行器
            ExecutorInfo executor = strategy.select(availableExecutors, subTask);

            // 4. 记录选择结果
            recordSelection(executor, subTask);

            return executor;

        } catch (Exception e) {
            log.error("Select executor failed", e);
            throw new LoadBalanceException("Select executor failed: " + e.getMessage(), e);
        }
    }

    /**
     * 批量选择执行器
     */
    public Map<SubTask, ExecutorInfo> batchSelect(List<ExecutorInfo> executors, List<SubTask> subTasks) {
        try {
            // 1. 过滤可用执行器
            List<ExecutorInfo> availableExecutors = filterAvailableExecutors(executors);
            if (CollectionUtils.isEmpty(availableExecutors)) {
                throw new NoAvailableExecutorException("No available executor");
            }

            // 2. 执行批量选择
            Map<SubTask, ExecutorInfo> selectionMap = new HashMap<>();
            for (SubTask subTask : subTasks) {
                LoadBalanceStrategy strategy = getStrategy(subTask);
                ExecutorInfo executor = strategy.select(availableExecutors, subTask);
                selectionMap.put(subTask, executor);
                // 更新执行器负载
                updateExecutorLoad(executor);
            }

            // 3. 记录批量选择结果
            recordBatchSelection(selectionMap);

            return selectionMap;

        } catch (Exception e) {
            log.error("Batch select executor failed", e);
            throw new LoadBalanceException("Batch select executor failed: " + e.getMessage(), e);
        }
    }

    /**
     * 注册负载均衡策略
     */
    private void registerStrategies() {
        // 随机策略
        strategyMap.put("random", new RandomStrategy());
        
        // 轮询策略
        strategyMap.put("round_robin", new RoundRobinStrategy());
        
        // 最小负载策略
        strategyMap.put("least_load", new LeastLoadStrategy());
        
        // 一致性哈希策略
        strategyMap.put("consistent_hash", new ConsistentHashStrategy());

        log.info("Load balance strategies registered: {}", strategyMap.keySet());
    }

    /**
     * 过滤可用执行器
     */
    private List<ExecutorInfo> filterAvailableExecutors(List<ExecutorInfo> executors) {
        return executors.stream()
            .filter(this::isExecutorAvailable)
            .collect(Collectors.toList());
    }

    /**
     * 检查执行器是否可用
     */
    private boolean isExecutorAvailable(ExecutorInfo executor) {
        // 1. 检查状态
        if (executor.getStatus() != ExecutorStatus.ONLINE) {
            return false;
        }

        // 2. 检查负载
        if (executor.getLoad() >= executor.getMaxLoad()) {
            return false;
        }

        // 3. 检查健康状态
        return isExecutorHealthy(executor);
    }

    /**
     * 检查执行器健康状态
     */
    private boolean isExecutorHealthy(ExecutorInfo executor) {
        try {
            // 1. 获取健康检查结果
            HealthCheckResult result = executor.getClient().checkHealth();
            
            // 2. 检查CPU使用率
            if (result.getCpuUsage() > 80) {
                return false;
            }
            
            // 3. 检查内存使用率
            if (result.getMemoryUsage() > 80) {
                return false;
            }
            
            // 4. 检查响应时间
            if (result.getResponseTime() > 1000) {
                return false;
            }
            
            return true;
        } catch (Exception e) {
            log.warn("Check executor health failed: {}", executor.getId(), e);
            return false;
        }
    }

    /**
     * 获取负载均衡策略
     */
    private LoadBalanceStrategy getStrategy(SubTask subTask) {
        // 1. 获取策略配置
        String strategyName = subTask.getLoadBalanceStrategy();
        if (strategyName == null) {
            strategyName = "least_load"; // 默认策略
        }

        // 2. 获取策略实现
        LoadBalanceStrategy strategy = strategyMap.get(strategyName);
        if (strategy == null) {
            throw new IllegalArgumentException("Unknown strategy: " + strategyName);
        }

        return strategy;
    }

    /**
     * 更新执行器负载
     */
    private void updateExecutorLoad(ExecutorInfo executor) {
        // 1. 增加负载计数
        executor.incrementLoad();
        
        // 2. 更新注册表
        executorRegistry.updateExecutor(executor);
        
        // 3. 记录负载指标
        recordLoadMetrics(executor);
    }

    /**
     * 记录选择结果
     */
    private void recordSelection(ExecutorInfo executor, SubTask subTask) {
        SelectionRecord record = SelectionRecord.builder()
            .subTaskId(subTask.getSubTaskId())
            .executorId(executor.getId())
            .strategy(subTask.getLoadBalanceStrategy())
            .selectTime(new Date())
            .build();
            
        metricsCollector.recordSelection(record);
    }

    /**
     * 记录负载指标
     */
    private void recordLoadMetrics(ExecutorInfo executor) {
        try {
            // 记录执行器负载
            metricsCollector.recordValue(
                "executor.load." + executor.getId(),
                executor.getLoad()
            );
            
            // 记录总体负载分布
            metricsCollector.recordHistogram(
                "executor.load.distribution",
                executor.getLoad()
            );
        } catch (Exception e) {
            log.error("Record load metrics failed", e);
        }
    }
}
```

这个负载均衡器实现了以下主要功能：
1. 多种负载均衡策略支持(随机、轮询、最小负载、一致性哈希)
2. 执行器可用性检查和健康检查
3. 批量任务的负载均衡
4. 负载指标收集和监控
5. 选择结果记录和统计

接下来要实现其中的具体负载均衡策略吗？比如LeastLoadStrategy(最小负载策略)。
好的,让我们实现具体的负载均衡策略,先从LeastLoadStrategy(最小负载策略)开始。

```java
package com.platform.collect.core.scheduler.elastic.strategy;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 最小负载策略
 */
@Slf4j
@Component
public class LeastLoadStrategy implements LoadBalanceStrategy {

    @Override
    public ExecutorInfo select(List<ExecutorInfo> executors, SubTask subTask) {
        if (CollectionUtils.isEmpty(executors)) {
            throw new NoAvailableExecutorException("No executor available");
        }

        try {
            // 1. 获取负载指标
            Map<ExecutorInfo, Double> loadScores = calculateLoadScores(executors);

            // 2. 选择负载最小的执行器
            Optional<ExecutorInfo> selected = loadScores.entrySet().stream()
                .min(Map.Entry.comparingByValue())
                .map(Map.Entry::getKey);

            // 3. 返回选择结果
            if (selected.isPresent()) {
                return selected.get();
            }

            throw new LoadBalanceException("Failed to select executor by least load");

        } catch (Exception e) {
            log.error("Select executor by least load failed", e);
            throw new LoadBalanceException("Select executor failed: " + e.getMessage(), e);
        }
    }

    /**
     * 计算负载分数
     */
    private Map<ExecutorInfo, Double> calculateLoadScores(List<ExecutorInfo> executors) {
        Map<ExecutorInfo, Double> loadScores = new HashMap<>();
        
        for (ExecutorInfo executor : executors) {
            // 1. 计算CPU分数
            double cpuScore = calculateCpuScore(executor);
            
            // 2. 计算内存分数
            double memoryScore = calculateMemoryScore(executor);
            
            // 3. 计算任务数分数
            double taskScore = calculateTaskScore(executor);
            
            // 4. 计算网络分数
            double networkScore = calculateNetworkScore(executor);
            
            // 5. 计算综合分数
            double totalScore = calculateTotalScore(
                cpuScore, memoryScore, taskScore, networkScore);
                
            loadScores.put(executor, totalScore);
        }
        
        return loadScores;
    }

    /**
     * 计算CPU分数
     */
    private double calculateCpuScore(ExecutorInfo executor) {
        // CPU使用率 0-100%
        double cpuUsage = executor.getMetrics().getCpuUsage();
        // 转换为0-1的分数,使用率越高分数越高
        return cpuUsage / 100.0;
    }

    /**
     * 计算内存分数
     */
    private double calculateMemoryScore(ExecutorInfo executor) {
        // 内存使用率 0-100%
        double memoryUsage = executor.getMetrics().getMemoryUsage();
        // 转换为0-1的分数,使用率越高分数越高
        return memoryUsage / 100.0;
    }

    /**
     * 计算任务数分数
     */
    private double calculateTaskScore(ExecutorInfo executor) {
        // 当前任务数与最大任务数的比值
        int currentTasks = executor.getTaskCount();
        int maxTasks = executor.getMaxTaskCount();
        // 转换为0-1的分数,任务数越多分数越高
        return (double) currentTasks / maxTasks;
    }

    /**
     * 计算网络分数
     */
    private double calculateNetworkScore(ExecutorInfo executor) {
        // 网络延迟 (ms)
        double networkLatency = executor.getMetrics().getNetworkLatency();
        // 转换为0-1的分数,延迟越高分数越高
        double maxLatency = 1000.0; // 最大延迟1秒
        return Math.min(networkLatency / maxLatency, 1.0);
    }

    /**
     * 计算综合分数
     */
    private double calculateTotalScore(double cpuScore, double memoryScore, 
            double taskScore, double networkScore) {
        // 权重配置
        double cpuWeight = 0.3;
        double memoryWeight = 0.3;
        double taskWeight = 0.3;
        double networkWeight = 0.1;
        
        // 计算加权平均分数
        return cpuScore * cpuWeight +
               memoryScore * memoryWeight +
               taskScore * taskWeight +
               networkScore * networkWeight;
    }

    /**
     * 批量选择执行器
     */
    @Override
    public Map<SubTask, ExecutorInfo> batchSelect(List<ExecutorInfo> executors, List<SubTask> subTasks) {
        if (CollectionUtils.isEmpty(executors) || CollectionUtils.isEmpty(subTasks)) {
            throw new IllegalArgumentException("Executors or subTasks is empty");
        }

        try {
            Map<SubTask, ExecutorInfo> selectionMap = new HashMap<>();
            
            // 1. 获取初始负载分数
            Map<ExecutorInfo, Double> loadScores = calculateLoadScores(executors);
            
            // 2. 为每个任务选择执行器
            for (SubTask subTask : subTasks) {
                // 选择最小负载的执行器
                ExecutorInfo selected = loadScores.entrySet().stream()
                    .min(Map.Entry.comparingByValue())
                    .map(Map.Entry::getKey)
                    .orElseThrow(() -> new LoadBalanceException("No available executor"));
                    
                // 更新选择结果
                selectionMap.put(subTask, selected);
                
                // 更新负载分数
                updateLoadScore(loadScores, selected, subTask);
            }
            
            return selectionMap;

        } catch (Exception e) {
            log.error("Batch select executors failed", e);
            throw new LoadBalanceException("Batch select failed: " + e.getMessage(), e);
        }
    }

    /**
     * 更新负载分数
     */
    private void updateLoadScore(Map<ExecutorInfo, Double> loadScores, 
            ExecutorInfo executor, SubTask subTask) {
        // 1. 估算任务负载
        double taskLoad = estimateTaskLoad(subTask);
        
        // 2. 更新执行器负载分数
        double currentScore = loadScores.get(executor);
        double newScore = currentScore + taskLoad;
        loadScores.put(executor, newScore);
    }

    /**
     * 估算任务负载
     */
    private double estimateTaskLoad(SubTask subTask) {
        // 根据任务类型和规模估算负载
        TaskType type = subTask.getTaskType();
        int dataSize = subTask.getDataSize();
        
        double baseLoad = 0.1; // 基础负载
        double typeLoad = getTypeLoad(type); // 类型负载
        double sizeLoad = getSizeLoad(dataSize); // 规模负载
        
        return baseLoad + typeLoad + sizeLoad;
    }
}
```

这个最小负载策略实现了以下特点：

1. 多维度负载计算
    - CPU使用率
    - 内存使用率
    - 任务数量
    - 网络延迟

2. 加权分数计算
    - 综合考虑各维度权重
    - 得到最终负载分数

3. 批量任务处理
    - 支持批量任务分配
    - 动态更新负载分数
    - 基于任务特征估算负载

4. 负载预估
    - 基于任务类型估算
    - 考虑数据规模影响
    - 动态调整分配

接下来要实现ConsistentHashStrategy(一致性哈希策略)吗？用于保证相似任务的亲和性调度。
好的,让我们实现ConsistentHashStrategy(一致性哈希策略),用于保证相似任务的亲和性调度。

```java
package com.platform.collect.core.scheduler.elastic.strategy;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 一致性哈希负载均衡策略
 */
@Slf4j
@Component
public class ConsistentHashStrategy implements LoadBalanceStrategy {

    // 虚拟节点数
    private static final int VIRTUAL_NODE_COUNT = 256;
    
    // 虚拟节点与实际节点映射
    private final Map<Long, ExecutorInfo> ring = new ConcurrentSkipListMap<>();

    @Override
    public ExecutorInfo select(List<ExecutorInfo> executors, SubTask subTask) {
        if (CollectionUtils.isEmpty(executors)) {
            throw new NoAvailableExecutorException("No executor available");
        }

        try {
            // 1. 初始化哈希环
            initHashRing(executors);

            // 2. 计算任务哈希值
            long hash = calculateTaskHash(subTask);

            // 3. 选择执行器
            return selectExecutor(hash);

        } catch (Exception e) {
            log.error("Select executor by consistent hash failed", e);
            throw new LoadBalanceException("Select executor failed: " + e.getMessage(), e);
        }
    }

    /**
     * 初始化哈希环
     */
    private void initHashRing(List<ExecutorInfo> executors) {
        // 1. 清空当前环
        ring.clear();
        
        // 2. 为每个执行器创建虚拟节点
        for (ExecutorInfo executor : executors) {
            addExecutor(executor);
        }
    }

    /**
     * 添加执行器
     */
    private void addExecutor(ExecutorInfo executor) {
        // 为执行器创建虚拟节点
        for (int i = 0; i < VIRTUAL_NODE_COUNT; i++) {
            // 1. 构建虚拟节点标识
            String virtualNode = executor.getId() + "#" + i;
            
            // 2. 计算虚拟节点哈希值
            long hash = hash(virtualNode);
            
            // 3. 添加到哈希环
            ring.put(hash, executor);
        }
    }

    /**
     * 移除执行器
     */
    private void removeExecutor(ExecutorInfo executor) {
        // 移除执行器的所有虚拟节点
        for (int i = 0; i < VIRTUAL_NODE_COUNT; i++) {
            String virtualNode = executor.getId() + "#" + i;
            long hash = hash(virtualNode);
            ring.remove(hash);
        }
    }

    /**
     * 选择执行器
     */
    private ExecutorInfo selectExecutor(long hash) {
        if (ring.isEmpty()) {
            throw new NoAvailableExecutorException("Hash ring is empty");
        }

        // 1. 获取大于等于hash的第一个节点
        SortedMap<Long, ExecutorInfo> tailMap = ((ConcurrentSkipListMap<Long, ExecutorInfo>) ring).tailMap(hash);
        
        // 2. 如果没有大于等于hash的节点,则返回环首节点
        if (tailMap.isEmpty()) {
            return ring.get(ring.firstKey());
        }
        
        // 3. 返回最近的节点
        return tailMap.get(tailMap.firstKey());
    }

    /**
     * 计算任务哈希值
     */
    private long calculateTaskHash(SubTask subTask) {
        // 1. 获取任务亲和性标识
        String affinityId = getAffinityId(subTask);
        
        // 2. 计算哈希值
        return hash(affinityId);
    }

    /**
     * 获取任务亲和性标识
     */
    private String getAffinityId(SubTask subTask) {
        // 根据任务特征构建亲和性标识
        StringBuilder sb = new StringBuilder();
        
        // 1. 添加数据源标识
        if (subTask.getSourceId() != null) {
            sb.append(subTask.getSourceId());
        }
        
        // 2. 添加任务类型
        if (subTask.getTaskType() != null) {
            sb.append("#").append(subTask.getTaskType());
        }
        
        // 3. 添加自定义亲和性标识
        if (subTask.getAffinityId() != null) {
            sb.append("#").append(subTask.getAffinityId());
        }
        
        return sb.toString();
    }

    /**
     * 计算哈希值 
     */
    private long hash(String key) {
        // 使用MurmurHash算法
        return MurmurHash.hash64(key);
    }

    /**
     * 批量选择执行器
     */
    @Override
    public Map<SubTask, ExecutorInfo> batchSelect(List<ExecutorInfo> executors, List<SubTask> subTasks) {
        if (CollectionUtils.isEmpty(executors) || CollectionUtils.isEmpty(subTasks)) {
            throw new IllegalArgumentException("Executors or subTasks is empty");
        }

        try {
            // 1. 初始化哈希环
            initHashRing(executors);
            
            // 2. 批量选择执行器
            Map<SubTask, ExecutorInfo> selectionMap = new HashMap<>();
            for (SubTask subTask : subTasks) {
                // 计算任务哈希值
                long hash = calculateTaskHash(subTask);
                // 选择执行器
                ExecutorInfo executor = selectExecutor(hash);
                selectionMap.put(subTask, executor);
            }
            
            // 3. 验证分配结果
            validateSelection(selectionMap);
            
            return selectionMap;

        } catch (Exception e) {
            log.error("Batch select executors failed", e);
            throw new LoadBalanceException("Batch select failed: " + e.getMessage(), e);
        }
    }

    /**
     * 验证分配结果
     */
    private void validateSelection(Map<SubTask, ExecutorInfo> selectionMap) {
        // 1. 统计每个执行器分配的任务数
        Map<String, Integer> executorTaskCount = new HashMap<>();
        for (ExecutorInfo executor : selectionMap.values()) {
            executorTaskCount.merge(executor.getId(), 1, Integer::sum);
        }
        
        // 2. 检查分配是否均衡
        int avgCount = selectionMap.size() / executorTaskCount.size();
        for (Map.Entry<String, Integer> entry : executorTaskCount.entrySet()) {
            if (entry.getValue() > avgCount * 2) {
                log.warn("Executor {} is overloaded: {}", entry.getKey(), entry.getValue());
            }
        }
    }

    /**
     * 更新执行器
     */
    public void updateExecutor(ExecutorInfo executor) {
        // 1. 移除旧的虚拟节点
        removeExecutor(executor);
        
        // 2. 添加新的虚拟节点
        addExecutor(executor);
    }

    /**
     * 重新平衡
     */
    public Map<SubTask, ExecutorInfo> rebalance(List<ExecutorInfo> executors, 
            Map<SubTask, ExecutorInfo> currentMapping) {
        // 1. 重新初始化哈希环
        initHashRing(executors);
        
        // 2. 重新分配任务
        Map<SubTask, ExecutorInfo> newMapping = new HashMap<>();
        for (SubTask subTask : currentMapping.keySet()) {
            long hash = calculateTaskHash(subTask);
            ExecutorInfo executor = selectExecutor(hash);
            newMapping.put(subTask, executor);
        }
        
        // 3. 计算需要迁移的任务
        Map<SubTask, ExecutorInfo> migrationMap = calculateMigration(
            currentMapping, newMapping);
            
        return migrationMap;
    }
}
```

这个一致性哈希策略实现了以下特点：

1. 虚拟节点机制
    - 通过虚拟节点提高均衡性
    - 支持动态添加删除节点
    - 最小化节点变更影响

2. 亲和性保证
    - 基于任务特征计算哈希值
    - 相似任务调度到相同节点
    - 支持自定义亲和性标识

3. 动态伸缩
    - 支持执行器动态更新
    - 提供重平衡机制
    - 计算最小迁移任务

4. 负载均衡
    - 验证分配均衡性
    - 检测过载执行器
    - 支持批量任务分配

接下来要实现其他策略如RandomStrategy(随机策略)或RoundRobinStrategy(轮询策略)吗？
好的，让我们实现RandomStrategy(随机策略)和RoundRobinStrategy(轮询策略)。先来实现RandomStrategy：

```java
package com.platform.collect.core.scheduler.elastic.strategy;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 随机负载均衡策略
 */
@Slf4j
@Component
public class RandomStrategy implements LoadBalanceStrategy {

    // 随机数生成器
    private final Random random = new Random();
    
    // 权重缓存
    private final Map<String, Integer> weightCache = new ConcurrentHashMap<>();

    @Override
    public ExecutorInfo select(List<ExecutorInfo> executors, SubTask subTask) {
        if (CollectionUtils.isEmpty(executors)) {
            throw new NoAvailableExecutorException("No executor available");
        }

        try {
            // 1. 获取权重配置
            Map<ExecutorInfo, Integer> weights = getWeights(executors);

            // 2. 计算总权重
            int totalWeight = weights.values().stream()
                .mapToInt(Integer::intValue)
                .sum();

            // 3. 随机选择
            int offset = random.nextInt(totalWeight);
            for (Map.Entry<ExecutorInfo, Integer> entry : weights.entrySet()) {
                offset -= entry.getValue();
                if (offset < 0) {
                    return entry.getKey();
                }
            }

            // 4. 降级为普通随机
            return executors.get(random.nextInt(executors.size()));

        } catch (Exception e) {
            log.error("Select executor by random failed", e);
            throw new LoadBalanceException("Select executor failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取执行器权重
     */
    private Map<ExecutorInfo, Integer> getWeights(List<ExecutorInfo> executors) {
        Map<ExecutorInfo, Integer> weights = new HashMap<>();
        
        for (ExecutorInfo executor : executors) {
            // 1. 尝试从缓存获取
            Integer weight = weightCache.get(executor.getId());
            
            // 2. 缓存未命中则计算权重
            if (weight == null) {
                weight = calculateWeight(executor);
                weightCache.put(executor.getId(), weight);
            }
            
            weights.put(executor, weight);
        }
        
        return weights;
    }

    /**
     * 计算执行器权重
     */
    private int calculateWeight(ExecutorInfo executor) {
        // 基础权重
        int baseWeight = executor.getWeight();
        
        // 性能修正
        double cpuScore = (100 - executor.getMetrics().getCpuUsage()) / 100.0;
        double memoryScore = (100 - executor.getMetrics().getMemoryUsage()) / 100.0;
        double performanceScore = (cpuScore + memoryScore) / 2;
        
        // 计算最终权重
        return (int) (baseWeight * performanceScore);
    }

    /**
     * 批量选择执行器
     */
    @Override
    public Map<SubTask, ExecutorInfo> batchSelect(List<ExecutorInfo> executors, List<SubTask> subTasks) {
        if (CollectionUtils.isEmpty(executors) || CollectionUtils.isEmpty(subTasks)) {
            throw new IllegalArgumentException("Executors or subTasks is empty");
        }

        try {
            Map<SubTask, ExecutorInfo> selectionMap = new HashMap<>();
            
            // 1. 获取权重配置
            Map<ExecutorInfo, Integer> weights = getWeights(executors);
            
            // 2. 为每个任务随机选择执行器
            for (SubTask subTask : subTasks) {
                ExecutorInfo selected = doSelect(executors, weights);
                selectionMap.put(subTask, selected);
            }
            
            // 3. 检查分配结果
            validateDistribution(selectionMap);
            
            return selectionMap;

        } catch (Exception e) {
            log.error("Batch select executors failed", e);
            throw new LoadBalanceException("Batch select failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行选择
     */
    private ExecutorInfo doSelect(List<ExecutorInfo> executors, Map<ExecutorInfo, Integer> weights) {
        // 1. 计算总权重
        int totalWeight = weights.values().stream()
            .mapToInt(Integer::intValue)
            .sum();
            
        // 2. 随机选择
        int offset = random.nextInt(totalWeight);
        for (Map.Entry<ExecutorInfo, Integer> entry : weights.entrySet()) {
            offset -= entry.getValue();
            if (offset < 0) {
                return entry.getKey();
            }
        }
        
        // 3. 降级处理
        return executors.get(random.nextInt(executors.size()));
    }

    /**
     * 验证分配分布
     */
    private void validateDistribution(Map<SubTask, ExecutorInfo> selectionMap) {
        // 1. 统计分配结果
        Map<String, Integer> distribution = new HashMap<>();
        for (ExecutorInfo executor : selectionMap.values()) {
            distribution.merge(executor.getId(), 1, Integer::sum);
        }
        
        // 2. 计算标准差
        double mean = distribution.values().stream()
            .mapToInt(Integer::intValue)
            .average()
            .orElse(0.0);
            
        double variance = distribution.values().stream()
            .mapToInt(Integer::intValue)
            .mapToDouble(count -> Math.pow(count - mean, 2))
            .average()
            .orElse(0.0);
            
        double stddev = Math.sqrt(variance);
        
        // 3. 检查分布是否均匀
        if (stddev > mean * 0.5) {
            log.warn("Distribution is not balanced, stddev: {}, mean: {}", stddev, mean);
        }
    }

    /**
     * 更新执行器权重
     */
    public void updateWeight(String executorId, int weight) {
        weightCache.put(executorId, weight);
    }

    /**
     * 清除权重缓存
     */
    public void clearWeightCache() {
        weightCache.clear();
    }
}
```

接下来要实现RoundRobinStrategy(轮询策略)吗？它维护一个执行器序列，按顺序轮流选择执行器。
好的，让我们实现RoundRobinStrategy(轮询策略)：

```java
package com.platform.collect.core.scheduler.elastic.strategy;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 轮询负载均衡策略
 */
@Slf4j
@Component
public class RoundRobinStrategy implements LoadBalanceStrategy {

    // 执行器序号记录
    private final AtomicInteger sequence = new AtomicInteger(0);
    
    // 权重轮询计数器
    private final Map<String, WeightedRound> weightedRounds = new ConcurrentHashMap<>();

    @Override
    public ExecutorInfo select(List<ExecutorInfo> executors, SubTask subTask) {
        if (CollectionUtils.isEmpty(executors)) {
            throw new NoAvailableExecutorException("No executor available");
        }

        try {
            // 1. 检查是否使用权重轮询
            if (isWeightedRoundRobin(executors)) {
                return selectByWeight(executors);
            }

            // 2. 普通轮询选择
            return selectByRoundRobin(executors);

        } catch (Exception e) {
            log.error("Select executor by round robin failed", e);
            throw new LoadBalanceException("Select executor failed: " + e.getMessage(), e);
        }
    }

    /**
     * 普通轮询选择
     */
    private ExecutorInfo selectByRoundRobin(List<ExecutorInfo> executors) {
        // 1. 获取当前序号
        int current = sequence.getAndIncrement();
        
        // 2. 计算索引
        int index = current % executors.size();
        
        // 3. 选择执行器
        return executors.get(index);
    }

    /**
     * 权重轮询选择
     */
    private ExecutorInfo selectByWeight(List<ExecutorInfo> executors) {
        // 1. 获取权重轮询器
        String key = generateKey(executors);
        WeightedRound weightedRound = weightedRounds.computeIfAbsent(
            key, k -> new WeightedRound(executors));
            
        // 2. 执行选择
        return weightedRound.select();
    }

    /**
     * 权重轮询器
     */
    private static class WeightedRound {
        // 执行器列表
        private final List<ExecutorInfo> executors;
        // 权重配置
        private final Map<ExecutorInfo, Integer> weights;
        // 当前权重
        private final Map<ExecutorInfo, AtomicInteger> currentWeights;
        // 总权重
        private final int totalWeight;
        
        public WeightedRound(List<ExecutorInfo> executors) {
            this.executors = executors;
            this.weights = calculateWeights(executors);
            this.currentWeights = initCurrentWeights(executors);
            this.totalWeight = weights.values().stream()
                .mapToInt(Integer::intValue)
                .sum();
        }
        
        /**
         * 选择执行器
         */
        public synchronized ExecutorInfo select() {
            // 1. 获取最大权重执行器
            ExecutorInfo selected = null;
            int maxWeight = Integer.MIN_VALUE;
            
            for (ExecutorInfo executor : executors) {
                int weight = currentWeights.get(executor).get();
                if (weight > maxWeight) {
                    maxWeight = weight;
                    selected = executor;
                }
            }
            
            // 2. 更新当前权重
            for (ExecutorInfo executor : executors) {
                AtomicInteger current = currentWeights.get(executor);
                if (executor.equals(selected)) {
                    current.addAndGet(-totalWeight);
                }
                current.addAndGet(weights.get(executor));
            }
            
            return selected;
        }
    }

    /**
     * 批量选择执行器
     */
    @Override
    public Map<SubTask, ExecutorInfo> batchSelect(List<ExecutorInfo> executors, List<SubTask> subTasks) {
        if (CollectionUtils.isEmpty(executors) || CollectionUtils.isEmpty(subTasks)) {
            throw new IllegalArgumentException("Executors or subTasks is empty");
        }

        try {
            Map<SubTask, ExecutorInfo> selectionMap = new HashMap<>();
            
            // 1. 确定轮询方式
            boolean useWeighted = isWeightedRoundRobin(executors);
            WeightedRound weightedRound = null;
            if (useWeighted) {
                weightedRound = new WeightedRound(executors);
            }
            
            // 2. 为每个任务选择执行器
            for (SubTask subTask : subTasks) {
                ExecutorInfo selected = useWeighted ? 
                    weightedRound.select() : 
                    selectByRoundRobin(executors);
                selectionMap.put(subTask, selected);
            }
            
            // 3. 验证分配结果
            validateDistribution(selectionMap, executors);
            
            return selectionMap;

        } catch (Exception e) {
            log.error("Batch select executors failed", e);
            throw new LoadBalanceException("Batch select failed: " + e.getMessage(), e);
        }
    }

    /**
     * 检查是否使用权重轮询
     */
    private boolean isWeightedRoundRobin(List<ExecutorInfo> executors) {
        return executors.stream()
            .anyMatch(e -> e.getWeight() != DEFAULT_WEIGHT);
    }

    /**
     * 计算执行器权重
     */
    private Map<ExecutorInfo, Integer> calculateWeights(List<ExecutorInfo> executors) {
        Map<ExecutorInfo, Integer> weights = new HashMap<>();
        for (ExecutorInfo executor : executors) {
            int weight = calculateWeight(executor);
            weights.put(executor, weight);
        }
        return weights;
    }

    /**
     * 初始化当前权重
     */
    private Map<ExecutorInfo, AtomicInteger> initCurrentWeights(List<ExecutorInfo> executors) {
        Map<ExecutorInfo, AtomicInteger> currentWeights = new HashMap<>();
        for (ExecutorInfo executor : executors) {
            currentWeights.put(executor, new AtomicInteger(0));
        }
        return currentWeights;
    }

    /**
     * 计算单个执行器权重
     */
    private int calculateWeight(ExecutorInfo executor) {
        // 1. 基础权重
        int baseWeight = executor.getWeight();
        
        // 2. 性能权重
        double cpuScore = (100 - executor.getMetrics().getCpuUsage()) / 100.0;
        double memoryScore = (100 - executor.getMetrics().getMemoryUsage()) / 100.0;
        double performanceScore = (cpuScore + memoryScore) / 2;
        
        // 3. 计算最终权重
        return (int) (baseWeight * performanceScore);
    }

    /**
     * 验证分配分布
     */
    private void validateDistribution(Map<SubTask, ExecutorInfo> selectionMap, 
            List<ExecutorInfo> executors) {
        // 1. 统计分配结果
        Map<String, Integer> distribution = new HashMap<>();
        for (ExecutorInfo executor : selectionMap.values()) {
            distribution.merge(executor.getId(), 1, Integer::sum);
        }
        
        // 2. 检查分布是否均匀
        int totalTasks = selectionMap.size();
        int executorCount = executors.size();
        int expectedTasks = totalTasks / executorCount;
        
        for (Map.Entry<String, Integer> entry : distribution.entrySet()) {
            int diff = Math.abs(entry.getValue() - expectedTasks);
            if (diff > 1) {
                log.warn("Uneven distribution for executor: {}, tasks: {}, expected: {}", 
                    entry.getKey(), entry.getValue(), expectedTasks);
            }
        }
    }
}
```

这个轮询策略实现了以下特点：

1. 支持两种轮询模式
    - 普通轮询(Round Robin)
    - 加权轮询(Weighted Round Robin)

2. 权重动态调整
    - 基于执行器基础权重
    - 考虑性能指标影响
    - 支持动态更新权重

3. 平滑加权轮询
    - 使用平滑权重算法
    - 避免切换抖动
    - 保证分配均匀性

4. 分布验证
    - 检查任务分布
    - 监控分配均匀性
    - 告警异常分布

接下来我们要实现TaskExecutor(任务执行器)吗？它负责具体任务的执行和生命周期管理。
好的，让我们实现TaskExecutor(任务执行器)。它负责具体任务的执行和生命周期管理。

```java
package com.platform.collect.core.executor;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * 任务执行器
 */
@Slf4j
@Component
public class TaskExecutor {

    @Autowired
    private CollectorFactory collectorFactory;

    @Autowired
    private ProcessorChain processorChain;
    
    @Autowired
    private StateManager stateManager;

    @Autowired 
    private MetricsCollector metricsCollector;

    // 执行上下文缓存
    private final Map<String, ExecuteContext> contextCache = new ConcurrentHashMap<>();

    /**
     * 执行任务
     */
    public void execute(SubTask subTask) {
        String taskId = subTask.getSubTaskId();
        log.info("Start execute task: {}", taskId);

        ExecuteContext context = null;
        try {
            // 1. 创建执行上下文
            context = createContext(subTask);
            contextCache.put(taskId, context);

            // 2. 执行任务
            doExecute(context);

            // 3. 处理执行结果
            handleSuccess(context);

        } catch (Exception e) {
            log.error("Execute task failed: {}", taskId, e);
            handleError(context, e);
        } finally {
            // 4. 清理上下文
            contextCache.remove(taskId);
        }
    }

    /**
     * 停止任务
     */
    public void stop(String taskId) {
        log.info("Stop task: {}", taskId);

        try {
            // 1. 获取执行上下文
            ExecuteContext context = contextCache.get(taskId);
            if (context == null) {
                log.warn("Task context not found: {}", taskId);
                return;
            }

            // 2. 执行停止
            doStop(context);

            // 3. 更新状态
            updateStopStatus(taskId);

        } catch (Exception e) {
            log.error("Stop task failed: {}", taskId, e);
        }
    }

    /**
     * 获取任务状态
     */
    public TaskStatus getStatus(String taskId) {
        // 1. 检查上下文
        ExecuteContext context = contextCache.get(taskId);
        if (context != null) {
            return context.getStatus();
        }

        // 2. 查询状态记录
        return stateManager.getTaskStatus(taskId);
    }

    /**
     * 执行任务
     */
    private void doExecute(ExecuteContext context) throws Exception {
        // 1. 更新状态为执行中
        updateStatus(context, TaskStatus.RUNNING);

        // 2. 获取采集器
        Collector collector = collectorFactory.getCollector(context.getCollectType());

        // 3. 执行数据采集
        CollectResult collectResult = collector.collect(context);
        context.setCollectResult(collectResult);

        // 4. 执行数据处理
        ProcessResult processResult = processorChain.process(context);
        context.setProcessResult(processResult);

        // 5. 更新执行进度
        updateProgress(context);
    }

    /**
     * 停止任务执行
     */
    private void doStop(ExecuteContext context) throws Exception {
        // 1. 停止采集器
        Collector collector = collectorFactory.getCollector(context.getCollectType());
        collector.stop(context);

        // 2. 停止处理器链
        processorChain.stop(context);

        // 3. 更新状态
        updateStatus(context, TaskStatus.STOPPED);
    }

    /**
     * 创建执行上下文
     */
    private ExecuteContext createContext(SubTask subTask) {
        return ExecuteContext.builder()
            .taskId(subTask.getSubTaskId())
            .parentTaskId(subTask.getParentTaskId())
            .collectType(subTask.getCollectType())
            .config(subTask.getConfig())
            .createTime(new Date())
            .build();
    }

    /**
     * 处理执行成功
     */
    private void handleSuccess(ExecuteContext context) {
        try {
            // 1. 更新状态
            updateStatus(context, TaskStatus.COMPLETED);

            // 2. 保存执行结果
            saveExecuteResult(context);

            // 3. 发送成功事件
            publishSuccessEvent(context);

            // 4. 记录统计信息
            recordMetrics(context, true);

        } catch (Exception e) {
            log.error("Handle success failed", e);
        }
    }

    /**
     * 处理执行错误
     */
    private void handleError(ExecuteContext context, Exception e) {
        try {
            // 1. 更新状态
            updateStatus(context, TaskStatus.FAILED);

            // 2. 保存错误信息
            saveErrorInfo(context, e);

            // 3. 发送失败事件
            publishFailEvent(context, e);

            // 4. 记录统计信息
            recordMetrics(context, false);

        } catch (Exception ex) {
            log.error("Handle error failed", ex);
        }
    }

    /**
     * 更新执行状态
     */
    private void updateStatus(ExecuteContext context, TaskStatus status) {
        context.setStatus(status);
        stateManager.updateTaskStatus(context.getTaskId(), status);
    }

    /**
     * 更新执行进度
     */
    private void updateProgress(ExecuteContext context) {
        TaskProgress progress = TaskProgress.builder()
            .taskId(context.getTaskId())
            .total(context.getCollectResult().getTotal())
            .current(context.getProcessResult().getProcessed())
            .updateTime(new Date())
            .build();
            
        stateManager.updateTaskProgress(progress);
    }

    /**
     * 记录统计信息
     */
    private void recordMetrics(ExecuteContext context, boolean success) {
        TaskMetrics metrics = TaskMetrics.builder()
            .taskId(context.getTaskId())
            .collectType(context.getCollectType())
            .startTime(context.getCreateTime())
            .endTime(new Date())
            .success(success)
            .dataCount(context.getCollectResult().getTotal())
            .processedCount(context.getProcessResult().getProcessed())
            .build();
            
        metricsCollector.recordTaskMetrics(metrics);
    }

    /**
     * 获取正在执行的任务
     */
    public List<String> getRunningTasks() {
        return new ArrayList<>(contextCache.keySet());
    }

    /**
     * 获取任务进度
     */
    public TaskProgress getProgress(String taskId) {
        return stateManager.getTaskProgress(taskId);
    }
}
```

主要实现了以下功能：

1. 任务生命周期管理
    - 执行任务
    - 停止任务
    - 状态查询
    - 进度更新

2. 执行流程控制
    - 创建执行上下文
    - 调用采集器采集数据
    - 调用处理器链处理数据
    - 处理执行结果

3. 状态和进度管理
    - 状态变更记录
    - 进度信息更新
    - 执行结果保存
    - 错误信息记录

4. 监控和统计
    - 执行指标采集
    - 统计信息记录
    - 事件通知发布
    - 运行状态监控

接下来要实现ExecuteContext(执行上下文)吗？它负责维护任务执行过程中的上下文信息。
好的，让我们实现ExecuteContext(执行上下文)，用于维护任务执行过程中的所有相关信息。

```java
package com.platform.collect.core.executor.context;

import lombok.Builder;
import lombok.Data;
import lombok.extern.slf4j.Slf4j;
import java.util.concurrent.ConcurrentHashMap;

/**
 * 执行上下文
 */
@Slf4j
@Data
@Builder
public class ExecuteContext {

    // 任务基本信息
    private String taskId;                  // 任务ID
    private String parentTaskId;            // 父任务ID
    private CollectType collectType;        // 采集类型
    private TaskConfig config;              // 任务配置
    private Date createTime;                // 创建时间
    private TaskStatus status;              // 执行状态
    
    // 执行数据
    private CollectResult collectResult;    // 采集结果
    private ProcessResult processResult;    // 处理结果
    
    // 执行控制
    private volatile boolean stopped;       // 是否已停止
    private final CountDownLatch completeLatch = new CountDownLatch(1); // 完成锁
    
    // 执行状态
    private ExecuteStats stats;            // 执行统计
    private List<ExecuteError> errors;     // 错误记录
    
    // 上下文数据
    private final Map<String, Object> attributes = new ConcurrentHashMap<>();

    /**
     * 初始化上下文
     */
    public void init() {
        // 初始化状态
        this.status = TaskStatus.CREATED;
        this.stopped = false;
        
        // 初始化统计
        this.stats = ExecuteStats.builder()
            .taskId(taskId)
            .startTime(new Date())
            .build();
            
        // 初始化错误列表
        this.errors = new ArrayList<>();
    }

    /**
     * 设置属性
     */
    public void setAttribute(String key, Object value) {
        attributes.put(key, value);
    }

    /**
     * 获取属性
     */
    @SuppressWarnings("unchecked")
    public <T> T getAttribute(String key) {
        return (T) attributes.get(key);
    }

    /**
     * 移除属性
     */
    public void removeAttribute(String key) {
        attributes.remove(key);
    }

    /**
     * 标记停止
     */
    public void markStopped() {
        this.stopped = true;
    }

    /**
     * 检查是否已停止
     */
    public boolean isStopped() {
        return stopped;
    }

    /**
     * 等待完成
     */
    public boolean await(long timeout, TimeUnit unit) throws InterruptedException {
        return completeLatch.await(timeout, unit);
    }

    /**
     * 标记完成
     */
    public void markCompleted() {
        completeLatch.countDown();
    }

    /**
     * 记录错误
     */
    public void recordError(Throwable error) {
        ExecuteError executeError = ExecuteError.builder()
            .taskId(taskId)
            .phase(status.name())
            .errorType(error.getClass().getSimpleName())
            .errorMessage(error.getMessage())
            .timestamp(new Date())
            .build();
            
        errors.add(executeError);
    }

    /**
     * 更新执行统计
     */
    public void updateStats() {
        stats.setEndTime(new Date());
        stats.setDuration(System.currentTimeMillis() - stats.getStartTime().getTime());
        
        if (collectResult != null) {
            stats.setTotalCount(collectResult.getTotal());
            stats.setSuccessCount(collectResult.getSuccess());
            stats.setFailCount(collectResult.getFailed());
        }
        
        if (processResult != null) {
            stats.setProcessedCount(processResult.getProcessed());
            stats.setFilteredCount(processResult.getFiltered());
            stats.setErrorCount(processResult.getErrors());
        }
    }

    /**
     * 获取执行耗时(毫秒)
     */
    public long getDuration() {
        return System.currentTimeMillis() - createTime.getTime();
    }

    /**
     * 构建进度信息
     */
    public TaskProgress buildProgress() {
        return TaskProgress.builder()
            .taskId(taskId)
            .total(collectResult != null ? collectResult.getTotal() : 0)
            .current(processResult != null ? processResult.getProcessed() : 0)
            .updateTime(new Date())
            .build();
    }

    /**
     * 构建结果信息
     */
    public TaskResult buildResult() {
        return TaskResult.builder()
            .taskId(taskId)
            .status(status)
            .startTime(createTime)
            .endTime(new Date())
            .duration(getDuration())
            .stats(stats)
            .errors(errors)
            .build();
    }

    /**
     * 克隆上下文
     */
    public ExecuteContext clone() {
        return ExecuteContext.builder()
            .taskId(taskId)
            .parentTaskId(parentTaskId)
            .collectType(collectType)
            .config(config.clone())
            .createTime(createTime)
            .status(status)
            .build();
    }

    /**
     * 执行统计
     */
    @Data
    @Builder
    public static class ExecuteStats {
        private String taskId;          // 任务ID
        private Date startTime;         // 开始时间
        private Date endTime;           // 结束时间
        private long duration;          // 执行时长
        private long totalCount;        // 总数据量
        private long successCount;      // 成功数量
        private long failCount;         // 失败数量
        private long processedCount;    // 处理数量
        private long filteredCount;     // 过滤数量
        private long errorCount;        // 错误数量
    }

    /**
     * 执行错误
     */
    @Data
    @Builder  
    public static class ExecuteError {
        private String taskId;          // 任务ID
        private String phase;           // 执行阶段
        private String errorType;       // 错误类型
        private String errorMessage;    // 错误信息
        private Date timestamp;         // 错误时间
    }
}
```

这个执行上下文实现了以下主要功能：

1. 基本信息管理
    - 任务标识信息
    - 配置参数
    - 执行状态
    - 时间信息

2. 数据存储
    - 采集结果
    - 处理结果
    - 属性数据
    - 错误记录

3. 执行控制
    - 停止标记
    - 完成等待
    - 状态变更
    - 进度更新

4. 统计功能
    - 执行统计
    - 错误记录
    - 性能指标
    - 结果构建

接下来要实现Collector(采集器)接口和AbstractCollector(采集器基类)吗？它们是采集功能的核心抽象。
好的，让我们实现ListCollector(列表数据采集器)。

```java
package com.platform.collect.core.collector.list;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 列表数据采集器
 */
@Slf4j
@Component
public class ListCollector extends AbstractCollector {

    // 分页配置
    private static final int DEFAULT_PAGE_SIZE = 500;
    private static final int MAX_PAGE_SIZE = 2000;

    // 并发配置
    private static final int DEFAULT_CONCURRENT = 3;
    private static final int MAX_CONCURRENT = 10;

    // 采集执行器
    private final ExecutorService executor;

    public ListCollector() {
        this.executor = new ThreadPoolExecutor(
            DEFAULT_CONCURRENT,
            MAX_CONCURRENT,
            60L,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(1000),
            new NamedThreadFactory("list-collector-"),
            new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }

    @Override
    protected CollectResult doCollect(ExecuteContext context) throws Exception {
        // 1. 获取数据总数
        int totalCount = getTotalCount(context);
        if (totalCount == 0) {
            return CollectResult.empty();
        }

        // 2. 设置采集进度
        context.setAttribute("total.count", totalCount);
        updateProgress(context, 0, totalCount);

        // 3. 计算分页参数
        int pageSize = getPageSize(context);
        int totalPages = (totalCount + pageSize - 1) / pageSize;

        // 4. 并发采集数据
        List<ListData> allData = Collections.synchronizedList(new ArrayList<>());
        List<CompletableFuture<Void>> futures = new ArrayList<>();

        for (int pageNum = 1; pageNum <= totalPages; pageNum++) {
            // 检查是否停止
            if (context.isStopped()) {
                break;
            }

            // 创建分页任务
            final int currentPage = pageNum;
            CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {
                collectPage(context, currentPage, pageSize, allData);
            }, executor);

            futures.add(future);
        }

        // 5. 等待采集完成
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).get();

        // 6. 构建采集结果
        return buildCollectResult(allData);
    }

    /**
     * 采集分页数据
     */
    private void collectPage(ExecuteContext context, int pageNum, int pageSize, List<ListData> allData) {
        try {
            // 1. 执行分页查询
            List<ListData> pageData = queryPageData(context, pageNum, pageSize);
            if (!CollectionUtils.isEmpty(pageData)) {
                allData.addAll(pageData);
            }

            // 2. 更新进度
            updateProgress(context, pageData.size());

        } catch (Exception e) {
            log.error("Collect page data failed, pageNum: {}", pageNum, e);
            handlePageError(context, pageNum, e);
        }
    }

    /**
     * 获取数据总数
     */
    private int getTotalCount(ExecuteContext context) throws Exception {
        ListCollectConfig config = (ListCollectConfig) context.getConfig();
        DataSourceConnection conn = context.getAttribute("connection");

        try {
            // 1. 准备查询参数
            Map<String, Object> params = new HashMap<>(config.getParams());

            // 2. 执行统计查询
            return conn.queryForObject(config.getCountQuery(), params, Integer.class);

        } catch (Exception e) {
            log.error("Get total count failed", e);
            throw new CollectException("Get total count failed: " + e.getMessage(), e);
        }
    }

    /**
     * 查询分页数据
     */
    private List<ListData> queryPageData(ExecuteContext context, int pageNum, int pageSize) throws Exception {
        ListCollectConfig config = (ListCollectConfig) context.getConfig();
        DataSourceConnection conn = context.getAttribute("connection");

        try {
            // 1. 准备分页参数
            Map<String, Object> params = new HashMap<>(config.getParams());
            params.put("offset", (pageNum - 1) * pageSize);
            params.put("limit", pageSize);
            params.put("pageNum", pageNum);
            params.put("pageSize", pageSize);

            // 2. 执行分页查询
            return conn.queryForList(config.getDataQuery(), params, ListData.class);

        } catch (Exception e) {
            log.error("Query page data failed, pageNum: {}", pageNum, e);
            throw new CollectException("Query page data failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取分页大小
     */
    private int getPageSize(ExecuteContext context) {
        ListCollectConfig config = (ListCollectConfig) context.getConfig();
        
        // 使用配置的分页大小
        int pageSize = config.getPageSize();
        if (pageSize <= 0) {
            pageSize = DEFAULT_PAGE_SIZE;
        }
        
        // 限制最大分页
        return Math.min(pageSize, MAX_PAGE_SIZE);
    }

    /**
     * 更新采集进度
     */
    private void updateProgress(ExecuteContext context, int increment) {
        try {
            CollectProgress progress = context.getAttribute("collect.progress");
            if (progress == null) {
                int total = context.getAttribute("total.count");
                progress = new CollectProgress(total);
                context.setAttribute("collect.progress", progress);
            }

            progress.increment(increment);
            updateProgress(context, progress.getCurrent(), progress.getTotal());

        } catch (Exception e) {
            log.error("Update progress failed", e);
        }
    }

    /**
     * 处理分页错误
     */
    private void handlePageError(ExecuteContext context, int pageNum, Exception e) {
        try {
            // 1. 记录错误信息
            PageError error = PageError.builder()
                .taskId(context.getTaskId())
                .pageNum(pageNum)
                .error(e.getMessage())
                .timestamp(new Date())
                .build();
            context.setAttribute("page.errors", error);

            // 2. 更新错误统计
            PageErrorStats errorStats = context.getAttribute("error.stats");
            if (errorStats == null) {
                errorStats = new PageErrorStats();
                context.setAttribute("error.stats", errorStats);
            }
            errorStats.incrementError();

        } catch (Exception ex) {
            log.error("Handle page error failed", ex);
        }
    }

    /**
     * 构建采集结果
     */
    private CollectResult buildCollectResult(List<ListData> allData) {
        return CollectResult.builder()
            .success(true)
            .total(allData.size())
            .data(allData)
            .build();
    }

    @Override
    protected void doStop(ExecuteContext context) {
        // 已通过context.isStopped()控制停止
    }

    @Override
    public CollectType getType() {
        return CollectType.LIST;
    }

    @Override
    public void validateConfig(CollectConfig config) throws ConfigException {
        if (!(config instanceof ListCollectConfig)) {
            throw new ConfigException("Invalid config type: " + config.getClass());
        }

        ListCollectConfig listConfig = (ListCollectConfig) config;
        if (StringUtils.isEmpty(listConfig.getCountQuery())) {
            throw new ConfigException("Count query is required");
        }
        if (StringUtils.isEmpty(listConfig.getDataQuery())) {
            throw new ConfigException("Data query is required");
        }
    }
}
```

主要特点：

1. 分页采集
    - 统计总数
    - 计算分页
    - 分页大小控制

2. 并发处理
    - 多线程分页采集
    - 线程池管理
    - 并发度控制

3. 进度管理
    - 实时进度更新
    - 分页进度记录
    - 总体进度统计

4. 错误处理
    - 分页级错误处理
    - 错误统计记录
    - 结果状态管理

接下来要实现CompoundCollector(复合采集器)吗？它可以组合多个采集器来完成复杂的采集任务。
好的，让我们实现CompoundCollector(复合采集器)，用于组合多个采集器处理复杂的采集任务。

```java
package com.platform.collect.core.collector.compound;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 复合采集器
 */
@Slf4j
@Component
public class CompoundCollector extends AbstractCollector {

    @Autowired
    private CollectorFactory collectorFactory;

    // 子采集器执行器
    private final ExecutorService executor;

    public CompoundCollector() {
        this.executor = new ThreadPoolExecutor(
            5, 
            10,
            60L, 
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(1000),
            new NamedThreadFactory("compound-collector-"),
            new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }

    @Override
    protected CollectResult doCollect(ExecuteContext context) throws Exception {
        // 1. 获取采集配置
        CompoundCollectConfig config = (CompoundCollectConfig) context.getConfig();
        List<CollectorConfig> collectorConfigs = config.getCollectorConfigs();

        // 2. 创建子采集器上下文
        List<CollectorContext> collectorContexts = createCollectorContexts(context, collectorConfigs);

        // 3. 并发执行子采集器
        CompletableFuture<CollectResult>[] futures = collectorContexts.stream()
            .map(ctx -> CompletableFuture.supplyAsync(() -> 
                executeCollector(ctx), executor))
            .toArray(CompletableFuture[]::new);

        // 4. 等待所有采集完成
        CompletableFuture.allOf(futures).get();

        // 5. 合并采集结果
        return mergeResults(futures);
    }

    /**
     * 创建子采集器上下文
     */
    private List<CollectorContext> createCollectorContexts(ExecuteContext context, 
            List<CollectorConfig> configs) {
        List<CollectorContext> contexts = new ArrayList<>();
        
        for (CollectorConfig config : configs) {
            try {
                // 1. 获取子采集器
                Collector collector = collectorFactory.getCollector(config.getType());
                
                // 2. 创建子上下文
                ExecuteContext subContext = context.clone();
                subContext.setConfig(config);
                
                // 3. 构建采集器上下文
                CollectorContext collectorContext = CollectorContext.builder()
                    .collector(collector)
                    .context(subContext)
                    .build();
                    
                contexts.add(collectorContext);
                
            } catch (Exception e) {
                log.error("Create collector context failed", e);
                handleContextError(context, config, e);
            }
        }
        
        return contexts;
    }

    /**
     * 执行子采集器
     */
    private CollectResult executeCollector(CollectorContext ctx) {
        try {
            // 1. 检查是否已停止
            if (ctx.getContext().isStopped()) {
                return CollectResult.empty();
            }

            // 2. 执行采集
            return ctx.getCollector().collect(ctx.getContext());

        } catch (Exception e) {
            log.error("Execute collector failed", e);
            handleCollectorError(ctx, e);
            return CollectResult.failed(e.getMessage());
        }
    }

    /**
     * 合并采集结果
     */
    private CollectResult mergeResults(CompletableFuture<CollectResult>[] futures) {
        // 1. 构建合并结果
        CompoundCollectResult result = new CompoundCollectResult();
        
        // 2. 合并子结果
        for (CompletableFuture<CollectResult> future : futures) {
            try {
                CollectResult subResult = future.get();
                result.addSubResult(subResult);
            } catch (Exception e) {
                log.error("Get collector result failed", e);
            }
        }
        
        return result;
    }

    /**
     * 处理上下文创建错误
     */
    private void handleContextError(ExecuteContext context, CollectorConfig config, Exception e) {
        try {
            // 1. 记录错误信息
            ContextError error = ContextError.builder()
                .taskId(context.getTaskId())
                .collectorType(config.getType())
                .error(e.getMessage())
                .timestamp(new Date())
                .build();
            context.setAttribute("context.errors", error);

            // 2. 更新错误统计
            ErrorStats errorStats = context.getAttribute("error.stats");
            if (errorStats == null) {
                errorStats = new ErrorStats();
                context.setAttribute("error.stats", errorStats);
            }
            errorStats.incrementContextError();

        } catch (Exception ex) {
            log.error("Handle context error failed", ex);
        }
    }

    /**
     * 处理采集器执行错误
     */
    private void handleCollectorError(CollectorContext ctx, Exception e) {
        try {
            // 1. 记录错误信息
            CollectorError error = CollectorError.builder()
                .taskId(ctx.getContext().getTaskId())
                .collectorType(ctx.getCollector().getType())
                .error(e.getMessage())
                .timestamp(new Date())
                .build();
            ctx.getContext().setAttribute("collector.errors", error);

            // 2. 更新错误统计
            ErrorStats errorStats = ctx.getContext().getAttribute("error.stats");
            if (errorStats == null) {
                errorStats = new ErrorStats();
                ctx.getContext().setAttribute("error.stats", errorStats);
            }
            errorStats.incrementCollectorError();

        } catch (Exception ex) {
            log.error("Handle collector error failed", ex);
        }
    }

    @Override
    protected void doStop(ExecuteContext context) {
        // 停止所有子采集器
        List<CollectorContext> contexts = context.getAttribute("collector.contexts");
        if (contexts != null) {
            for (CollectorContext ctx : contexts) {
                try {
                    ctx.getCollector().stop(ctx.getContext());
                } catch (Exception e) {
                    log.error("Stop collector failed", e);
                }
            }
        }
    }

    @Override
    public CollectType getType() {
        return CollectType.COMPOUND;
    }

    @Override
    public void validateConfig(CollectConfig config) throws ConfigException {
        if (!(config instanceof CompoundCollectConfig)) {
            throw new ConfigException("Invalid config type: " + config.getClass());
        }

        CompoundCollectConfig compoundConfig = (CompoundCollectConfig) config;
        if (CollectionUtils.isEmpty(compoundConfig.getCollectorConfigs())) {
            throw new ConfigException("Collector configs is required");
        }

        // 验证子配置
        for (CollectorConfig collectorConfig : compoundConfig.getCollectorConfigs()) {
            Collector collector = collectorFactory.getCollector(collectorConfig.getType());
            collector.validateConfig(collectorConfig);
        }
    }

    /**
     * 采集器上下文
     */
    @Data
    @Builder
    private static class CollectorContext {
        private Collector collector;
        private ExecuteContext context;
    }
}
```

主要特点：

1. 组合采集
    - 支持多个子采集器
    - 配置独立管理
    - 结果合并处理

2. 并发执行
    - 子采集器并发执行
    - 线程池管理
    - 异步结果处理

3. 上下文管理
    - 子上下文隔离
    - 资源独立管理
    - 错误分别处理

4. 错误处理
    - 上下文创建错误
    - 采集器执行错误
    - 错误统计分析

接下来要实现CollectorFactory(采集器工厂)吗？它负责创建和管理各类采集器实例。

好的，让我们实现CollectorFactory(采集器工厂)，它负责创建和管理各种采集器实例。

```java
package com.platform.collect.core.collector.factory;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 采集器工厂
 */
@Slf4j
@Component
public class CollectorFactory {

    // 采集器注册表
    private final Map<CollectType, Collector> collectorRegistry = new ConcurrentHashMap<>();

    // 采集器配置缓存
    private final Map<String, CollectorConfig> configCache = new ConcurrentHashMap<>();

    @Autowired
    private ApplicationContext applicationContext;

    /**
     * 初始化工厂
     */
    @PostConstruct
    public void init() {
        try {
            // 1. 扫描采集器实现
            Map<String, Collector> collectors = applicationContext.getBeansOfType(Collector.class);

            // 2. 注册采集器
            for (Collector collector : collectors.values()) {
                registerCollector(collector);
            }

            log.info("Collector factory initialized with {} collectors", collectors.size());
        } catch (Exception e) {
            log.error("Initialize collector factory failed", e);
            throw new CollectorInitException("Initialize collector factory failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取采集器
     */
    public Collector getCollector(CollectType type) {
        Collector collector = collectorRegistry.get(type);
        if (collector == null) {
            throw new CollectorNotFoundException("Collector not found: " + type);
        }
        return collector;
    }

    /**
     * 注册采集器
     */
    public void registerCollector(Collector collector) {
        try {
            // 1. 验证采集器
            validateCollector(collector);

            // 2. 注册采集器
            CollectType type = collector.getType();
            collectorRegistry.put(type, collector);

            log.info("Registered collector: {}", type);
        } catch (Exception e) {
            log.error("Register collector failed", e);
            throw new CollectorRegisterException("Register collector failed: " + e.getMessage(), e);
        }
    }

    /**
     * 注销采集器
     */
    public void unregisterCollector(CollectType type) {
        try {
            // 1. 移除采集器
            Collector collector = collectorRegistry.remove(type);
            if (collector == null) {
                return;
            }

            // 2. 清理相关配置
            cleanupCollectorConfig(type);

            log.info("Unregistered collector: {}", type);
        } catch (Exception e) {
            log.error("Unregister collector failed", e);
        }
    }

    /**
     * 获取采集器配置
     */
    public CollectorConfig getCollectorConfig(String configId) {
        // 1. 从缓存获取
        CollectorConfig config = configCache.get(configId);
        if (config != null) {
            return config;
        }

        // 2. 加载配置
        config = loadCollectorConfig(configId);
        if (config != null) {
            configCache.put(configId, config);
        }

        return config;
    }

    /**
     * 更新采集器配置
     */
    public void updateCollectorConfig(String configId, CollectorConfig config) {
        try {
            // 1. 验证配置
            validateCollectorConfig(config);

            // 2. 保存配置
            saveCollectorConfig(configId, config);

            // 3. 更新缓存
            configCache.put(configId, config);

            log.info("Updated collector config: {}", configId);
        } catch (Exception e) {
            log.error("Update collector config failed", e);
            throw new ConfigUpdateException("Update collector config failed: " + e.getMessage(), e);
        }
    }

    /**
     * 验证采集器
     */
    private void validateCollector(Collector collector) {
        // 1. 检查类型
        if (collector.getType() == null) {
            throw new IllegalArgumentException("Collector type is required");
        }

        // 2. 检查重复注册
        if (collectorRegistry.containsKey(collector.getType())) {
            throw new DuplicateCollectorException("Duplicate collector: " + collector.getType());
        }
    }

    /**
     * 验证采集器配置
     */
    private void validateCollectorConfig(CollectorConfig config) {
        // 1. 验证基本配置
        if (config.getType() == null) {
            throw new IllegalArgumentException("Collector type is required");
        }

        // 2. 获取采集器
        Collector collector = getCollector(config.getType());

        // 3. 验证具体配置
        collector.validateConfig(config);
    }

    /**
     * 加载采集器配置
     */
    private CollectorConfig loadCollectorConfig(String configId) {
        try {
            // 从配置中心或数据库加载配置
            return configRepository.getConfig(configId);
        } catch (Exception e) {
            log.error("Load collector config failed", e);
            return null;
        }
    }

    /**
     * 保存采集器配置
     */
    private void saveCollectorConfig(String configId, CollectorConfig config) {
        try {
            configRepository.saveConfig(configId, config);
        } catch (Exception e) {
            log.error("Save collector config failed", e);
            throw e;
        }
    }

    /**
     * 清理采集器配置
     */
    private void cleanupCollectorConfig(CollectType type) {
        // 清理相关配置缓存
        configCache.entrySet().removeIf(entry -> 
            entry.getValue().getType() == type);
    }

    /**
     * 获取所有采集器类型
     */
    public Set<CollectType> getCollectorTypes() {
        return new HashSet<>(collectorRegistry.keySet());
    }

    /**
     * 获取采集器统计信息
     */
    public CollectorStats getCollectorStats() {
        CollectorStats stats = new CollectorStats();
        
        for (Map.Entry<CollectType, Collector> entry : collectorRegistry.entrySet()) {
            CollectType type = entry.getKey();
            
            // 获取采集器运行状态
            CollectorStatus status = getCollectorStatus(type);
            stats.addCollectorStatus(type, status);
        }
        
        return stats;
    }

    /**
     * 获取采集器运行状态
     */
    private CollectorStatus getCollectorStatus(CollectType type) {
        try {
            // 从监控系统获取运行状态
            return monitorService.getCollectorStatus(type);
        } catch (Exception e) {
            log.error("Get collector status failed", e);
            return CollectorStatus.unknown();
        }
    }
}
```

主要特点：

1. 采集器管理
    - 扫描注册采集器
    - 类型映射管理
    - 生命周期控制

2. 配置管理
    - 配置加载保存
    - 配置缓存管理
    - 配置验证更新

3. 运行监控
    - 采集器统计
    - 状态监控
    - 运行诊断

4. 异常处理
    - 初始化异常
    - 注册异常
    - 配置异常

接下来要实现CollectorConfig(采集器配置)的不同类型吗？如TreeCollectorConfig和ListCollectorConfig等。
好的，让我们实现不同类型的采集器配置类。首先实现基础的CollectorConfig抽象类，然后实现具体的配置类。

```java
package com.platform.collect.core.collector.config;

/**
 * 采集器配置基类
 */
@Data
public abstract class CollectorConfig {

    // 基础配置
    private String configId;            // 配置ID
    private CollectType type;          // 采集类型
    private String name;               // 配置名称
    private String description;        // 配置描述
    private Map<String, Object> params;// 扩展参数
    
    // 数据源配置
    private DataSourceConfig dataSource; // 数据源配置
    
    // 重试配置
    private int retryTimes = 3;         // 重试次数
    private long retryInterval = 1000;   // 重试间隔(毫秒)
    
    // 超时配置
    private long timeout = 30000;        // 执行超时(毫秒)
    
    /**
     * 克隆配置
     */
    public abstract CollectorConfig clone();
    
    /**
     * 验证配置
     */
    public abstract void validate() throws ConfigException;
}

/**
 * 树形采集器配置
 */
@Data
@EqualsAndHashCode(callSuper = true)
public class TreeCollectorConfig extends CollectorConfig {

    // 根节点查询
    private String rootQuery;           // 根节点查询语句
    private String rootPath;            // 根节点路径
    
    // 子节点查询
    private String childQuery;          // 子节点查询语句
    private int maxDepth = -1;          // 最大深度(-1表示不限制)
    
    // 并发配置
    private int concurrentLevel = 3;    // 并发度
    private int batchSize = 100;        // 批量大小
    
    // 节点配置
    private Set<String> includeFields;  // 包含字段
    private Set<String> excludeFields;  // 排除字段

    @Override
    public CollectorConfig clone() {
        TreeCollectorConfig config = new TreeCollectorConfig();
        BeanUtils.copyProperties(this, config);
        return config;
    }

    @Override
    public void validate() throws ConfigException {
        // 1. 验证基础配置
        if (StringUtils.isEmpty(getRootQuery())) {
            throw new ConfigException("Root query is required");
        }
        if (StringUtils.isEmpty(getChildQuery())) {
            throw new ConfigException("Child query is required");
        }
        
        // 2. 验证并发配置
        if (getConcurrentLevel() <= 0) {
            throw new ConfigException("Invalid concurrent level: " + getConcurrentLevel());
        }
        if (getBatchSize() <= 0) {
            throw new ConfigException("Invalid batch size: " + getBatchSize());
        }
        
        // 3. 验证深度配置
        if (getMaxDepth() < -1) {
            throw new ConfigException("Invalid max depth: " + getMaxDepth());
        }
    }
}

/**
 * 列表采集器配置
 */
@Data
@EqualsAndHashCode(callSuper = true)
public class ListCollectorConfig extends CollectorConfig {

    // 数据查询
    private String countQuery;          // 总数查询语句
    private String dataQuery;           // 数据查询语句
    
    // 分页配置
    private int pageSize = 500;         // 分页大小
    private boolean scrollEnabled;       // 是否启用游标
    private String scrollField;         // 游标字段
    
    // 并发配置
    private int concurrentLevel = 3;    // 并发度
    
    // 数据配置
    private Set<String> includeFields;  // 包含字段
    private Set<String> excludeFields;  // 排除字段
    private String orderBy;             // 排序字段
    private boolean ascending = true;    // 是否升序

    @Override
    public CollectorConfig clone() {
        ListCollectorConfig config = new ListCollectorConfig();
        BeanUtils.copyProperties(this, config);
        return config;
    }

    @Override
    public void validate() throws ConfigException {
        // 1. 验证查询配置
        if (StringUtils.isEmpty(getCountQuery())) {
            throw new ConfigException("Count query is required");
        }
        if (StringUtils.isEmpty(getDataQuery())) {
            throw new ConfigException("Data query is required");
        }
        
        // 2. 验证分页配置
        if (getPageSize() <= 0) {
            throw new ConfigException("Invalid page size: " + getPageSize());
        }
        
        // 3. 验证游标配置
        if (isScrollEnabled() && StringUtils.isEmpty(getScrollField())) {
            throw new ConfigException("Scroll field is required when scroll is enabled");
        }
        
        // 4. 验证并发配置
        if (getConcurrentLevel() <= 0) {
            throw new ConfigException("Invalid concurrent level: " + getConcurrentLevel());
        }
    }
}

/**
 * 复合采集器配置
 */
@Data
@EqualsAndHashCode(callSuper = true)
public class CompoundCollectorConfig extends CollectorConfig {

    // 子采集器配置
    private List<CollectorConfig> collectorConfigs;  // 子采集器配置列表
    
    // 执行配置
    private boolean parallel = true;     // 是否并行执行
    private int concurrentLevel = 3;     // 并发度
    
    // 数据合并配置
    private String mergeField;           // 合并字段
    private MergeStrategy mergeStrategy; // 合并策略

    @Override
    public CollectorConfig clone() {
        CompoundCollectorConfig config = new CompoundCollectorConfig();
        BeanUtils.copyProperties(this, config);
        
        // 深度克隆子配置
        if (collectorConfigs != null) {
            List<CollectorConfig> clonedConfigs = collectorConfigs.stream()
                .map(CollectorConfig::clone)
                .collect(Collectors.toList());
            config.setCollectorConfigs(clonedConfigs);
        }
        
        return config;
    }

    @Override
    public void validate() throws ConfigException {
        // 1. 验证子配置
        if (CollectionUtils.isEmpty(getCollectorConfigs())) {
            throw new ConfigException("Collector configs is required");
        }
        
        // 2. 验证所有子配置
        for (CollectorConfig config : getCollectorConfigs()) {
            config.validate();
        }
        
        // 3. 验证并发配置
        if (getConcurrentLevel() <= 0) {
            throw new ConfigException("Invalid concurrent level: " + getConcurrentLevel());
        }
        
        // 4. 验证合并配置
        if (StringUtils.isEmpty(getMergeField())) {
            throw new ConfigException("Merge field is required");
        }
        if (getMergeStrategy() == null) {
            throw new ConfigException("Merge strategy is required");
        }
    }
}
```

这些配置类实现了:

1. 层次结构
    - 基础配置抽象
    - 类型特定配置
    - 配置继承体系

2. 配置验证
    - 必要字段检查
    - 参数范围验证
    - 组合配置校验

3. 配置克隆
    - 浅克隆基础属性
    - 深克隆复杂属性
    - 配置复制能力

4. 功能支持
    - 数据源配置
    - 重试配置
    - 超时控制
    - 并发控制

接下来要实现DataSourceConfig(数据源配置)吗？它用于配置不同类型的数据源连接信息。
好的，让我们实现DataSourceConfig(数据源配置)及其相关的具体数据源配置类。

```java
package com.platform.collect.core.collector.config.datasource;

/**
 * 数据源配置基类
 */
@Data
public abstract class DataSourceConfig {
    
    private String sourceId;           // 数据源ID
    private DataSourceType type;       // 数据源类型
    private String name;               // 数据源名称
    private String description;        // 数据源描述
    
    // 连接配置
    private int maxConnections = 10;   // 最大连接数
    private int minConnections = 1;    // 最小连接数
    private long connectionTimeout = 3000; // 连接超时时间(毫秒)
    private long idleTimeout = 600000;    // 空闲超时时间(毫秒)
    
    // 重试配置
    private int maxRetries = 3;        // 最大重试次数
    private long retryInterval = 1000; // 重试间隔(毫秒)
    
    /**
     * 克隆配置
     */
    public abstract DataSourceConfig clone();
    
    /**
     * 验证配置
     */
    public abstract void validate() throws ConfigException;
}

/**
 * JDBC数据源配置
 */
@Data
@EqualsAndHashCode(callSuper = true)
public class JdbcDataSourceConfig extends DataSourceConfig {

    private String url;                // 数据库URL
    private String username;           // 用户名
    private String password;           // 密码
    private String driverClassName;    // 驱动类名
    
    // 连接池配置
    private int maxPoolSize = 10;      // 最大池大小
    private int minPoolSize = 1;       // 最小池大小
    private long maxLifetime = 1800000;// 连接最大生命周期
    
    // 性能配置
    private boolean autoCommit = true; // 自动提交
    private int queryTimeout = 30;     // 查询超时(秒)
    private String initSql;            // 初始化SQL

    @Override
    public DataSourceConfig clone() {
        JdbcDataSourceConfig config = new JdbcDataSourceConfig();
        BeanUtils.copyProperties(this, config);
        return config;
    }

    @Override
    public void validate() throws ConfigException {
        // 1. 验证必要参数
        if (StringUtils.isEmpty(getUrl())) {
            throw new ConfigException("JDBC URL is required");
        }
        if (StringUtils.isEmpty(getUsername())) {
            throw new ConfigException("Username is required");
        }
        
        // 2. 验证连接池配置
        if (getMaxPoolSize() < getMinPoolSize()) {
            throw new ConfigException("Max pool size must be greater than min pool size");
        }
        
        // 3. 验证超时配置
        if (getQueryTimeout() <= 0) {
            throw new ConfigException("Invalid query timeout: " + getQueryTimeout());
        }
    }
}

/**
 * HTTP数据源配置
 */
@Data
@EqualsAndHashCode(callSuper = true)
public class HttpDataSourceConfig extends DataSourceConfig {
    
    private String baseUrl;            // 基础URL
    private String method = "GET";     // 请求方法
    private Map<String, String> headers;// 请求头
    private Map<String, String> params; // 请求参数
    
    // 认证配置
    private AuthType authType;         // 认证类型
    private String authToken;          // 认证令牌
    private String username;           // 用户名
    private String password;           // 密码
    
    // 超时配置
    private int connectTimeout = 3000; // 连接超时(毫秒)
    private int readTimeout = 5000;    // 读取超时(毫秒)
    
    // 代理配置
    private String proxyHost;          // 代理主机
    private int proxyPort;            // 代理端口

    @Override
    public DataSourceConfig clone() {
        HttpDataSourceConfig config = new HttpDataSourceConfig();
        BeanUtils.copyProperties(this, config);
        
        // 深度克隆Map
        if (headers != null) {
            config.setHeaders(new HashMap<>(headers));
        }
        if (params != null) {
            config.setParams(new HashMap<>(params));
        }
        
        return config;
    }

    @Override
    public void validate() throws ConfigException {
        // 1. 验证基础URL
        if (StringUtils.isEmpty(getBaseUrl())) {
            throw new ConfigException("Base URL is required");
        }
        
        // 2. 验证请求方法
        if (!isValidMethod(getMethod())) {
            throw new ConfigException("Invalid HTTP method: " + getMethod());
        }
        
        // 3. 验证认证配置
        if (getAuthType() != null && getAuthType() != AuthType.NONE) {
            validateAuth();
        }
        
        // 4. 验证超时配置
        if (getConnectTimeout() <= 0) {
            throw new ConfigException("Invalid connect timeout: " + getConnectTimeout());
        }
        if (getReadTimeout() <= 0) {
            throw new ConfigException("Invalid read timeout: " + getReadTimeout());
        }
    }

    /**
     * 验证认证配置
     */
    private void validateAuth() throws ConfigException {
        switch (getAuthType()) {
            case BASIC:
                if (StringUtils.isEmpty(getUsername()) || StringUtils.isEmpty(getPassword())) {
                    throw new ConfigException("Username and password are required for BASIC auth");
                }
                break;
            case BEARER:
                if (StringUtils.isEmpty(getAuthToken())) {
                    throw new ConfigException("Auth token is required for BEARER auth");
                }
                break;
        }
    }

    /**
     * 验证HTTP方法
     */
    private boolean isValidMethod(String method) {
        return Arrays.asList("GET", "POST", "PUT", "DELETE", "PATCH", "HEAD").contains(method.toUpperCase());
    }
}

/**
 * MongoDB数据源配置
 */
@Data
@EqualsAndHashCode(callSuper = true)
public class MongoDataSourceConfig extends DataSourceConfig {

    private String uri;                // MongoDB URI
    private String database;           // 数据库名
    private List<ServerAddress> hosts; // 服务器地址列表
    private String replicaSet;         // 副本集名称
    
    // 认证配置
    private String authDatabase;       // 认证数据库
    private String username;           // 用户名
    private String password;           // 密码
    
    // 连接池配置
    private int maxPoolSize = 100;     // 最大连接数
    private int minPoolSize = 10;      // 最小连接数
    private int maxWaitTime = 5000;    // 最大等待时间
    private int connectTimeout = 3000; // 连接超时时间
    
    // 读写配置
    private ReadPreference readPreference;    // 读偏好
    private WriteConcern writeConcern;       // 写关注

    @Override
    public DataSourceConfig clone() {
        MongoDataSourceConfig config = new MongoDataSourceConfig();
        BeanUtils.copyProperties(this, config);
        
        // 深度克隆服务器地址列表
        if (hosts != null) {
            config.setHosts(new ArrayList<>(hosts));
        }
        
        return config;
    }

    @Override
    public void validate() throws ConfigException {
        // 1. 验证连接信息
        if (StringUtils.isEmpty(getUri()) && CollectionUtils.isEmpty(getHosts())) {
            throw new ConfigException("Either URI or hosts must be specified");
        }
        if (StringUtils.isEmpty(getDatabase())) {
            throw new ConfigException("Database name is required");
        }
        
        // 2. 验证认证配置
        if (!StringUtils.isEmpty(getUsername()) && StringUtils.isEmpty(getPassword())) {
            throw new ConfigException("Password is required when username is specified");
        }
        
        // 3. 验证连接池配置
        if (getMaxPoolSize() < getMinPoolSize()) {
            throw new ConfigException("Max pool size must be greater than min pool size");
        }
        if (getMaxWaitTime() <= 0) {
            throw new ConfigException("Invalid max wait time: " + getMaxWaitTime());
        }
    }
}
```

这些配置类实现了：

1. 基础配置
    - 数据源标识
    - 连接池配置
    - 重试机制

2. 特定配置
    - JDBC数据源配置
    - HTTP数据源配置
    - MongoDB数据源配置

3. 配置验证
    - 必要参数检查
    - 参数范围验证
    - 组合参数验证

4. 配置克隆
    - 基础属性复制
    - 集合深度克隆
    - 完整配置复制

接下来要实现DataSourceFactory(数据源工厂)吗？它负责根据配置创建和管理数据源连接。
好的，让我们实现DataSourceFactory(数据源工厂)，用于创建和管理数据源连接。

```java
package com.platform.collect.core.collector.datasource;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

/**
 * 数据源工厂
 */
@Slf4j
@Component
public class DataSourceFactory {

    // 数据源连接池
    private final Map<String, DataSource> dataSourcePool = new ConcurrentHashMap<>();
    
    // 数据源配置缓存
    private final Cache<String, DataSourceConfig> configCache;

    @Autowired
    private ConfigRepository configRepository;

    public DataSourceFactory() {
        // 初始化配置缓存
        this.configCache = CacheBuilder.newBuilder()
            .expireAfterWrite(5, TimeUnit.MINUTES)
            .maximumSize(1000)
            .build();
    }

    /**
     * 获取数据源
     */
    public DataSource getDataSource(String sourceId) {
        try {
            // 1. 从连接池获取
            DataSource dataSource = dataSourcePool.get(sourceId);
            if (dataSource != null && dataSource.isValid()) {
                return dataSource;
            }

            // 2. 创建新数据源
            DataSourceConfig config = getDataSourceConfig(sourceId);
            dataSource = createDataSource(config);
            
            // 3. 放入连接池
            dataSourcePool.put(sourceId, dataSource);
            
            return dataSource;

        } catch (Exception e) {
            log.error("Get data source failed: {}", sourceId, e);
            throw new DataSourceException("Get data source failed: " + e.getMessage(), e);
        }
    }

    /**
     * 创建数据源
     */
    private DataSource createDataSource(DataSourceConfig config) {
        try {
            // 1. 根据类型创建
            switch (config.getType()) {
                case JDBC:
                    return createJdbcDataSource((JdbcDataSourceConfig) config);
                case HTTP:
                    return createHttpDataSource((HttpDataSourceConfig) config);
                case MONGO:
                    return createMongoDataSource((MongoDataSourceConfig) config);
                default:
                    throw new IllegalArgumentException("Unsupported data source type: " + config.getType());
            }
        } catch (Exception e) {
            log.error("Create data source failed: {}", config.getSourceId(), e);
            throw new DataSourceException("Create data source failed: " + e.getMessage(), e);
        }
    }

    /**
     * 创建JDBC数据源
     */
    private DataSource createJdbcDataSource(JdbcDataSourceConfig config) {
        // 1. 创建连接池配置
        HikariConfig poolConfig = new HikariConfig();
        poolConfig.setJdbcUrl(config.getUrl());
        poolConfig.setUsername(config.getUsername());
        poolConfig.setPassword(config.getPassword());
        poolConfig.setDriverClassName(config.getDriverClassName());
        
        // 2. 设置连接池参数
        poolConfig.setMaximumPoolSize(config.getMaxPoolSize());
        poolConfig.setMinimumIdle(config.getMinPoolSize());
        poolConfig.setConnectionTimeout(config.getConnectionTimeout());
        poolConfig.setMaxLifetime(config.getMaxLifetime());
        poolConfig.setAutoCommit(config.isAutoCommit());
        
        // 3. 创建连接池
        return new JdbcDataSource(new HikariDataSource(poolConfig), config);
    }

    /**
     * 创建HTTP数据源
     */
    private DataSource createHttpDataSource(HttpDataSourceConfig config) {
        // 1. 创建HTTP客户端配置
        HttpClientConfig clientConfig = HttpClientConfig.custom()
            .setConnectTimeout(config.getConnectTimeout())
            .setReadTimeout(config.getReadTimeout())
            .setMaxConnections(config.getMaxConnections())
            .setRetryTimes(config.getMaxRetries())
            .setRetryInterval(config.getRetryInterval())
            .build();
            
        // 2. 设置认证
        if (config.getAuthType() != null) {
            configureAuth(clientConfig, config);
        }
        
        // 3. 设置代理
        if (config.getProxyHost() != null) {
            configureProxy(clientConfig, config);
        }
        
        // 4. 创建数据源
        return new HttpDataSource(clientConfig, config);
    }

    /**
     * 创建MongoDB数据源
     */
    private DataSource createMongoDataSource(MongoDataSourceConfig config) {
        // 1. 创建MongoDB客户端配置
        MongoClientSettings.Builder settingsBuilder = MongoClientSettings.builder();
        
        // 2. 配置连接参数
        settingsBuilder.applyConnectionString(new ConnectionString(config.getUri()))
            .applyToConnectionPoolSettings(builder -> 
                builder.maxSize(config.getMaxPoolSize())
                      .minSize(config.getMinPoolSize())
                      .maxWaitTime(config.getMaxWaitTime(), TimeUnit.MILLISECONDS)
                      .maxConnectionLifeTime(config.getMaxLifetime(), TimeUnit.MILLISECONDS))
            .applyToClusterSettings(builder -> 
                builder.hosts(config.getHosts())
                      .requiredReplicaSetName(config.getReplicaSet()));
                      
        // 3. 配置认证
        if (config.getUsername() != null) {
            settingsBuilder.credential(MongoCredential.createCredential(
                config.getUsername(),
                config.getAuthDatabase(),
                config.getPassword().toCharArray()));
        }
        
        // 4. 配置读写偏好
        if (config.getReadPreference() != null) {
            settingsBuilder.readPreference(config.getReadPreference());
        }
        if (config.getWriteConcern() != null) {
            settingsBuilder.writeConcern(config.getWriteConcern());
        }
        
        // 5. 创建数据源
        return new MongoDataSource(
            MongoClients.create(settingsBuilder.build()), 
            config);
    }

    /**
     * 获取数据源配置
     */
    private DataSourceConfig getDataSourceConfig(String sourceId) {
        try {
            // 1. 从缓存获取
            DataSourceConfig config = configCache.getIfPresent(sourceId);
            if (config != null) {
                return config;
            }

            // 2. 从存储加载
            config = configRepository.getDataSourceConfig(sourceId);
            if (config == null) {
                throw new ConfigNotFoundException("Data source config not found: " + sourceId);
            }

            // 3. 放入缓存
            configCache.put(sourceId, config);
            
            return config;

        } catch (Exception e) {
            log.error("Get data source config failed: {}", sourceId, e);
            throw new ConfigException("Get data source config failed: " + e.getMessage(), e);
        }
    }

    /**
     * 关闭数据源
     */
    public void closeDataSource(String sourceId) {
        try {
            DataSource dataSource = dataSourcePool.remove(sourceId);
            if (dataSource != null) {
                dataSource.close();
            }
        } catch (Exception e) {
            log.error("Close data source failed: {}", sourceId, e);
        }
    }

    /**
     * 关闭所有数据源
     */
    @PreDestroy
    public void closeAll() {
        for (Map.Entry<String, DataSource> entry : dataSourcePool.entrySet()) {
            try {
                entry.getValue().close();
            } catch (Exception e) {
                log.error("Close data source failed: {}", entry.getKey(), e);
            }
        }
        dataSourcePool.clear();
    }
}
```

这个工厂类实现了：

1. 数据源管理
    - 数据源创建
    - 连接池管理
    - 生命周期控制

2. 配置管理
    - 配置加载缓存
    - 配置验证
    - 参数解析

3. 多类型支持
    - JDBC数据源
    - HTTP数据源
    - MongoDB数据源

4. 资源管理
    - 连接池优化
    - 自动关闭
    - 资源清理

接下来要实现具体的DataSource(数据源)接口和实现类吗？
好的，让我们实现DataSource接口和各个具体的数据源实现类。首先是DataSource接口：

```java
package com.platform.collect.core.collector.datasource;

/**
 * 数据源接口
 */
public interface DataSource extends AutoCloseable {

    /**
     * 获取连接
     */
    Connection getConnection() throws DataSourceException;

    /**
     * 执行查询
     */
    <T> List<T> queryForList(String query, Map<String, Object> params, Class<T> type) throws DataSourceException;

    /**
     * 执行单条查询
     */
    <T> T queryForObject(String query, Map<String, Object> params, Class<T> type) throws DataSourceException;

    /**
     * 检查数据源是否可用
     */
    boolean isValid();

    /**
     * 获取数据源类型
     */
    DataSourceType getType();

    /**
     * 获取数据源配置
     */
    DataSourceConfig getConfig();
}

/**
 * JDBC数据源实现
 */
@Slf4j
public class JdbcDataSource implements DataSource {

    private final HikariDataSource hikariDataSource;
    private final JdbcDataSourceConfig config;
    private final JdbcTemplate jdbcTemplate;

    public JdbcDataSource(HikariDataSource hikariDataSource, JdbcDataSourceConfig config) {
        this.hikariDataSource = hikariDataSource;
        this.config = config;
        this.jdbcTemplate = new JdbcTemplate(hikariDataSource);
    }

    @Override
    public Connection getConnection() throws DataSourceException {
        try {
            return hikariDataSource.getConnection();
        } catch (SQLException e) {
            throw new DataSourceException("Get connection failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> List<T> queryForList(String query, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            // 1. 准备SQL和参数
            PreparedStatementCreator psc = createPreparedStatement(query, params);
            
            // 2. 设置查询超时
            jdbcTemplate.setQueryTimeout(config.getQueryTimeout());
            
            // 3. 执行查询
            return jdbcTemplate.query(psc, new BeanPropertyRowMapper<>(type));
            
        } catch (Exception e) {
            log.error("Query for list failed: {}", query, e);
            throw new DataSourceException("Query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> T queryForObject(String query, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            PreparedStatementCreator psc = createPreparedStatement(query, params);
            jdbcTemplate.setQueryTimeout(config.getQueryTimeout());
            return jdbcTemplate.queryForObject(psc, new BeanPropertyRowMapper<>(type));
        } catch (EmptyResultDataAccessException e) {
            return null;
        } catch (Exception e) {
            log.error("Query for object failed: {}", query, e);
            throw new DataSourceException("Query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public boolean isValid() {
        try (Connection conn = hikariDataSource.getConnection()) {
            return conn.isValid(config.getConnectionTimeout());
        } catch (Exception e) {
            log.error("Check connection validity failed", e);
            return false;
        }
    }

    @Override
    public DataSourceType getType() {
        return DataSourceType.JDBC;
    }

    @Override
    public DataSourceConfig getConfig() {
        return config;
    }

    @Override
    public void close() {
        if (hikariDataSource != null && !hikariDataSource.isClosed()) {
            hikariDataSource.close();
        }
    }

    /**
     * 创建PreparedStatement
     */
    private PreparedStatementCreator createPreparedStatement(String query, Map<String, Object> params) {
        return con -> {
            PreparedStatement ps = con.prepareStatement(query);
            if (params != null) {
                int index = 1;
                for (Map.Entry<String, Object> entry : params.entrySet()) {
                    ps.setObject(index++, entry.getValue());
                }
            }
            return ps;
        };
    }
}

/**
 * HTTP数据源实现
 */
@Slf4j
public class HttpDataSource implements DataSource {

    private final CloseableHttpClient httpClient;
    private final HttpDataSourceConfig config;
    private final ObjectMapper objectMapper;

    public HttpDataSource(HttpClientConfig clientConfig, HttpDataSourceConfig config) {
        this.httpClient = createHttpClient(clientConfig);
        this.config = config;
        this.objectMapper = new ObjectMapper();
    }

    @Override
    public Connection getConnection() throws DataSourceException {
        // HTTP数据源不需要维护连接
        throw new UnsupportedOperationException("HTTP data source doesn't support connection");
    }

    @Override
    public <T> List<T> queryForList(String url, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            // 1. 构建请求
            HttpUriRequest request = buildRequest(url, params);
            
            // 2. 执行请求
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                // 3. 检查响应
                validateResponse(response);
                
                // 4. 解析响应
                return parseResponseList(response, type);
            }
        } catch (Exception e) {
            log.error("HTTP query failed: {}", url, e);
            throw new DataSourceException("HTTP query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> T queryForObject(String url, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            HttpUriRequest request = buildRequest(url, params);
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                validateResponse(response);
                return parseResponseObject(response, type);
            }
        } catch (Exception e) {
            log.error("HTTP query failed: {}", url, e);
            throw new DataSourceException("HTTP query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public boolean isValid() {
        try {
            // 执行健康检查请求
            HttpGet request = new HttpGet(config.getBaseUrl() + "/health");
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                return response.getStatusLine().getStatusCode() == HttpStatus.SC_OK;
            }
        } catch (Exception e) {
            log.error("Health check failed", e);
            return false;
        }
    }

    @Override
    public DataSourceType getType() {
        return DataSourceType.HTTP;
    }

    @Override
    public DataSourceConfig getConfig() {
        return config;
    }

    @Override
    public void close() {
        try {
            if (httpClient != null) {
                httpClient.close();
            }
        } catch (IOException e) {
            log.error("Close HTTP client failed", e);
        }
    }

    /**
     * 构建HTTP请求
     */
    private HttpUriRequest buildRequest(String url, Map<String, Object> params) {
        // 构建完整URL
        String fullUrl = buildUrl(url, params);
        
        // 创建请求
        RequestBuilder builder = RequestBuilder.create(config.getMethod())
            .setUri(fullUrl);
            
        // 添加请求头
        if (config.getHeaders() != null) {
            config.getHeaders().forEach(builder::addHeader);
        }
        
        return builder.build();
    }

    /**
     * 验证HTTP响应
     */
    private void validateResponse(HttpResponse response) throws DataSourceException {
        int statusCode = response.getStatusLine().getStatusCode();
        if (statusCode >= 400) {
            throw new DataSourceException("HTTP request failed with status: " + statusCode);
        }
    }

    /**
     * 解析响应列表
     */
    private <T> List<T> parseResponseList(HttpResponse response, Class<T> type) throws IOException {
        String content = EntityUtils.toString(response.getEntity());
        return objectMapper.readValue(content,
            objectMapper.getTypeFactory().constructCollectionType(List.class, type));
    }

    /**
     * 解析响应对象
     */
    private <T> T parseResponseObject(HttpResponse response, Class<T> type) throws IOException {
        String content = EntityUtils.toString(response.getEntity());
        return objectMapper.readValue(content, type);
    }
}
```

我们继续实现MongoDB数据源类吗？这个类负责MongoDB的连接和查询管理。
好的，让我们继续实现MongoDB数据源类：

```java
package com.platform.collect.core.collector.datasource;

/**
 * MongoDB数据源实现
 */
@Slf4j
public class MongoDataSource implements DataSource {

    private final MongoClient mongoClient;
    private final MongoDataSourceConfig config;
    private final MongoConverter mongoConverter;

    public MongoDataSource(MongoClient mongoClient, MongoDataSourceConfig config) {
        this.mongoClient = mongoClient;
        this.config = config;
        this.mongoConverter = createMongoConverter();
    }

    @Override
    public Connection getConnection() throws DataSourceException {
        try {
            // 返回MongoDB数据库连接
            return new MongoConnection(
                mongoClient.getDatabase(config.getDatabase()),
                config
            );
        } catch (Exception e) {
            throw new DataSourceException("Get MongoDB connection failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> List<T> queryForList(String collection, Map<String, Object> query, Class<T> type) 
            throws DataSourceException {
        try {
            // 1. 获取集合
            MongoCollection<Document> mongoCollection = getCollection(collection);

            // 2. 构建查询
            Bson filter = buildQuery(query);

            // 3. 执行查询
            return mongoCollection.find(filter)
                .map(doc -> convertToObject(doc, type))
                .into(new ArrayList<>());

        } catch (Exception e) {
            log.error("MongoDB query failed: {}", collection, e);
            throw new DataSourceException("MongoDB query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> T queryForObject(String collection, Map<String, Object> query, Class<T> type) 
            throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);
            Bson filter = buildQuery(query);
            
            Document doc = mongoCollection.find(filter).first();
            return doc != null ? convertToObject(doc, type) : null;

        } catch (Exception e) {
            log.error("MongoDB query failed: {}", collection, e);
            throw new DataSourceException("MongoDB query failed: " + e.getMessage(), e);
        }
    }

    /**
     * 聚合查询
     */
    public <T> List<T> aggregate(String collection, List<Bson> pipeline, Class<T> type) 
            throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);
            
            return mongoCollection.aggregate(pipeline)
                .map(doc -> convertToObject(doc, type))
                .into(new ArrayList<>());

        } catch (Exception e) {
            log.error("MongoDB aggregate failed: {}", collection, e);
            throw new DataSourceException("MongoDB aggregate failed: " + e.getMessage(), e);
        }
    }

    /**
     * 分页查询
     */
    public <T> PageResult<T> queryForPage(String collection, Map<String, Object> query, 
            int pageNum, int pageSize, Class<T> type) throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);
            Bson filter = buildQuery(query);

            // 1. 查询总数
            long total = mongoCollection.countDocuments(filter);

            // 2. 分页查询数据
            List<T> data = mongoCollection.find(filter)
                .skip((pageNum - 1) * pageSize)
                .limit(pageSize)
                .map(doc -> convertToObject(doc, type))
                .into(new ArrayList<>());

            // 3. 构建分页结果
            return new PageResult<>(data, total, pageNum, pageSize);

        } catch (Exception e) {
            log.error("MongoDB page query failed: {}", collection, e);
            throw new DataSourceException("MongoDB page query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public boolean isValid() {
        try {
            // 执行ping命令检查连接
            Document result = mongoClient.getDatabase("admin")
                .runCommand(new Document("ping", 1));
            return result.getDouble("ok") == 1.0;
        } catch (Exception e) {
            log.error("MongoDB health check failed", e);
            return false;
        }
    }

    @Override
    public DataSourceType getType() {
        return DataSourceType.MONGO;
    }

    @Override
    public DataSourceConfig getConfig() {
        return config;
    }

    @Override
    public void close() {
        try {
            if (mongoClient != null) {
                mongoClient.close();
            }
        } catch (Exception e) {
            log.error("Close MongoDB client failed", e);
        }
    }

    /**
     * 获取MongoDB集合
     */
    private MongoCollection<Document> getCollection(String collection) {
        return mongoClient
            .getDatabase(config.getDatabase())
            .getCollection(collection);
    }

    /**
     * 构建MongoDB查询
     */
    private Bson buildQuery(Map<String, Object> query) {
        if (MapUtils.isEmpty(query)) {
            return new Document();
        }

        Document filter = new Document();
        query.forEach((key, value) -> {
            if (value instanceof Map) {
                // 处理操作符查询
                Map<String, Object> operators = (Map<String, Object>) value;
                Document opFilter = new Document();
                operators.forEach((op, val) -> 
                    opFilter.append(parseOperator(op), val));
                filter.append(key, opFilter);
            } else {
                // 处理等值查询
                filter.append(key, value);
            }
        });
        return filter;
    }

    /**
     * 解析MongoDB操作符
     */
    private String parseOperator(String op) {
        switch (op.toLowerCase()) {
            case "eq": return "$eq";
            case "ne": return "$ne";
            case "gt": return "$gt";
            case "gte": return "$gte";
            case "lt": return "$lt";
            case "lte": return "$lte";
            case "in": return "$in";
            case "nin": return "$nin";
            case "exists": return "$exists";
            case "regex": return "$regex";
            default:
                throw new IllegalArgumentException("Unsupported operator: " + op);
        }
    }

    /**
     * 创建MongoDB转换器
     */
    private MongoConverter createMongoConverter() {
        MongoMappingContext mappingContext = new MongoMappingContext();
        mappingContext.setSimpleTypeHolder(new SimpleTypeHolder());
        
        MappingMongoConverter converter = new MappingMongoConverter(
            new DefaultDbRefResolver(mongoClient),
            mappingContext
        );
        
        converter.setCustomConversions(new MongoCustomConversions(
            Arrays.asList(
                new DateToLocalDateTimeConverter(),
                new LocalDateTimeToDateConverter()
            )
        ));
        
        return converter;
    }

    /**
     * 转换MongoDB文档到对象
     */
    private <T> T convertToObject(Document document, Class<T> type) {
        return mongoConverter.read(type, document);
    }

    /**
     * MongoDB连接包装类
     */
    private static class MongoConnection implements Connection {
        private final MongoDatabase database;
        private final MongoDataSourceConfig config;

        public MongoConnection(MongoDatabase database, MongoDataSourceConfig config) {
            this.database = database;
            this.config = config;
        }

        @Override
        public void close() {
            // MongoDB连接由连接池管理，无需手动关闭
        }

        @Override
        public boolean isClosed() {
            return false;
        }
    }
}
```

这个MongoDB数据源实现提供了：

1. 查询功能
    - 基础查询操作
    - 聚合查询支持
    - 分页查询实现

2. 数据转换
    - 文档对象转换
    - 类型自动映射
    - 自定义转换器

3. 查询构建
    - 查询条件解析
    - 操作符支持
    - 过滤器构建

4. 连接管理
    - 连接池管理
    - 健康检查
    - 资源释放

要继续实现DataSourceConnection(数据源连接)接口吗？它定义了数据源连接的基本操作。
好的，让我们实现DataSourceConnection接口及其具体实现：

```java
package com.platform.collect.core.collector.datasource.connection;

/**
 * 数据源连接接口
 */
public interface DataSourceConnection extends AutoCloseable {

    /**
     * 执行查询
     */
    <T> List<T> queryForList(String query, Map<String, Object> params, Class<T> type) throws DataSourceException;

    /**
     * 执行单条查询
     */
    <T> T queryForObject(String query, Map<String, Object> params, Class<T> type) throws DataSourceException;

    /**
     * 执行更新操作
     */
    int execute(String query, Map<String, Object> params) throws DataSourceException;

    /**
     * 开始事务
     */
    void beginTransaction() throws DataSourceException;

    /**
     * 提交事务
     */
    void commit() throws DataSourceException;

    /**
     * 回滚事务
     */
    void rollback() throws DataSourceException;

    /**
     * 检查连接是否有效
     */
    boolean isValid() throws DataSourceException;

    /**
     * 获取原生连接
     */
    <T> T getNativeConnection();
}

/**
 * JDBC连接实现
 */
@Slf4j
public class JdbcConnection implements DataSourceConnection {
    
    private final Connection connection;
    private final JdbcTemplate jdbcTemplate;
    private final JdbcDataSourceConfig config;

    public JdbcConnection(Connection connection, JdbcDataSourceConfig config) {
        this.connection = connection;
        this.config = config;
        this.jdbcTemplate = new JdbcTemplate(new SingleConnectionDataSource(connection, true));
    }

    @Override
    public <T> List<T> queryForList(String query, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            PreparedStatementCreator psc = createPreparedStatement(query, params);
            jdbcTemplate.setQueryTimeout(config.getQueryTimeout());
            return jdbcTemplate.query(psc, new BeanPropertyRowMapper<>(type));
        } catch (Exception e) {
            throw new DataSourceException("Query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> T queryForObject(String query, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            PreparedStatementCreator psc = createPreparedStatement(query, params);
            jdbcTemplate.setQueryTimeout(config.getQueryTimeout());
            return jdbcTemplate.queryForObject(psc, new BeanPropertyRowMapper<>(type));
        } catch (EmptyResultDataAccessException e) {
            return null;
        } catch (Exception e) {
            throw new DataSourceException("Query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public int execute(String query, Map<String, Object> params) throws DataSourceException {
        try {
            PreparedStatementCreator psc = createPreparedStatement(query, params);
            return jdbcTemplate.update(psc);
        } catch (Exception e) {
            throw new DataSourceException("Execute failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void beginTransaction() throws DataSourceException {
        try {
            connection.setAutoCommit(false);
        } catch (SQLException e) {
            throw new DataSourceException("Begin transaction failed", e);
        }
    }

    @Override
    public void commit() throws DataSourceException {
        try {
            connection.commit();
        } catch (SQLException e) {
            throw new DataSourceException("Commit transaction failed", e);
        }
    }

    @Override
    public void rollback() throws DataSourceException {
        try {
            connection.rollback();
        } catch (SQLException e) {
            throw new DataSourceException("Rollback transaction failed", e);
        }
    }

    @Override
    public boolean isValid() throws DataSourceException {
        try {
            return connection.isValid(config.getConnectionTimeout());
        } catch (SQLException e) {
            throw new DataSourceException("Check connection validity failed", e);
        }
    }

    @Override
    @SuppressWarnings("unchecked")
    public <T> T getNativeConnection() {
        return (T) connection;
    }

    @Override
    public void close() throws Exception {
        if (connection != null && !connection.isClosed()) {
            connection.close();
        }
    }

    private PreparedStatementCreator createPreparedStatement(String query, Map<String, Object> params) {
        return con -> {
            PreparedStatement ps = con.prepareStatement(query);
            if (params != null) {
                int index = 1;
                for (Map.Entry<String, Object> entry : params.entrySet()) {
                    ps.setObject(index++, entry.getValue());
                }
            }
            return ps;
        };
    }
}

/**
 * HTTP连接实现
 */
@Slf4j
public class HttpConnection implements DataSourceConnection {

    private final CloseableHttpClient httpClient;
    private final HttpDataSourceConfig config;
    private final ObjectMapper objectMapper;

    public HttpConnection(CloseableHttpClient httpClient, HttpDataSourceConfig config) {
        this.httpClient = httpClient;
        this.config = config;
        this.objectMapper = new ObjectMapper();
    }

    @Override
    public <T> List<T> queryForList(String url, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            HttpUriRequest request = buildRequest(url, params);
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                validateResponse(response);
                String content = EntityUtils.toString(response.getEntity());
                return objectMapper.readValue(content,
                    objectMapper.getTypeFactory().constructCollectionType(List.class, type));
            }
        } catch (Exception e) {
            throw new DataSourceException("HTTP query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> T queryForObject(String url, Map<String, Object> params, Class<T> type) 
            throws DataSourceException {
        try {
            HttpUriRequest request = buildRequest(url, params);
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                validateResponse(response);
                String content = EntityUtils.toString(response.getEntity());
                return objectMapper.readValue(content, type);
            }
        } catch (Exception e) {
            throw new DataSourceException("HTTP query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public int execute(String url, Map<String, Object> params) throws DataSourceException {
        try {
            HttpUriRequest request = buildRequest(url, params);
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                validateResponse(response);
                return response.getStatusLine().getStatusCode();
            }
        } catch (Exception e) {
            throw new DataSourceException("HTTP execute failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void beginTransaction() throws DataSourceException {
        // HTTP是无状态的，不支持事务
        throw new UnsupportedOperationException("HTTP connection doesn't support transactions");
    }

    @Override
    public void commit() throws DataSourceException {
        throw new UnsupportedOperationException("HTTP connection doesn't support transactions");
    }

    @Override
    public void rollback() throws DataSourceException {
        throw new UnsupportedOperationException("HTTP connection doesn't support transactions");
    }

    @Override
    public boolean isValid() throws DataSourceException {
        try {
            HttpGet request = new HttpGet(config.getBaseUrl() + "/health");
            try (CloseableHttpResponse response = httpClient.execute(request)) {
                return response.getStatusLine().getStatusCode() == HttpStatus.SC_OK;
            }
        } catch (Exception e) {
            return false;
        }
    }

    @Override
    @SuppressWarnings("unchecked")
    public <T> T getNativeConnection() {
        return (T) httpClient;
    }

    @Override
    public void close() throws Exception {
        // HTTP连接由连接池管理，这里不需要关闭
    }

    private HttpUriRequest buildRequest(String url, Map<String, Object> params) {
        String fullUrl = buildUrl(url, params);
        RequestBuilder builder = RequestBuilder.create(config.getMethod())
            .setUri(fullUrl);
            
        if (config.getHeaders() != null) {
            config.getHeaders().forEach(builder::addHeader);
        }
        
        return builder.build();
    }

    private void validateResponse(HttpResponse response) throws DataSourceException {
        int statusCode = response.getStatusLine().getStatusCode();
        if (statusCode >= 400) {
            throw new DataSourceException("HTTP request failed with status: " + statusCode);
        }
    }
}
```

我们是否要继续实现MongoConnection类？它提供MongoDB特定的连接实现。

好的，让我们实现MongoConnection类：

```java
package com.platform.collect.core.collector.datasource.connection;

/**
 * MongoDB连接实现
 */
@Slf4j
public class MongoConnection implements DataSourceConnection {

    private final MongoDatabase database;
    private final MongoDataSourceConfig config;
    private final MongoConverter converter;
    private ClientSession session;

    public MongoConnection(MongoDatabase database, MongoDataSourceConfig config) {
        this.database = database;
        this.config = config;
        this.converter = createMongoConverter();
    }

    @Override
    public <T> List<T> queryForList(String collection, Map<String, Object> query, Class<T> type) 
            throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);
            Bson filter = buildQuery(query);

            FindIterable<Document> result = session != null ?
                mongoCollection.find(session, filter) :
                mongoCollection.find(filter);

            return result.map(doc -> convertToObject(doc, type))
                .into(new ArrayList<>());
        } catch (Exception e) {
            throw new DataSourceException("MongoDB query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public <T> T queryForObject(String collection, Map<String, Object> query, Class<T> type) 
            throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);
            Bson filter = buildQuery(query);

            Document doc = session != null ?
                mongoCollection.find(session, filter).first() :
                mongoCollection.find(filter).first();

            return doc != null ? convertToObject(doc, type) : null;
        } catch (Exception e) {
            throw new DataSourceException("MongoDB query failed: " + e.getMessage(), e);
        }
    }

    @Override
    public int execute(String collection, Map<String, Object> document) throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);
            Document doc = new Document(document);

            if (session != null) {
                mongoCollection.insertOne(session, doc);
            } else {
                mongoCollection.insertOne(doc);
            }

            return 1;
        } catch (Exception e) {
            throw new DataSourceException("MongoDB execute failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行聚合查询
     */
    public <T> List<T> aggregate(String collection, List<Bson> pipeline, Class<T> type) 
            throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);

            AggregateIterable<Document> result = session != null ?
                mongoCollection.aggregate(session, pipeline) :
                mongoCollection.aggregate(pipeline);

            return result.map(doc -> convertToObject(doc, type))
                .into(new ArrayList<>());
        } catch (Exception e) {
            throw new DataSourceException("MongoDB aggregate failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行批量写入
     */
    public void bulkWrite(String collection, List<WriteModel<Document>> writes) 
            throws DataSourceException {
        try {
            MongoCollection<Document> mongoCollection = getCollection(collection);

            if (session != null) {
                mongoCollection.bulkWrite(session, writes);
            } else {
                mongoCollection.bulkWrite(writes);
            }
        } catch (Exception e) {
            throw new DataSourceException("MongoDB bulk write failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void beginTransaction() throws DataSourceException {
        try {
            if (session != null) {
                throw new IllegalStateException("Transaction already started");
            }
            session = database.getClient().startSession();
            session.startTransaction();
        } catch (Exception e) {
            throw new DataSourceException("Begin transaction failed", e);
        }
    }

    @Override
    public void commit() throws DataSourceException {
        try {
            if (session == null) {
                throw new IllegalStateException("No transaction in progress");
            }
            session.commitTransaction();
        } catch (Exception e) {
            throw new DataSourceException("Commit transaction failed", e);
        } finally {
            closeSession();
        }
    }

    @Override
    public void rollback() throws DataSourceException {
        try {
            if (session == null) {
                throw new IllegalStateException("No transaction in progress");
            }
            session.abortTransaction();
        } catch (Exception e) {
            throw new DataSourceException("Rollback transaction failed", e);
        } finally {
            closeSession();
        }
    }

    @Override
    public boolean isValid() throws DataSourceException {
        try {
            Document result = database.runCommand(new Document("ping", 1));
            return result.getDouble("ok") == 1.0;
        } catch (Exception e) {
            return false;
        }
    }

    @Override
    public <T> T getNativeConnection() {
        return (T) database;
    }

    @Override
    public void close() {
        closeSession();
    }

    private void closeSession() {
        if (session != null) {
            session.close();
            session = null;
        }
    }

    private MongoCollection<Document> getCollection(String collection) {
        return database.getCollection(collection);
    }

    private Bson buildQuery(Map<String, Object> query) {
        if (MapUtils.isEmpty(query)) {
            return new Document();
        }

        Document filter = new Document();
        query.forEach((key, value) -> {
            if (value instanceof Map) {
                // 处理操作符查询
                Map<String, Object> operators = (Map<String, Object>) value;
                Document opFilter = new Document();
                operators.forEach((op, val) -> 
                    opFilter.append(parseOperator(op), val));
                filter.append(key, opFilter);
            } else {
                filter.append(key, value);
            }
        });
        return filter;
    }

    private String parseOperator(String op) {
        switch (op.toLowerCase()) {
            case "eq": return "$eq";
            case "ne": return "$ne";
            case "gt": return "$gt";
            case "gte": return "$gte";
            case "lt": return "$lt";
            case "lte": return "$lte";
            case "in": return "$in";
            case "nin": return "$nin";
            case "exists": return "$exists";
            case "regex": return "$regex";
            default:
                throw new IllegalArgumentException("Unsupported operator: " + op);
        }
    }

    private <T> T convertToObject(Document document, Class<T> type) {
        return converter.read(type, document);
    }

    private MongoConverter createMongoConverter() {
        MongoMappingContext mappingContext = new MongoMappingContext();
        mappingContext.setSimpleTypeHolder(new SimpleTypeHolder());
        
        MappingMongoConverter converter = new MappingMongoConverter(
            new DefaultDbRefResolver(database.getClient()),
            mappingContext
        );
        
        converter.setCustomConversions(new MongoCustomConversions(
            Arrays.asList(
                new DateToLocalDateTimeConverter(),
                new LocalDateTimeToDateConverter()
            )
        ));
        
        return converter;
    }
}
```

这个MongoDB连接实现提供了：

1. 基本操作
    - 查询操作
    - 文档插入
    - 聚合查询
    - 批量写入

2. 事务支持
    - 事务管理
    - 会话控制
    - 提交回滚

3. 查询构建
    - 过滤条件构建
    - 操作符支持
    - 聚合管道构建

4. 数据转换
    - 文档对象映射
    - 类型转换
    - 自定义转换器

接下来我们要实现ConnectionManager(连接管理器)吗？用于管理和复用数据源连接。
好的，让我们实现ConnectionManager(连接管理器)来管理数据源连接：

```java
package com.platform.collect.core.collector.datasource.connection;

/**
 * 连接管理器
 */
@Slf4j
@Component
public class ConnectionManager {

    // 连接池配置
    private static final int DEFAULT_MAX_POOL_SIZE = 20;
    private static final int DEFAULT_MIN_POOL_SIZE = 5;
    private static final long DEFAULT_MAX_WAIT_TIME = 3000;
    private static final long DEFAULT_KEEP_ALIVE_TIME = 60000;

    // 连接池
    private final Map<String, GenericObjectPool<DataSourceConnection>> connectionPools;
    
    // 数据源工厂
    @Autowired
    private DataSourceFactory dataSourceFactory;

    public ConnectionManager() {
        this.connectionPools = new ConcurrentHashMap<>();
    }

    /**
     * 获取连接
     */
    public DataSourceConnection getConnection(String sourceId) throws DataSourceException {
        try {
            // 1. 获取或创建连接池
            GenericObjectPool<DataSourceConnection> pool = getConnectionPool(sourceId);

            // 2. 借用连接
            DataSourceConnection connection = pool.borrowObject();

            // 3. 验证连接
            if (!connection.isValid()) {
                pool.invalidateObject(connection);
                connection = pool.borrowObject();
            }

            return new PooledConnection(connection, pool);

        } catch (Exception e) {
            log.error("Get connection failed: {}", sourceId, e);
            throw new DataSourceException("Get connection failed: " + e.getMessage(), e);
        }
    }

    /**
     * 获取连接池
     */
    private GenericObjectPool<DataSourceConnection> getConnectionPool(String sourceId) {
        return connectionPools.computeIfAbsent(sourceId, key -> {
            // 1. 创建连接工厂
            ConnectionFactory factory = new ConnectionFactory(
                dataSourceFactory.getDataSource(key)
            );

            // 2. 创建池配置
            GenericObjectPoolConfig<DataSourceConnection> config = createPoolConfig(
                dataSourceFactory.getDataSourceConfig(key)
            );

            // 3. 创建连接池
            return new GenericObjectPool<>(factory, config);
        });
    }

    /**
     * 创建连接池配置
     */
    private GenericObjectPoolConfig<DataSourceConnection> createPoolConfig(DataSourceConfig config) {
        GenericObjectPoolConfig<DataSourceConnection> poolConfig = new GenericObjectPoolConfig<>();
        
        // 基本配置
        poolConfig.setMaxTotal(config.getMaxConnections());
        poolConfig.setMinIdle(config.getMinConnections());
        poolConfig.setMaxWaitMillis(config.getConnectionTimeout());
        
        // 测试配置
        poolConfig.setTestOnBorrow(true);
        poolConfig.setTestOnReturn(true);
        poolConfig.setTestWhileIdle(true);
        
        // 驱逐配置
        poolConfig.setTimeBetweenEvictionRunsMillis(60000);
        poolConfig.setMinEvictableIdleTimeMillis(300000);
        
        return poolConfig;
    }

    /**
     * 连接工厂
     */
    private static class ConnectionFactory extends BasePooledObjectFactory<DataSourceConnection> {
        
        private final DataSource dataSource;
        
        public ConnectionFactory(DataSource dataSource) {
            this.dataSource = dataSource;
        }

        @Override
        public DataSourceConnection create() throws Exception {
            return dataSource.getConnection();
        }

        @Override
        public PooledObject<DataSourceConnection> wrap(DataSourceConnection connection) {
            return new DefaultPooledObject<>(connection);
        }

        @Override
        public void destroyObject(PooledObject<DataSourceConnection> p) throws Exception {
            p.getObject().close();
        }

        @Override
        public boolean validateObject(PooledObject<DataSourceConnection> p) {
            return p.getObject().isValid();
        }
    }

    /**
     * 池化连接包装器
     */
    private static class PooledConnection implements DataSourceConnection {
        
        private final DataSourceConnection delegate;
        private final GenericObjectPool<DataSourceConnection> pool;
        private volatile boolean closed = false;

        public PooledConnection(DataSourceConnection delegate, 
                GenericObjectPool<DataSourceConnection> pool) {
            this.delegate = delegate;
            this.pool = pool;
        }

        @Override
        public <T> List<T> queryForList(String query, Map<String, Object> params, Class<T> type) 
                throws DataSourceException {
            checkClosed();
            return delegate.queryForList(query, params, type);
        }

        @Override
        public <T> T queryForObject(String query, Map<String, Object> params, Class<T> type) 
                throws DataSourceException {
            checkClosed();
            return delegate.queryForObject(query, params, type);
        }

        @Override
        public int execute(String query, Map<String, Object> params) throws DataSourceException {
            checkClosed();
            return delegate.execute(query, params);
        }

        @Override
        public void beginTransaction() throws DataSourceException {
            checkClosed();
            delegate.beginTransaction();
        }

        @Override
        public void commit() throws DataSourceException {
            checkClosed();
            delegate.commit();
        }

        @Override
        public void rollback() throws DataSourceException {
            checkClosed();
            delegate.rollback();
        }

        @Override
        public boolean isValid() throws DataSourceException {
            return !closed && delegate.isValid();
        }

        @Override
        public <T> T getNativeConnection() {
            checkClosed();
            return delegate.getNativeConnection();
        }

        @Override
        public void close() {
            if (!closed) {
                closed = true;
                try {
                    pool.returnObject(delegate);
                } catch (Exception e) {
                    log.error("Return connection to pool failed", e);
                }
            }
        }

        private void checkClosed() throws DataSourceException {
            if (closed) {
                throw new DataSourceException("Connection is closed");
            }
        }
    }

    /**
     * 关闭指定数据源的连接池
     */
    public void closeConnectionPool(String sourceId) {
        GenericObjectPool<DataSourceConnection> pool = connectionPools.remove(sourceId);
        if (pool != null) {
            try {
                pool.close();
            } catch (Exception e) {
                log.error("Close connection pool failed: {}", sourceId, e);
            }
        }
    }

    /**
     * 关闭所有连接池
     */
    @PreDestroy
    public void shutdown() {
        connectionPools.forEach((sourceId, pool) -> {
            try {
                pool.close();
            } catch (Exception e) {
                log.error("Close connection pool failed: {}", sourceId, e);
            }
        });
        connectionPools.clear();
    }
}
```

这个连接管理器实现了：

1. 连接池管理
    - 按数据源管理连接池
    - 连接池配置管理
    - 连接的借用和归还

2. 连接生命周期
    - 连接的创建和销毁
    - 连接的验证
    - 连接的复用

3. 池化连接
    - 连接包装和代理
    - 状态检查
    - 自动关闭处理

4. 资源管理
    - 连接池关闭
    - 资源清理
    - 异常处理

接下来要实现TransactionManager(事务管理器)吗？用于管理分布式事务。
好的，让我们实现TransactionManager(事务管理器)来管理分布式事务：

```java
package com.platform.collect.core.collector.transaction;

/**
 * 事务管理器
 */
@Slf4j
@Component
public class TransactionManager {

    @Autowired
    private ConnectionManager connectionManager;

    // 事务上下文
    private final ThreadLocal<TransactionContext> transactionContext = new ThreadLocal<>();

    /**
     * 开启事务
     */
    public TransactionStatus begin() throws TransactionException {
        try {
            // 1. 检查是否已存在事务
            TransactionContext context = transactionContext.get();
            if (context != null) {
                throw new TransactionException("Transaction already exists");
            }

            // 2. 创建事务上下文
            context = new TransactionContext();
            transactionContext.set(context);

            // 3. 创建事务状态
            TransactionStatus status = new TransactionStatus(context);
            
            log.debug("Begin transaction: {}", status.getTransactionId());
            return status;

        } catch (Exception e) {
            log.error("Begin transaction failed", e);
            throw new TransactionException("Begin transaction failed: " + e.getMessage(), e);
        }
    }

    /**
     * 提交事务
     */
    public void commit(TransactionStatus status) throws TransactionException {
        try {
            // 1. 验证事务状态
            validateTransaction(status);

            // 2. 执行提交
            TransactionContext context = status.getTransactionContext();
            doCommit(context);

            // 3. 清理事务上下文
            cleanup();

            log.debug("Commit transaction: {}", status.getTransactionId());

        } catch (Exception e) {
            log.error("Commit transaction failed", e);
            throw new TransactionException("Commit transaction failed: " + e.getMessage(), e);
        }
    }

    /**
     * 回滚事务
     */
    public void rollback(TransactionStatus status) throws TransactionException {
        try {
            // 1. 验证事务状态
            validateTransaction(status);

            // 2. 执行回滚
            TransactionContext context = status.getTransactionContext();
            doRollback(context);

            // 3. 清理事务上下文
            cleanup();

            log.debug("Rollback transaction: {}", status.getTransactionId());

        } catch (Exception e) {
            log.error("Rollback transaction failed", e);
            throw new TransactionException("Rollback transaction failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行提交
     */
    private void doCommit(TransactionContext context) throws Exception {
        // 1. 获取参与者列表
        List<TransactionParticipant> participants = context.getParticipants();
        if (CollectionUtils.isEmpty(participants)) {
            return;
        }

        // 2. 执行两阶段提交
        // 第一阶段: 准备
        boolean prepareSuccess = prepareCommit(participants);
        if (!prepareSuccess) {
            // 准备失败,执行回滚
            doRollback(context);
            throw new TransactionException("Transaction prepare failed");
        }

        // 第二阶段: 提交
        try {
            for (TransactionParticipant participant : participants) {
                participant.commit();
            }
        } catch (Exception e) {
            // 提交失败,执行补偿
            compensateCommit(participants);
            throw e;
        }
    }

    /**
     * 准备提交
     */
    private boolean prepareCommit(List<TransactionParticipant> participants) {
        for (TransactionParticipant participant : participants) {
            try {
                if (!participant.prepare()) {
                    return false;
                }
            } catch (Exception e) {
                log.error("Prepare commit failed", e);
                return false;
            }
        }
        return true;
    }

    /**
     * 补偿提交
     */
    private void compensateCommit(List<TransactionParticipant> participants) {
        for (TransactionParticipant participant : participants) {
            try {
                participant.compensate();
            } catch (Exception e) {
                log.error("Compensate commit failed", e);
            }
        }
    }

    /**
     * 执行回滚
     */
    private void doRollback(TransactionContext context) {
        List<TransactionParticipant> participants = context.getParticipants();
        if (CollectionUtils.isEmpty(participants)) {
            return;
        }

        // 逆序回滚
        for (int i = participants.size() - 1; i >= 0; i--) {
            TransactionParticipant participant = participants.get(i);
            try {
                participant.rollback();
            } catch (Exception e) {
                log.error("Rollback participant failed", e);
            }
        }
    }

    /**
     * 验证事务状态
     */
    private void validateTransaction(TransactionStatus status) throws TransactionException {
        // 1. 检查事务上下文
        TransactionContext context = transactionContext.get();
        if (context == null) {
            throw new TransactionException("No transaction in progress");
        }

        // 2. 验证事务状态
        if (!context.equals(status.getTransactionContext())) {
            throw new TransactionException("Invalid transaction status");
        }
    }

    /**
     * 清理事务上下文
     */
    private void cleanup() {
        transactionContext.remove();
    }

    /**
     * 获取当前事务上下文
     */
    public TransactionContext getCurrentTransaction() {
        return transactionContext.get();
    }

    /**
     * 注册事务参与者
     */
    public void registerParticipant(TransactionParticipant participant) {
        TransactionContext context = transactionContext.get();
        if (context != null) {
            context.addParticipant(participant);
        }
    }

    /**
     * 事务上下文
     */
    @Data
    public static class TransactionContext {
        private final String transactionId = UUID.randomUUID().toString();
        private final List<TransactionParticipant> participants = new ArrayList<>();
        private final Date startTime = new Date();
        private Date endTime;
        private TransactionStatus status = TransactionStatus.ACTIVE;

        public void addParticipant(TransactionParticipant participant) {
            participants.add(participant);
        }
    }

    /**
     * 事务状态
     */
    @Data
    public static class TransactionStatus {
        private final TransactionContext transactionContext;
        private final String transactionId;

        public TransactionStatus(TransactionContext context) {
            this.transactionContext = context;
            this.transactionId = context.getTransactionId();
        }
    }

    /**
     * 事务参与者接口
     */
    public interface TransactionParticipant {
        boolean prepare() throws Exception;
        void commit() throws Exception;
        void rollback() throws Exception;
        void compensate() throws Exception;
    }
}
```

这个事务管理器实现了：

1. 事务生命周期管理
    - 事务开启
    - 事务提交
    - 事务回滚
    - 事务状态跟踪

2. 两阶段提交协议
    - 准备阶段
    - 提交阶段
    - 回滚处理
    - 补偿机制

3. 事务参与者管理
    - 参与者注册
    - 参与者协调
    - 有序执行

4. 事务上下文管理
    - 线程绑定
    - 状态验证
    - 资源清理

接下来要实现具体的TransactionParticipant(事务参与者)实现类吗？比如JdbcTransactionParticipant和MongoTransactionParticipant。
好的，让我们实现具体的事务参与者类。先实现JdbcTransactionParticipant：

```java
package com.platform.collect.core.collector.transaction.participant;

/**
 * JDBC事务参与者
 */
@Slf4j
public class JdbcTransactionParticipant implements TransactionParticipant {

    private final Connection connection;
    private final String resourceId;
    private Savepoint savepoint;

    public JdbcTransactionParticipant(Connection connection, String resourceId) {
        this.connection = connection;
        this.resourceId = resourceId;
    }

    @Override
    public boolean prepare() throws Exception {
        try {
            // 1. 验证连接
            if (!connection.isValid(3)) {
                log.error("Connection is invalid: {}", resourceId);
                return false;
            }

            // 2. 创建保存点
            savepoint = connection.setSavepoint("PREPARE_" + resourceId);
            
            return true;
        } catch (Exception e) {
            log.error("Prepare JDBC transaction failed: {}", resourceId, e);
            return false;
        }
    }

    @Override
    public void commit() throws Exception {
        try {
            // 1. 检查连接状态
            if (!connection.isValid(3)) {
                throw new TransactionException("Connection is invalid: " + resourceId);
            }

            // 2. 执行提交
            if (!connection.getAutoCommit()) {
                connection.commit();
            }
            
            // 3. 释放保存点
            if (savepoint != null) {
                connection.releaseSavepoint(savepoint);
            }

        } catch (Exception e) {
            log.error("Commit JDBC transaction failed: {}", resourceId, e);
            throw new TransactionException("Commit failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void rollback() throws Exception {
        try {
            // 1. 检查连接状态
            if (!connection.isValid(3)) {
                throw new TransactionException("Connection is invalid: " + resourceId);
            }

            // 2. 回滚到保存点
            if (savepoint != null) {
                connection.rollback(savepoint);
            } else {
                connection.rollback();
            }

        } catch (Exception e) {
            log.error("Rollback JDBC transaction failed: {}", resourceId, e);
            throw new TransactionException("Rollback failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void compensate() throws Exception {
        try {
            // 1. 检查连接状态
            if (!connection.isValid(3)) {
                throw new TransactionException("Connection is invalid: " + resourceId);
            }

            // 2. 回滚事务
            connection.rollback();

            // 3. 记录补偿日志
            logCompensation();

        } catch (Exception e) {
            log.error("Compensate JDBC transaction failed: {}", resourceId, e);
            throw new TransactionException("Compensation failed: " + e.getMessage(), e);
        }
    }

    /**
     * 记录补偿日志
     */
    private void logCompensation() {
        try {
            CompensationLog log = CompensationLog.builder()
                .resourceId(resourceId)
                .resourceType("JDBC")
                .timestamp(new Date())
                .build();
            
            compensationLogService.saveLog(log);
        } catch (Exception e) {
            log.error("Log compensation failed", e);
        }
    }
}

/**
 * MongoDB事务参与者
 */
@Slf4j
public class MongoTransactionParticipant implements TransactionParticipant {

    private final MongoDatabase database;
    private final String resourceId;
    private ClientSession session;

    public MongoTransactionParticipant(MongoDatabase database, String resourceId) {
        this.database = database;
        this.resourceId = resourceId;
    }

    @Override
    public boolean prepare() throws Exception {
        try {
            // 1. 验证连接
            Document result = database.runCommand(new Document("ping", 1));
            if (result.getDouble("ok") != 1.0) {
                log.error("Database connection is invalid: {}", resourceId);
                return false;
            }

            // 2. 开启会话
            session = database.getClient().startSession();
            session.startTransaction();
            
            return true;
        } catch (Exception e) {
            log.error("Prepare MongoDB transaction failed: {}", resourceId, e);
            return false;
        }
    }

    @Override
    public void commit() throws Exception {
        try {
            // 1. 检查会话状态
            if (session == null || !session.hasActiveTransaction()) {
                throw new TransactionException("No active transaction: " + resourceId);
            }

            // 2. 提交事务
            session.commitTransaction();

        } catch (Exception e) {
            log.error("Commit MongoDB transaction failed: {}", resourceId, e);
            throw new TransactionException("Commit failed: " + e.getMessage(), e);
        } finally {
            closeSession();
        }
    }

    @Override
    public void rollback() throws Exception {
        try {
            // 1. 检查会话状态
            if (session == null || !session.hasActiveTransaction()) {
                return;
            }

            // 2. 回滚事务
            session.abortTransaction();

        } catch (Exception e) {
            log.error("Rollback MongoDB transaction failed: {}", resourceId, e);
            throw new TransactionException("Rollback failed: " + e.getMessage(), e);
        } finally {
            closeSession();
        }
    }

    @Override
    public void compensate() throws Exception {
        try {
            // 1. 回滚事务
            if (session != null && session.hasActiveTransaction()) {
                session.abortTransaction();
            }

            // 2. 记录补偿日志
            logCompensation();

        } catch (Exception e) {
            log.error("Compensate MongoDB transaction failed: {}", resourceId, e);
            throw new TransactionException("Compensation failed: " + e.getMessage(), e);
        } finally {
            closeSession();
        }
    }

    /**
     * 关闭会话
     */
    private void closeSession() {
        if (session != null) {
            try {
                session.close();
                session = null;
            } catch (Exception e) {
                log.error("Close session failed", e);
            }
        }
    }

    /**
     * 记录补偿日志
     */
    private void logCompensation() {
        try {
            CompensationLog log = CompensationLog.builder()
                .resourceId(resourceId)
                .resourceType("MongoDB")
                .timestamp(new Date())
                .build();
            
            compensationLogService.saveLog(log);
        } catch (Exception e) {
            log.error("Log compensation failed", e);
        }
    }
}
```

这些事务参与者实现了：

1. 资源管理
    - 连接验证
    - 会话管理
    - 资源清理

2. 事务操作
    - 准备阶段
    - 提交操作
    - 回滚操作
    - 补偿处理

3. 状态管理
    - 保存点管理
    - 会话状态跟踪
    - 事务状态检查

4. 错误处理
    - 异常处理
    - 补偿日志
    - 资源恢复

要继续实现TransactionTemplate(事务模板)吗？它提供了一个更高级的事务管理抽象。
好的，让我们实现TransactionTemplate(事务模板)，提供一个更简单的事务管理接口：

```java
package com.platform.collect.core.collector.transaction;

/**
 * 事务模板
 */
@Slf4j
@Component
public class TransactionTemplate {

    @Autowired
    private TransactionManager transactionManager;

    /**
     * 在事务中执行操作
     */
    public <T> T execute(TransactionCallback<T> action) throws TransactionException {
        // 1. 开启事务
        TransactionStatus status = transactionManager.begin();
        
        try {
            // 2. 执行操作
            T result = action.doInTransaction(status);
            
            // 3. 提交事务
            transactionManager.commit(status);
            
            return result;
            
        } catch (Exception e) {
            // 4. 回滚事务
            transactionManager.rollback(status);
            throw new TransactionException("Transaction execution failed: " + e.getMessage(), e);
        }
    }

    /**
     * 在新事务中执行操作
     */
    public <T> T executeNew(TransactionCallback<T> action) throws TransactionException {
        // 1. 挂起当前事务
        TransactionStatus suspended = suspend();
        
        try {
            // 2. 执行新事务
            return execute(action);
            
        } finally {
            // 3. 恢复之前事务
            resume(suspended);
        }
    }

    /**
     * 在事务中执行无返回值操作
     */
    public void executeWithoutResult(TransactionCallbackWithoutResult action) throws TransactionException {
        execute(status -> {
            action.doInTransaction(status);
            return null;
        });
    }

    /**
     * 执行补偿操作
     */
    public void executeWithCompensation(TransactionCallbackWithCompensation action) throws TransactionException {
        TransactionStatus status = transactionManager.begin();
        
        try {
            // 1. 执行主要操作
            action.doInTransaction(status);
            
            // 2. 提交事务
            transactionManager.commit(status);
            
        } catch (Exception e) {
            try {
                // 3. 回滚事务
                transactionManager.rollback(status);
                
                // 4. 执行补偿
                action.doCompensation(e);
                
            } catch (Exception ex) {
                log.error("Compensation execution failed", ex);
                throw new TransactionException("Compensation failed: " + ex.getMessage(), ex);
            }
            throw new TransactionException("Transaction execution failed: " + e.getMessage(), e);
        }
    }

    /**
     * 挂起当前事务
     */
    private TransactionStatus suspend() {
        return transactionManager.getCurrentTransaction() != null ? 
            new TransactionStatus(transactionManager.getCurrentTransaction()) : null;
    }

    /**
     * 恢复事务
     */
    private void resume(TransactionStatus status) {
        if (status != null) {
            // TODO: 实现事务恢复逻辑
        }
    }

    /**
     * 事务回调接口
     */
    @FunctionalInterface
    public interface TransactionCallback<T> {
        T doInTransaction(TransactionStatus status) throws Exception;
    }

    /**
     * 无返回值事务回调接口
     */
    @FunctionalInterface
    public interface TransactionCallbackWithoutResult {
        void doInTransaction(TransactionStatus status) throws Exception;
    }

    /**
     * 带补偿的事务回调接口
     */
    public interface TransactionCallbackWithCompensation {
        void doInTransaction(TransactionStatus status) throws Exception;
        void doCompensation(Exception e) throws Exception;
    }

    /**
     * 事务配置构建器
     */
    @Data
    @Builder
    public static class TransactionConfig {
        private boolean readOnly;
        private int timeout;
        private IsolationLevel isolationLevel;
        private PropagationBehavior propagationBehavior;
        
        public static TransactionConfig getDefault() {
            return TransactionConfig.builder()
                .readOnly(false)
                .timeout(30)
                .isolationLevel(IsolationLevel.READ_COMMITTED)
                .propagationBehavior(PropagationBehavior.REQUIRED)
                .build();
        }
    }

    /**
     * 使用示例
     */
    public void examples() {
        // 1. 基本使用
        String result = transactionTemplate.execute(status -> {
            // 执行业务逻辑
            return "result";
        });

        // 2. 无返回值操作
        transactionTemplate.executeWithoutResult(status -> {
            // 执行业务逻辑
        });

        // 3. 带补偿的操作
        transactionTemplate.executeWithCompensation(new TransactionCallbackWithCompensation() {
            @Override
            public void doInTransaction(TransactionStatus status) throws Exception {
                // 执行业务逻辑
            }

            @Override
            public void doCompensation(Exception e) throws Exception {
                // 执行补偿逻辑
            }
        });

        // 4. 新事务执行
        transactionTemplate.executeNew(status -> {
            // 在新事务中执行业务逻辑
            return "result";
        });
    }
}
```

这个事务模板提供了：

1. 简化接口
    - 事务回调
    - Lambda支持
    - 链式调用

2. 事务管理
    - 事务创建
    - 事务提交
    - 事务回滚
    - 事务传播

3. 补偿支持
    - 补偿回调
    - 错误处理
    - 资源恢复

4. 配置管理
    - 事务属性
    - 隔离级别
    - 传播行为

接下来我们要实现具体的补偿处理相关的类吗？比如CompensationManager和CompensationHandler。
好的，让我们实现补偿管理相关的类。首先是CompensationManager：

```java
package com.platform.collect.core.collector.compensation;

/**
 * 补偿管理器
 */
@Slf4j
@Component
public class CompensationManager {

    @Autowired
    private CompensationRepository compensationRepository;

    // 补偿处理器注册表
    private final Map<String, CompensationHandler> handlerRegistry = new ConcurrentHashMap<>();

    // 补偿执行器
    private final ScheduledExecutorService executor = Executors.newScheduledThreadPool(
        5,
        new NamedThreadFactory("compensation-")
    );

    /**
     * 注册补偿处理器
     */
    public void registerHandler(String type, CompensationHandler handler) {
        handlerRegistry.put(type, handler);
        log.info("Registered compensation handler: {}", type);
    }

    /**
     * 创建补偿任务
     */
    public String createCompensation(CompensationTask task) {
        try {
            // 1. 验证任务
            validateTask(task);

            // 2. 保存任务
            task.setStatus(CompensationStatus.PENDING);
            task.setCreateTime(new Date());
            compensationRepository.save(task);

            // 3. 调度执行
            scheduleExecution(task);

            return task.getTaskId();

        } catch (Exception e) {
            log.error("Create compensation task failed", e);
            throw new CompensationException("Create compensation failed: " + e.getMessage(), e);
        }
    }

    /**
     * 执行补偿
     */
    public void executeCompensation(String taskId) {
        try {
            // 1. 获取任务
            CompensationTask task = compensationRepository.findById(taskId);
            if (task == null) {
                throw new TaskNotFoundException("Compensation task not found: " + taskId);
            }

            // 2. 检查状态
            if (task.getStatus() != CompensationStatus.PENDING) {
                log.warn("Task is not in pending status: {}", taskId);
                return;
            }

            // 3. 执行补偿
            doExecute(task);

        } catch (Exception e) {
            log.error("Execute compensation failed: {}", taskId, e);
            handleExecutionError(taskId, e);
        }
    }

    /**
     * 执行补偿操作
     */
    private void doExecute(CompensationTask task) {
        try {
            // 1. 获取处理器
            CompensationHandler handler = getHandler(task.getType());

            // 2. 更新状态
            updateTaskStatus(task, CompensationStatus.EXECUTING);

            // 3. 执行补偿
            CompensationResult result = handler.execute(task);

            // 4. 处理结果
            handleResult(task, result);

        } catch (Exception e) {
            log.error("Execute compensation task failed: {}", task.getTaskId(), e);
            handleExecutionError(task.getTaskId(), e);
        }
    }

    /**
     * 处理执行结果
     */
    private void handleResult(CompensationTask task, CompensationResult result) {
        if (result.isSuccess()) {
            // 补偿成功
            updateTaskStatus(task, CompensationStatus.COMPLETED);
        } else {
            // 补偿失败
            if (shouldRetry(task)) {
                // 重试补偿
                scheduleRetry(task);
            } else {
                // 标记失败
                updateTaskStatus(task, CompensationStatus.FAILED);
                recordFailure(task, result.getError());
            }
        }
    }

    /**
     * 调度执行
     */
    private void scheduleExecution(CompensationTask task) {
        executor.schedule(
            () -> executeCompensation(task.getTaskId()),
            task.getDelay(),
            TimeUnit.MILLISECONDS
        );
    }

    /**
     * 调度重试
     */
    private void scheduleRetry(CompensationTask task) {
        // 1. 更新重试次数
        task.setRetryCount(task.getRetryCount() + 1);
        compensationRepository.save(task);

        // 2. 计算重试延迟
        long delay = calculateRetryDelay(task);

        // 3. 调度重试
        executor.schedule(
            () -> executeCompensation(task.getTaskId()),
            delay,
            TimeUnit.MILLISECONDS
        );
    }

    /**
     * 计算重试延迟
     */
    private long calculateRetryDelay(CompensationTask task) {
        // 指数退避策略
        return 1000L * (long) Math.pow(2, task.getRetryCount());
    }

    /**
     * 检查是否需要重试
     */
    private boolean shouldRetry(CompensationTask task) {
        return task.getRetryCount() < task.getMaxRetries();
    }

    /**
     * 获取补偿处理器
     */
    private CompensationHandler getHandler(String type) {
        CompensationHandler handler = handlerRegistry.get(type);
        if (handler == null) {
            throw new HandlerNotFoundException("Compensation handler not found: " + type);
        }
        return handler;
    }

    /**
     * 更新任务状态
     */
    private void updateTaskStatus(CompensationTask task, CompensationStatus status) {
        task.setStatus(status);
        task.setUpdateTime(new Date());
        compensationRepository.save(task);
    }

    /**
     * 记录失败信息
     */
    private void recordFailure(CompensationTask task, Throwable error) {
        CompensationError failure = CompensationError.builder()
            .taskId(task.getTaskId())
            .error(error.getMessage())
            .stackTrace(ExceptionUtils.getStackTrace(error))
            .timestamp(new Date())
            .build();
            
        compensationRepository.saveError(failure);
    }

    @PreDestroy
    public void shutdown() {
        executor.shutdown();
        try {
            if (!executor.awaitTermination(5, TimeUnit.SECONDS)) {
                executor.shutdownNow();
            }
        } catch (InterruptedException e) {
            executor.shutdownNow();
            Thread.currentThread().interrupt();
        }
    }
}
```

接下来要实现CompensationHandler接口和具体的处理器实现类吗？它们负责具体的补偿逻辑处理。
好的，让我们实现CompensationHandler接口和具体的处理器实现类：

```java
package com.platform.collect.core.collector.compensation;

/**
 * 补偿处理器接口
 */
public interface CompensationHandler {
    /**
     * 执行补偿
     */
    CompensationResult execute(CompensationTask task) throws CompensationException;

    /**
     * 获取处理器类型
     */
    String getType();
}

/**
 * 数据同步补偿处理器
 */
@Slf4j
@Component
public class DataSyncCompensationHandler implements CompensationHandler {

    @Autowired
    private DataSyncService dataSyncService;

    @Autowired
    private StateManager stateManager;

    @Override
    public CompensationResult execute(CompensationTask task) throws CompensationException {
        try {
            // 1. 解析补偿参数
            SyncCompensationParams params = parseSyncParams(task.getParams());

            // 2. 获取同步状态
            SyncTask syncTask = stateManager.getSyncTask(params.getSyncId());
            if (syncTask == null) {
                return CompensationResult.failed("Sync task not found: " + params.getSyncId());
            }

            // 3. 执行补偿
            doCompensate(syncTask, params);

            return CompensationResult.success();

        } catch (Exception e) {
            log.error("Execute sync compensation failed: {}", task.getTaskId(), e);
            return CompensationResult.failed(e);
        }
    }

    @Override
    public String getType() {
        return "DATA_SYNC";
    }

    /**
     * 执行补偿
     */
    private void doCompensate(SyncTask syncTask, SyncCompensationParams params) throws Exception {
        // 1. 回滚已同步数据
        rollbackSyncData(syncTask);

        // 2. 重新执行同步
        reSync(syncTask, params);

        // 3. 验证同步结果
        verifySyncResult(syncTask);
    }

    /**
     * 回滚同步数据
     */
    private void rollbackSyncData(SyncTask syncTask) throws Exception {
        // 1. 获取备份数据
        List<Map<String, Object>> backupData = getBackupData(syncTask);

        // 2. 恢复数据
        dataSyncService.restoreData(syncTask.getTargetId(), backupData);
    }

    /**
     * 重新同步
     */
    private void reSync(SyncTask syncTask, SyncCompensationParams params) throws Exception {
        // 1. 重置同步状态
        syncTask.setStatus(SyncStatus.PENDING);
        stateManager.updateSyncTask(syncTask);

        // 2. 创建同步请求
        SyncRequest request = SyncRequest.builder()
            .sourceId(syncTask.getSourceId())
            .targetId(syncTask.getTargetId())
            .version(params.getVersion())
            .options(params.getOptions())
            .build();

        // 3. 执行同步
        dataSyncService.syncData(request);
    }
}

/**
 * 数据采集补偿处理器
 */
@Slf4j
@Component
public class DataCollectCompensationHandler implements CompensationHandler {

    @Autowired
    private CollectService collectService;

    @Autowired
    private StateManager stateManager;

    @Override
    public CompensationResult execute(CompensationTask task) throws CompensationException {
        try {
            // 1. 解析补偿参数
            CollectCompensationParams params = parseCollectParams(task.getParams());

            // 2. 获取采集任务
            CollectTask collectTask = stateManager.getCollectTask(params.getTaskId());
            if (collectTask == null) {
                return CompensationResult.failed("Collect task not found: " + params.getTaskId());
            }

            // 3. 执行补偿
            doCompensate(collectTask, params);

            return CompensationResult.success();

        } catch (Exception e) {
            log.error("Execute collect compensation failed: {}", task.getTaskId(), e);
            return CompensationResult.failed(e);
        }
    }

    @Override
    public String getType() {
        return "DATA_COLLECT";
    }

    /**
     * 执行补偿
     */
    private void doCompensate(CollectTask collectTask, CollectCompensationParams params) throws Exception {
        // 1. 清理错误数据
        cleanupErrorData(collectTask);

        // 2. 重新执行采集
        reCollect(collectTask, params);

        // 3. 验证采集结果
        verifyCollectResult(collectTask);
    }

    /**
     * 清理错误数据
     */
    private void cleanupErrorData(CollectTask collectTask) throws Exception {
        // 1. 获取错误记录
        List<ErrorRecord> errors = getErrorRecords(collectTask);

        // 2. 删除错误数据
        for (ErrorRecord error : errors) {
            collectService.deleteData(error.getDataId());
        }
    }

    /**
     * 重新采集
     */
    private void reCollect(CollectTask collectTask, CollectCompensationParams params) throws Exception {
        // 1. 重置采集状态
        collectTask.setStatus(CollectStatus.PENDING);
        stateManager.updateCollectTask(collectTask);

        // 2. 创建采集请求
        CollectRequest request = CollectRequest.builder()
            .sourceId(collectTask.getSourceId())
            .collectType(collectTask.getCollectType())
            .params(params.getParams())
            .options(params.getOptions())
            .build();

        // 3. 执行采集
        collectService.collect(request);
    }
}
```

这些补偿处理器实现了：

1. 补偿处理
    - 同步数据补偿
    - 采集数据补偿
    - 状态恢复

2. 错误处理
    - 数据清理
    - 状态重置
    - 结果验证

3. 补偿流程
    - 数据回滚
    - 重新执行
    - 结果验证

4. 任务管理
    - 任务状态管理
    - 参数解析
    - 错误记录

接下来要实现补偿任务(CompensationTask)和补偿结果(CompensationResult)等相关模型类吗？
好的，让我们实现补偿相关的模型类：

```java
package com.platform.collect.core.collector.compensation.model;

/**
 * 补偿任务
 */
@Data
@Builder
public class CompensationTask {
    private String taskId;              // 任务ID
    private String type;                // 补偿类型
    private String resourceId;          // 资源ID
    private Map<String, Object> params; // 补偿参数
    private CompensationStatus status;  // 任务状态
    private int retryCount;            // 重试次数
    private int maxRetries;            // 最大重试次数
    private long delay;                // 延迟执行时间(毫秒)
    private Date createTime;           // 创建时间
    private Date updateTime;           // 更新时间
    private String error;              // 错误信息

    /**
     * 创建新任务
     */
    public static CompensationTask create(String type, String resourceId, Map<String, Object> params) {
        return CompensationTask.builder()
            .taskId(UUID.randomUUID().toString())
            .type(type)
            .resourceId(resourceId)
            .params(params)
            .status(CompensationStatus.PENDING)
            .retryCount(0)
            .maxRetries(3)
            .delay(0L)
            .createTime(new Date())
            .build();
    }
}

/**
 * 补偿结果
 */
@Data
@Builder
public class CompensationResult {
    private boolean success;           // 是否成功
    private String message;            // 结果消息
    private Throwable error;           // 错误信息
    private Map<String, Object> data;  // 结果数据

    /**
     * 创建成功结果
     */
    public static CompensationResult success() {
        return CompensationResult.builder()
            .success(true)
            .build();
    }

    /**
     * 创建成功结果(带数据)
     */
    public static CompensationResult success(Map<String, Object> data) {
        return CompensationResult.builder()
            .success(true)
            .data(data)
            .build();
    }

    /**
     * 创建失败结果
     */
    public static CompensationResult failed(String message) {
        return CompensationResult.builder()
            .success(false)
            .message(message)
            .build();
    }

    /**
     * 创建失败结果(带异常)
     */
    public static CompensationResult failed(Throwable error) {
        return CompensationResult.builder()
            .success(false)
            .message(error.getMessage())
            .error(error)
            .build();
    }
}

/**
 * 补偿状态
 */
public enum CompensationStatus {
    PENDING,    // 待执行
    EXECUTING,  // 执行中
    COMPLETED,  // 已完成
    FAILED      // 失败
}

/**
 * 补偿错误记录
 */
@Data
@Builder
public class CompensationError {
    private String taskId;             // 任务ID
    private String error;              // 错误信息
    private String stackTrace;         // 堆栈信息
    private Date timestamp;            // 错误时间
}

/**
 * 数据同步补偿参数
 */
@Data
@Builder
public class SyncCompensationParams {
    private String syncId;             // 同步任务ID
    private String version;            // 数据版本
    private Map<String, Object> options;// 同步选项
}

/**
 * 数据采集补偿参数
 */
@Data
@Builder
public class CollectCompensationParams {
    private String taskId;             // 采集任务ID
    private Map<String, Object> params;// 采集参数
    private Map<String, Object> options;// 采集选项
}

/**
 * 补偿监控信息
 */
@Data
@Builder
public class CompensationMetrics {
    private int pendingCount;          // 待执行数量
    private int executingCount;        // 执行中数量
    private int completedCount;        // 已完成数量
    private int failedCount;           // 失败数量
    private double avgExecuteTime;     // 平均执行时间
    private double avgRetryCount;      // 平均重试次数
    
    /**
     * 创建监控快照
     */
    public static CompensationMetrics snapshot(List<CompensationTask> tasks) {
        return CompensationMetrics.builder()
            .pendingCount((int) tasks.stream()
                .filter(t -> t.getStatus() == CompensationStatus.PENDING)
                .count())
            .executingCount((int) tasks.stream()
                .filter(t -> t.getStatus() == CompensationStatus.EXECUTING)
                .count())
            .completedCount((int) tasks.stream()
                .filter(t -> t.getStatus() == CompensationStatus.COMPLETED)
                .count())
            .failedCount((int) tasks.stream()
                .filter(t -> t.getStatus() == CompensationStatus.FAILED)
                .count())
            .avgExecuteTime(tasks.stream()
                .filter(t -> t.getStatus() == CompensationStatus.COMPLETED)
                .mapToLong(t -> t.getUpdateTime().getTime() - t.getCreateTime().getTime())
                .average()
                .orElse(0))
            .avgRetryCount(tasks.stream()
                .mapToInt(CompensationTask::getRetryCount)
                .average()
                .orElse(0))
            .build();
    }
}
```

这些模型类包含：

1. 任务模型
    - 任务基本信息
    - 状态管理
    - 重试控制
    - 任务创建工具

2. 结果模型
    - 执行结果
    - 错误信息
    - 结果数据
    - 结果构建工具

3. 参数模型
    - 同步补偿参数
    - 采集补偿参数
    - 补偿选项

4. 监控模型
    - 任务统计
    - 性能指标
    - 状态分布
    - 监控快照

接下来要实现CompensationRepository(补偿仓储)吗？它负责补偿任务的持久化管理。
好的，让我们实现CompensationRepository(补偿仓储)：

```java
package com.platform.collect.core.collector.compensation.repository;

/**
 * 补偿仓储接口
 */
public interface CompensationRepository {

    /**
     * 保存补偿任务
     */
    void save(CompensationTask task);

    /**
     * 查询补偿任务
     */
    CompensationTask findById(String taskId);

    /**
     * 更新任务状态
     */
    void updateStatus(String taskId, CompensationStatus status);

    /**
     * 保存错误记录 
     */
    void saveError(CompensationError error);

    /**
     * 查询待执行任务
     */
    List<CompensationTask> findPendingTasks();

    /**
     * 查询失败任务
     */
    List<CompensationTask> findFailedTasks();

    /**
     * 删除任务
     */
    void deleteTask(String taskId);
}

/**
 * MongoDB补偿仓储实现
 */
@Slf4j
@Repository
public class MongoCompensationRepository implements CompensationRepository {

    private static final String TASK_COLLECTION = "compensation_tasks";
    private static final String ERROR_COLLECTION = "compensation_errors";

    @Autowired
    private MongoTemplate mongoTemplate;

    @Override
    public void save(CompensationTask task) {
        try {
            mongoTemplate.save(task, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Save compensation task failed", e);
            throw new RepositoryException("Save compensation task failed: " + e.getMessage(), e);
        }
    }

    @Override
    public CompensationTask findById(String taskId) {
        try {
            return mongoTemplate.findById(taskId, CompensationTask.class, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Find compensation task failed", e);
            throw new RepositoryException("Find compensation task failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void updateStatus(String taskId, CompensationStatus status) {
        try {
            Query query = Query.query(Criteria.where("_id").is(taskId));
            Update update = Update.update("status", status)
                .set("updateTime", new Date());
            
            mongoTemplate.updateFirst(query, update, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Update compensation status failed", e);
            throw new RepositoryException("Update compensation status failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void saveError(CompensationError error) {
        try {
            mongoTemplate.save(error, ERROR_COLLECTION);
        } catch (Exception e) {
            log.error("Save compensation error failed", e);
            throw new RepositoryException("Save compensation error failed: " + e.getMessage(), e);
        }
    }

    @Override
    public List<CompensationTask> findPendingTasks() {
        try {
            Query query = Query.query(
                Criteria.where("status").is(CompensationStatus.PENDING)
            );
            return mongoTemplate.find(query, CompensationTask.class, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Find pending tasks failed", e);
            throw new RepositoryException("Find pending tasks failed: " + e.getMessage(), e);
        }
    }

    @Override
    public List<CompensationTask> findFailedTasks() {
        try {
            Query query = Query.query(
                Criteria.where("status").is(CompensationStatus.FAILED)
            );
            return mongoTemplate.find(query, CompensationTask.class, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Find failed tasks failed", e);
            throw new RepositoryException("Find failed tasks failed: " + e.getMessage(), e);
        }
    }

    @Override
    public void deleteTask(String taskId) {
        try {
            Query query = Query.query(Criteria.where("_id").is(taskId));
            mongoTemplate.remove(query, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Delete compensation task failed", e);
            throw new RepositoryException("Delete compensation task failed: " + e.getMessage(), e);
        }
    }

    /**
     * 查询任务状态统计
     */
    public CompensationMetrics getMetrics() {
        try {
            List<CompensationTask> tasks = mongoTemplate.findAll(
                CompensationTask.class, 
                TASK_COLLECTION
            );
            return CompensationMetrics.snapshot(tasks);
        } catch (Exception e) {
            log.error("Get compensation metrics failed", e);
            throw new RepositoryException("Get compensation metrics failed: " + e.getMessage(), e);
        }
    }

    /**
     * 清理已完成任务
     */
    public void cleanupCompletedTasks(int days) {
        try {
            // 计算清理时间点
            Calendar calendar = Calendar.getInstance();
            calendar.add(Calendar.DAY_OF_YEAR, -days);
            Date cleanupDate = calendar.getTime();

            // 构建查询条件
            Query query = Query.query(
                Criteria.where("status").is(CompensationStatus.COMPLETED)
                .and("updateTime").lt(cleanupDate)
            );

            // 执行删除
            mongoTemplate.remove(query, TASK_COLLECTION);
        } catch (Exception e) {
            log.error("Cleanup completed tasks failed", e);
            throw new RepositoryException("Cleanup completed tasks failed: " + e.getMessage(), e);
        }
    }
}
```

该仓储实现了：

1. 基本操作
    - 任务保存
    - 状态更新
    - 错误记录
    - 任务查询

2. 任务管理
    - 待执行任务查询
    - 失败任务查询
    - 任务删除
    - 任务清理

3. 监控统计
    - 状态统计
    - 性能指标
    - 监控快照

4. 异常处理
    - 操作异常封装
    - 错误日志记录
    - 异常传递

接下来要实现CompensationScheduler(补偿调度器)吗？它负责定时调度和执行补偿任务。

